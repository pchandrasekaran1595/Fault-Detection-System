{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "All ML Classifiers",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNrTd7nXyWne9sqnwa3nSyu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/123prashanth123/Fault-Detection-System/blob/main/All%20ML%20Classifiers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H97f076UrWTV"
      },
      "source": [
        "# Notebook Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vdu5z2Z94Vkk"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "!pip install -q --upgrade imgaug\n",
        "!pip install -q imagecorruptions\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36Jae2qyv7L5"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import DataLoader as DL\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "import cv2\n",
        "import re\n",
        "import os\n",
        "import random as r\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import imgaug\n",
        "from imgaug import augmenters\n",
        "from time import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aa7VI8tP4QbJ"
      },
      "source": [
        "def breaker():\n",
        "    print(\"\\n\" + 50*\"*\" + \"\\n\")\n",
        "\n",
        "def head(x=None, no_of_ele=5):\n",
        "    print(x[:no_of_ele])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwNrqUdo3NzA"
      },
      "source": [
        "TRANSFORM = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.405], std=[0.229, 0.224, 0.225])])\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "SEED = 0\n",
        "SIZE = 224\n",
        "FEATURE_VECTOR_LENGTH = 2048\n",
        "SPLIT = 0.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TX0KadGjrgg9"
      },
      "source": [
        "# Build Feature Extractor Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVANZUCTrlN9"
      },
      "source": [
        "def build_feature_extractor():\n",
        "    class Model(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(Model, self).__init__()\n",
        "\n",
        "            self.model = models.vgg16_bn(pretrained=True, progress=True)\n",
        "            self.model = nn.Sequential(*[*self.model.children()][:-2])\n",
        "            self.model.add_module(\"Adaptive Average Pool\", nn.AdaptiveAvgPool2d(output_size=(2, 2)))\n",
        "            self.model.add_module(\"Flatten\", nn.Flatten())\n",
        "\n",
        "        def forward(self, x):\n",
        "            return self.model(x)\n",
        "\n",
        "\n",
        "    model = Model()\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rROSrmuroOC"
      },
      "source": [
        "# Build Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvGc_qcYrq_H"
      },
      "source": [
        "def build_features(num_samples: int, batch_size: int, path: str, p_name: str, n_name: str):\n",
        "    breaker()\n",
        "    print(\"Building Features ...\")\n",
        "\n",
        "    class FEDS(Dataset):\n",
        "        def __init__(self, X=None, transform=None):\n",
        "            self.X = X\n",
        "            self.transform = transform\n",
        "        \n",
        "        def __len__(self):\n",
        "            return self.X.shape[0]\n",
        "        \n",
        "        def __getitem__(self, idx):\n",
        "            return self.transform(self.X[idx])\n",
        "    \n",
        "\n",
        "    def normalize(x):\n",
        "            for i in range(x.shape[0]):\n",
        "                x[i] = (x[i] - torch.min(x[i])) / (torch.max(x[i]) - torch.min(x[i]))\n",
        "            return x\n",
        "    \n",
        "\n",
        "    def preprocess(image: np.ndarray) -> np.ndarray:\n",
        "        return cv2.resize(src=cv2.cvtColor(src=image, code=cv2.COLOR_BGR2RGB), dsize=(SIZE, SIZE), interpolation=cv2.INTER_AREA)\n",
        "        \n",
        "    \n",
        "    imgaug.seed(SEED)\n",
        "    dataset_augment = augmenters.Sequential([\n",
        "        augmenters.HorizontalFlip(p=0.25),\n",
        "        augmenters.VerticalFlip(p=0.25),\n",
        "        augmenters.SomeOf(5, [\n",
        "                augmenters.blur.GaussianBlur(sigma=(0, 5), seed=SEED),\n",
        "                augmenters.blur.MedianBlur(k=(1, 7), seed=SEED),\n",
        "                augmenters.size.Crop(percent=(0, 0.1), seed=SEED),\n",
        "                augmenters.geometric.Affine(rotate=(-45, 45), scale=(0.5, 1.2),translate_percent=(-0.2, 0.2), seed=SEED),\n",
        "                augmenters.geometric.Rot90(k=(1, 3), seed=SEED),\n",
        "                augmenters.arithmetic.Dropout(p=(0, 0.05), seed=SEED),\n",
        "                augmenters.arithmetic.SaltAndPepper(p=(0, 0.05), seed=SEED),\n",
        "                augmenters.color.MultiplyBrightness(mul=(0.5, 1.5)),\n",
        "                augmenters.color.MultiplySaturation(mul=(0, 5), seed=SEED),\n",
        "                augmenters.iaa_convolutional.Sharpen(alpha=(0.75, 1), lightness=(0.75, 1.25), seed=SEED),\n",
        "                augmenters.iaa_convolutional.Emboss(alpha=(0.75, 1), strength=(0.75, 1.25), seed=SEED),\n",
        "                augmenters.contrast.CLAHE(seed=SEED),\n",
        "                augmenters.contrast.GammaContrast(gamma=(0.2, 5), seed=SEED), \n",
        "                ])\n",
        "            ])\n",
        "\n",
        "\n",
        "    p_image, n_image = preprocess(cv2.imread(os.path.join(path, p_name), cv2.IMREAD_COLOR)), preprocess(cv2.imread(os.path.join(path, n_name), cv2.IMREAD_COLOR))\n",
        "    p_images, n_images = np.array(dataset_augment(images=[p_image for _ in range(num_samples)])), np.array(dataset_augment(images=[n_image for _ in range(num_samples)]))\n",
        "\n",
        "    fea_extractor = build_feature_extractor()\n",
        "    fea_extractor.to(DEVICE)\n",
        "\n",
        "    # Positive Features\n",
        "    feature_data_setup = FEDS(X=p_images, transform=TRANSFORM)\n",
        "    feature_data = DL(feature_data_setup, batch_size=batch_size, shuffle=False)\n",
        "    p_features = torch.zeros(num_samples, FEATURE_VECTOR_LENGTH).to(DEVICE)\n",
        "    for i, X in enumerate(feature_data):\n",
        "        X = X.to(DEVICE)\n",
        "        with torch.no_grad():\n",
        "            output = fea_extractor(X)\n",
        "        p_features[i * batch_size : (i * batch_size) + output.shape[0], :] = output\n",
        "    p_features = normalize(p_features).detach().cpu().numpy()\n",
        "\n",
        "\n",
        "    # Negative Features\n",
        "    feature_data_setup = FEDS(X=n_images, transform=TRANSFORM)\n",
        "    feature_data = DL(feature_data_setup, batch_size=batch_size, shuffle=False)\n",
        "    n_features = torch.zeros(num_samples, FEATURE_VECTOR_LENGTH).to(DEVICE)\n",
        "    for i, X in enumerate(feature_data):\n",
        "        X = X.to(DEVICE)\n",
        "        with torch.no_grad():\n",
        "            output = fea_extractor(X)\n",
        "        n_features[i * batch_size : (i * batch_size) + output.shape[0], :] = output\n",
        "    n_features = normalize(n_features).detach().cpu().numpy()\n",
        "    \n",
        "    features = np.concatenate((p_features, n_features), axis=0)\n",
        "    labels = np.concatenate((np.ones((len(p_features), ), dtype=np.uint8), np.zeros((len(n_features), ), dtype=np.uint8)), axis=0)\n",
        "\n",
        "    np.random.seed(SEED)\n",
        "    np.random.shuffle(features)\n",
        "\n",
        "    np.random.seed(SEED)\n",
        "    np.random.shuffle(labels)\n",
        "\n",
        "    del fea_extractor, p_images, n_images, p_image, n_image\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return features, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvFVSsLQr5wB"
      },
      "source": [
        "# Machine Learning Models Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnXLPrmsFrdf"
      },
      "source": [
        "class MLModels(object):\n",
        "    def __init__(self, model_name: str):\n",
        "        self.model_name = model_name\n",
        "        self.model = None\n",
        "    \n",
        "        if re.match(r\"lgr\", self.model_name, re.IGNORECASE):\n",
        "            self.model = LogisticRegression(random_state=SEED)\n",
        "        elif re.match(r\"gnb\", self.model_name, re.IGNORECASE):\n",
        "            self.model = GaussianNB()\n",
        "        elif re.match(r\"knc\", self.model_name, re.IGNORECASE):\n",
        "            self.model = KNeighborsClassifier()\n",
        "        elif re.match(r\"dtc\", self.model_name, re.IGNORECASE):\n",
        "            self.model = DecisionTreeClassifier(random_state=SEED)\n",
        "        elif re.match(r\"rfc\", self.model_name, re.IGNORECASE):\n",
        "            self.model = RandomForestClassifier(random_state=SEED)\n",
        "        elif re.match(r\"xgc\", self.model_name, re.IGNORECASE):\n",
        "            self.model = XGBClassifier(tree_method=\"gpu_hist\", random_state=SEED)\n",
        "        else:\n",
        "            raise NotImplementedError(\"Invalid Model Name\")\n",
        "    \n",
        "\n",
        "    def fit_model(self, features, labels):\n",
        "        breaker()\n",
        "        print(\"Running -{}- Model ...\".format(self.model_name))\n",
        "        tr_feat, va_feat, tr_label, va_label = train_test_split(features, labels, test_size=SPLIT, shuffle=True, random_state=SEED)\n",
        "        self.model.fit(tr_feat, tr_label)\n",
        "        y_pred = self.model.predict(va_feat)\n",
        "        breaker()\n",
        "        print(\"-{}- Accuracy : {:.5f}\".format(self.model_name, accuracy_score(y_pred, va_label)))\n",
        "        filename = \"{}_Model.pkl\".format(self.model_name)\n",
        "        pickle.dump(self.model, open(os.path.join(\"/content/\", filename), \"wb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8njLlPasACP"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtlYk37tr_lo",
        "outputId": "38f4449b-d6f7-40d7-91ea-fff7aa7aff48"
      },
      "source": [
        "def main():\n",
        "    num_samples = 15000\n",
        "    batch_size = 128\n",
        "\n",
        "    features, labels = build_features(num_samples=num_samples, batch_size=batch_size, path=\"/content/\", p_name=\"P.png\", n_name=\"N.png\")\n",
        "\n",
        "    model_names = [\"lgr\", \"gnb\", \"knc\", \"dtc\", \"rfc\", \"xgc\"]\n",
        "\n",
        "    for model_name in model_names:\n",
        "        model = MLModels(model_name=model_name)\n",
        "        model.fit_model(features, labels)\n",
        "        print(\"\\t\\t ---------- \")\n",
        "    breaker()\n",
        "main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "**************************************************\n",
            "\n",
            "Building Features ...\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Running -lgr- Model ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "**************************************************\n",
            "\n",
            "-lgr- Accuracy : 0.96833\n",
            "\t\t ---------- \n",
            "\n",
            "**************************************************\n",
            "\n",
            "Running -gnb- Model ...\n",
            "\n",
            "**************************************************\n",
            "\n",
            "-gnb- Accuracy : 0.86500\n",
            "\t\t ---------- \n",
            "\n",
            "**************************************************\n",
            "\n",
            "Running -knc- Model ...\n",
            "\n",
            "**************************************************\n",
            "\n",
            "-knc- Accuracy : 0.93583\n",
            "\t\t ---------- \n",
            "\n",
            "**************************************************\n",
            "\n",
            "Running -dtc- Model ...\n",
            "\n",
            "**************************************************\n",
            "\n",
            "-dtc- Accuracy : 0.83183\n",
            "\t\t ---------- \n",
            "\n",
            "**************************************************\n",
            "\n",
            "Running -rfc- Model ...\n",
            "\n",
            "**************************************************\n",
            "\n",
            "-rfc- Accuracy : 0.94867\n",
            "\t\t ---------- \n",
            "\n",
            "**************************************************\n",
            "\n",
            "Running -xgc- Model ...\n",
            "\n",
            "**************************************************\n",
            "\n",
            "-xgc- Accuracy : 0.93867\n",
            "\t\t ---------- \n",
            "\n",
            "**************************************************\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imrSvN45330J"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}