{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Triplet Network",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNFKTYIe20BLcP6DiIVJWrE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/123prashanth123/Fault-Detection-System/blob/main/Triplet%20Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yy84xoWw5FQ4"
      },
      "source": [
        "# NoteBook Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9KQypTq49Uv"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "\n",
        "!pip install --upgrade imgaug\n",
        "!pip install imagecorruptions\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQo3Xw5d5IJD"
      },
      "source": [
        "# Imports and Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbpldKNJ5Jsm"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim, FloatTensor\n",
        "from torchvision import models, transforms, ops\n",
        "from torch.utils.data import DataLoader as DL\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import imgaug\n",
        "from imgaug import augmenters\n",
        "from sklearn.model_selection import KFold\n",
        "from termcolor import colored\n",
        "\n",
        "import os\n",
        "import re\n",
        "import cv2\n",
        "import random as r\n",
        "from time import time\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qfaqi4mc5M7d"
      },
      "source": [
        "SEED = 0\n",
        "STANDARD_SIZE = 224\n",
        "FV = 2048\n",
        "\n",
        "EMBED = 128\n",
        "\n",
        "DS_PATH = \"/content/gdrive/My Drive/Videos/\"\n",
        "\n",
        "\n",
        "def breaker(num=50, char=\"*\"):\n",
        "    print(colored(\"\\n\" + num*char + \"\\n\", color=\"red\"))\n",
        "\n",
        "\n",
        "def normalize(x=None):\n",
        "    for i in range(x.shape[0]):\n",
        "        x[i] = (x[i] - torch.min(x[i]))/(torch.max(x[i]) - torch.min(x[i]))\n",
        "    return x\n",
        "\n",
        "\n",
        "def timeit(func):\n",
        "    start_time = time()\n",
        "    func\n",
        "    breaker()\n",
        "    print(\"Time Taken : {:.2f} minutes\".format((time()-start_time)/60))\n",
        "    breaker()\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTjdQRst5Pmb"
      },
      "source": [
        "# Build Pretrained Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlKIBEpz5OgN"
      },
      "source": [
        "def build_pretrained():\n",
        "    breaker()\n",
        "    print(\"Building Pretrained Models ...\")\n",
        "\n",
        "    class RoIExtractor(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(RoIExtractor, self).__init__()\n",
        "            self.model = models.detection.fasterrcnn_mobilenet_v3_large_320_fpn(pretrained=True, progress=True)\n",
        "        \n",
        "        def forward(self, x):\n",
        "            return self.model(x)\n",
        "\n",
        "\n",
        "    class FeatureExtractor(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(FeatureExtractor, self).__init__()\n",
        "\n",
        "            self.model = models.resnet50(pretrained=True, progress=True)\n",
        "            for params in self.model.parameters():\n",
        "                params.requires_grad = False\n",
        "            self.model = nn.Sequential(*[*self.model.children()][:-1])\n",
        "        \n",
        "        def forward(self, x):\n",
        "            return self.model(x)\n",
        "\n",
        "\n",
        "    roi_extractor = RoIExtractor().to(DEVICE)\n",
        "    roi_extractor.eval()\n",
        "    fea_extractor = FeatureExtractor().to(DEVICE)\n",
        "    fea_extractor.eval()\n",
        "\n",
        "    fea_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
        "                                                        std=[0.229, 0.224, 0.225]),\n",
        "                                ]) \n",
        "    roi_transform = transforms.Compose([transforms.ToTensor(),])\n",
        "\n",
        "    return fea_extractor, fea_transform, roi_extractor, roi_transform"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATbfzCUc5aNk"
      },
      "source": [
        "# Build Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haJGPZbm5cUp"
      },
      "source": [
        "def build_loaders(idx, batch_size, num_samples, triplet=True):\n",
        "    fea_extractor, fea_transform, roi_extractor, roi_transform = build_pretrained()\n",
        "\n",
        "    breaker()\n",
        "    print(\"Building Dataloaders ...\")\n",
        "\n",
        "    class FEDS(Dataset):\n",
        "        def __init__(self, X=None, transform=None):\n",
        "            self.transform = transform\n",
        "            self.X = X\n",
        "        \n",
        "        def __len__(self):\n",
        "            return self.X.shape[0]\n",
        "        \n",
        "        def __getitem__(self, idx):\n",
        "            return self.transform(self.X[idx])\n",
        "    \n",
        "\n",
        "    def get_anchor_image_and_features(idx, size=224):\n",
        "        names = [name for name in os.listdir(DS_PATH) if (name[-4:] == \".jpg\")]\n",
        "        image = cv2.cvtColor(cv2.imread(os.path.join(DS_PATH, names[idx]), cv2.IMREAD_COLOR), code=cv2.COLOR_BGR2RGB)\n",
        "        net_image = cv2.resize(image, dsize=(size, size), interpolation=cv2.INTER_AREA)\n",
        "        with torch.no_grad():\n",
        "            features = fea_extractor(fea_transform(net_image).to(DEVICE).unsqueeze(dim=0))[:, :, 0, 0]\n",
        "        return image, normalize(features).detach().cpu().numpy()\n",
        "\n",
        "\n",
        "    def make_data(size=224, num_samples=1000, cls=\"Positive\",\n",
        "                  roi_extractor=None, fea_extractor=None, roi_transform=None, fea_transform=None, \n",
        "                  device=\"cpu\", seed=0, feature_vector_size=512):\n",
        "        image, anchor = get_anchor_image_and_features(idx, size=STANDARD_SIZE)\n",
        "        image = cv2.resize(src=image, dsize=(size, size), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "        num_layers = 3\n",
        "        imgaug.seed(seed)\n",
        "        cropper_augment = augmenters.Sequential([augmenters.imgcorruptlike.GlassBlur(severity=(3, 5), seed=seed)] * num_layers)\n",
        "        \n",
        "        imgaug.seed(seed)\n",
        "        dataset_augment = augmenters.Sequential([\n",
        "            augmenters.HorizontalFlip(p=0.25),\n",
        "            augmenters.VerticalFlip(p=0.25),\n",
        "            augmenters.SomeOf(5, [\n",
        "                    augmenters.blur.GaussianBlur(sigma=(0, 5), seed=seed),\n",
        "                    augmenters.blur.MedianBlur(k=(1, 7), seed=seed),\n",
        "                    augmenters.size.Crop(percent=(0, 0.1), seed=seed),\n",
        "                    augmenters.geometric.Affine(rotate=(-45, 45), scale=(0.5, 1.2),translate_percent=(-0.2, 0.2), seed=seed),\n",
        "                    augmenters.geometric.Rot90(k=(1, 3), seed=seed),\n",
        "                    augmenters.arithmetic.Dropout(p=(0, 0.05), seed=seed),\n",
        "                    augmenters.arithmetic.SaltAndPepper(p=(0, 0.05), seed=seed),\n",
        "                    augmenters.color.MultiplyBrightness(mul=(0.5, 1.5)),\n",
        "                    augmenters.color.MultiplySaturation(mul=(0, 5), seed=seed),\n",
        "                    augmenters.iaa_convolutional.Sharpen(alpha=(0.75, 1), lightness=(0.75, 1.25), seed=seed),\n",
        "                    augmenters.iaa_convolutional.Emboss(alpha=(0.75, 1), strength=(0.75, 1.25), seed=seed),\n",
        "                    augmenters.contrast.CLAHE(seed=seed),\n",
        "                    augmenters.contrast.GammaContrast(gamma=(0.2, 5), seed=seed), \n",
        "                    ])\n",
        "                ])\n",
        "\n",
        "        if re.match(r\"Negative\", cls, re.IGNORECASE):\n",
        "            with torch.no_grad():\n",
        "                output = roi_extractor(roi_transform(image).to(device).unsqueeze(dim=0))\n",
        "            cnts, scrs = output[0][\"boxes\"], output[0][\"scores\"]\n",
        "            if len(cnts) != 0:\n",
        "                cnts = ops.clip_boxes_to_image(cnts, (image.shape[0], image.shape[1]))\n",
        "                best_index = ops.nms(cnts, scrs, 0.1)[0]\n",
        "\n",
        "                x1, y1, x2, y2 = int(cnts[best_index][0]), int(cnts[best_index][1]), int(cnts[best_index][2]), int(cnts[best_index][3])\n",
        "                crp_img = image[y1:y2, x1:x2]\n",
        "                crp_img = cropper_augment(images=np.expand_dims(crp_img, axis=0))\n",
        "                image[y1:y2, x1:x2] = crp_img.squeeze()\n",
        "\n",
        "        images = np.array(dataset_augment(images=[image for _ in range(num_samples)]))\n",
        "\n",
        "        batch_size = 128\n",
        "        feature_data_setup = FEDS(X=images, transform=fea_transform)\n",
        "        feature_data = DL(feature_data_setup, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "        features = torch.zeros(num_samples, feature_vector_size).to(device)\n",
        "\n",
        "        i = 0\n",
        "        for X in feature_data:\n",
        "            X = X.to(device)\n",
        "            with torch.no_grad():\n",
        "                output = fea_extractor(X)[:, :, 0, 0]\n",
        "            features[i * batch_size : (i * batch_size) + output.shape[0], :] = output\n",
        "            i += 1\n",
        "\n",
        "        return images, anchor, normalize(features).detach().cpu().numpy()\n",
        "    \n",
        "\n",
        "    _, anchor, p_features = make_data(size=STANDARD_SIZE, num_samples=num_samples, cls=\"Positive\",\n",
        "                                      roi_extractor=roi_extractor, fea_extractor=fea_extractor, \n",
        "                                      roi_transform=roi_transform, fea_transform=fea_transform, \n",
        "                                      device=DEVICE, seed=SEED, feature_vector_size=FV)\n",
        "    _, anchor, n_features = make_data(size=STANDARD_SIZE, num_samples=num_samples, cls=\"Negative\",\n",
        "                                      roi_extractor=roi_extractor, fea_extractor=fea_extractor, \n",
        "                                      roi_transform=roi_transform, fea_transform=fea_transform, \n",
        "                                      device=DEVICE, seed=SEED, feature_vector_size=FV)\n",
        "\n",
        "    np.random.seed(SEED)\n",
        "    class SiameseDS(Dataset):\n",
        "        def __init__(self, anchor, p_vector, n_vector):\n",
        "            self.anchor = anchor\n",
        "            self.p_vector = p_vector\n",
        "            self.n_vector = n_vector\n",
        "            \n",
        "        def __len__(self):\n",
        "            return self.p_vector.shape[0]\n",
        "            # return self.n_vector.shape[0]\n",
        "        \n",
        "        def __getitem__(self, idx):\n",
        "            return self.anchor, self.p_vector[idx], self.n_vector[idx]\n",
        "    \n",
        "    class DS(Dataset):\n",
        "        def __init__(self, p_vector=None, n_vector=None):\n",
        "            self.X = np.concatenate((p_vector, n_vector), axis=0)\n",
        "            self.y = np.concatenate((np.ones((p_vector.shape[0], 1)), np.zeros((n_vector.shape[0], 1))), axis=0)\n",
        "\n",
        "        def __len__(self):\n",
        "            return self.X.shape[0]\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            return torch.FloatTensor(self.X[idx]), torch.FloatTensor(self.y[idx])\n",
        "\n",
        "\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=SEED).split(p_features)\n",
        "    for tr_idx, va_idx in kf:\n",
        "        train_indices, valid_indices = tr_idx, va_idx\n",
        "        break\n",
        "    p_train, p_valid = p_features[train_indices], p_features[valid_indices]\n",
        "    n_train, n_valid = n_features[train_indices], n_features[valid_indices]\n",
        "\n",
        "    if triplet:\n",
        "        tr_data_setup = SiameseDS(anchor=anchor, p_vector=p_train, n_vector=n_train)\n",
        "        va_data_setup = SiameseDS(anchor=anchor, p_vector=p_valid, n_vector=n_valid)\n",
        "    else:\n",
        "        tr_data_setup = DS(p_vector=p_train, n_vector=n_train)\n",
        "        va_data_setup = DS(p_vector=p_valid, n_vector=n_valid)\n",
        "\n",
        "    dataloaders = {\"train\" : DL(tr_data_setup, batch_size=batch_size, shuffle=True, generator=torch.manual_seed(SEED)),\n",
        "                   \"valid\" : DL(va_data_setup, batch_size=batch_size, shuffle=False)\n",
        "                   }\n",
        "\n",
        "    return dataloaders"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz2qiwGb83zn"
      },
      "source": [
        "# Build Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiyHitCa80di"
      },
      "source": [
        "def build_embedder(embed=None):\n",
        "    breaker()\n",
        "    print(\"Building Embedding Network ...\")\n",
        "\n",
        "    class EmbeddingNetwork(nn.Module):\n",
        "        def __init__(self, IL=2048, embed=None):\n",
        "            super(EmbeddingNetwork, self).__init__()\n",
        "\n",
        "            self.embedder = nn.Sequential()\n",
        "            self.embedder.add_module(\"BN\", nn.BatchNorm1d(num_features=IL, eps=1e-5))\n",
        "            self.embedder.add_module(\"FC\", nn.Linear(in_features=IL, out_features=embed))\n",
        "            self.embedder.add_module(\"AN\", nn.ReLU())\n",
        "        \n",
        "        def getOptimizer(self, lr=1e-3, wd=0):\n",
        "            return optim.Adam(self.parameters(), lr=lr, weight_decay=wd)\n",
        "    \n",
        "        def forward(self, x1, x2=None, x3=None):\n",
        "            if x2 is not None and x3 is not None:\n",
        "                x1 = self.embedder(x1)\n",
        "                x2 = self.embedder(x2)\n",
        "                x3 = self.embedder(x3)\n",
        "                return x1, x2, x3\n",
        "            else:\n",
        "                return self.embedder(x1)\n",
        "    \n",
        "    model = EmbeddingNetwork(embed=embed)\n",
        "    return model\n",
        "\n",
        "def build_classifier(embedding_net=None, path=None, embed=None):\n",
        "    embedding_net.load_state_dict(torch.load(os.path.join(path, \"embedder_state.pt\"), map_location=DEVICE)[\"model_state_dict\"])\n",
        "    embedding_net.eval()\n",
        "    for params in embedding_net.parameters():\n",
        "        params.requires_grad = False\n",
        "    \n",
        "    breaker()\n",
        "    print(\"Building Classifier ...\")\n",
        "\n",
        "    class Network(nn.Module):\n",
        "        def __init__(self, embedding_net=None, embed=embed):\n",
        "            super(Network, self).__init__()\n",
        "\n",
        "            self.embedding_net = embedding_net\n",
        "        \n",
        "            self.classifier = nn.Sequential()\n",
        "            self.classifier.add_module(\"BN\", nn.BatchNorm1d(num_features=embed, eps=1e-5))\n",
        "            self.classifier.add_module(\"FC\", nn.Linear(in_features=embed, out_features=1))\n",
        "            self.classifier.add_module(\"AN\", nn.ReLU())\n",
        "        \n",
        "        def getOptimizer(self, lr=1e-3, wd=0):\n",
        "            p = [p for p in self.parameters() if p.requires_grad]\n",
        "            return optim.Adam(p, lr=lr, weight_decay=wd)\n",
        "    \n",
        "        def forward(self, x):\n",
        "            return self.classifier(self.embedding_net(x))\n",
        "    \n",
        "    model = Network(embedding_net=embedding_net, embed=embed)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hh1g_JsWaorX"
      },
      "source": [
        "# Embedder Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6BhNhtSatLF"
      },
      "source": [
        "def train_embedder(model, tr_data, va_data, epochs, lr, wd):\n",
        "\n",
        "    def fit_(model=None, optimizer=None, scheduler=None, epochs=None,\n",
        "             trainloader=None, validloader=None, criterion=None, device=None,\n",
        "             path=None, verbose=None):\n",
        "        breaker()\n",
        "        print(\"Training ...\")\n",
        "        breaker()\n",
        "\n",
        "        model.to(device)\n",
        "        Losses, Accuracies = [], []\n",
        "        bestLoss = {\"train\" : np.inf, \"valid\" : np.inf}\n",
        "        DLS = {\"train\" : trainloader, \"valid\" : validloader}\n",
        "\n",
        "        start_time = time()\n",
        "        for e in range(epochs):\n",
        "            e_st = time()\n",
        "            epochLoss = {\"train\" : 0.0, \"valid\" : 0.0}\n",
        "\n",
        "            for phase in [\"train\", \"valid\"]:\n",
        "                if phase == \"train\":\n",
        "                    model.train()\n",
        "                else:\n",
        "                    model.eval()\n",
        "                \n",
        "                lossPerPass = []\n",
        "\n",
        "                for A, P, N in DLS[phase]:\n",
        "                    A, P, N = A.to(DEVICE), P.to(DEVICE), N.to(DEVICE)\n",
        "\n",
        "                    optimizer.zero_grad()\n",
        "                    with torch.set_grad_enabled(phase == \"train\"):\n",
        "                        op_A, op_P, op_N = model(A.squeeze(), P, N)\n",
        "                        loss = criterion(op_A, op_P, op_N)\n",
        "                        if phase == \"train\":\n",
        "                            loss.backward()\n",
        "                            optimizer.step()\n",
        "                    lossPerPass.append(loss.item())\n",
        "                epochLoss[phase] = np.mean(np.array(lossPerPass))\n",
        "            Losses.append(epochLoss)\n",
        "            \n",
        "            if epochLoss[\"valid\"] < bestLoss[\"valid\"]:\n",
        "                bestLoss = epochLoss\n",
        "                BLE = e+1\n",
        "                torch.save({\"model_state_dict\" : model.state_dict(),\n",
        "                            \"optim_state_dict\" : optimizer.state_dict()},\n",
        "                            os.path.join(path, \"embedder_state.pt\"))\n",
        "            if scheduler:\n",
        "                scheduler.step(epochLoss[\"valid\"])\n",
        "            \n",
        "            if verbose:\n",
        "                print(\"Epoch: {} | Train Loss: {:.5f} | Valid Loss: {:.5f} | Time: {:.2f} seconds\".format(e + 1, epochLoss[\"train\"], epochLoss[\"valid\"], time() - e_st))\n",
        "\n",
        "        breaker()\n",
        "        print(\"Best Validation Loss at Epoch ---> {}\".format(BLE))\n",
        "        breaker()\n",
        "        print(\"Time Taken [{} Epochs] : {:.2f} minutes\".format(epochs, (time() - start_time) / 60))\n",
        "        breaker()\n",
        "        print(\"Training Completed\")\n",
        "        breaker()\n",
        "\n",
        "        return Losses, BLE\n",
        "    \n",
        "    optimizer = model.getOptimizer(lr=lr, wd=wd)\n",
        "    checkpoint_path = os.path.join(\"/content/embedder_checkpoints\")\n",
        "    if not os.path.exists(checkpoint_path):\n",
        "        os.makedirs(checkpoint_path)\n",
        "\n",
        "    L, BLE = fit_(model=model, optimizer=optimizer, scheduler=None, epochs=epochs,\n",
        "                  trainloader=tr_data, validloader=va_data, device=DEVICE,\n",
        "                  criterion=nn.TripletMarginLoss(margin=1.0), \n",
        "                  path=checkpoint_path, verbose=True)\n",
        "\n",
        "    TL, VL = [], []\n",
        "\n",
        "    for i in range(len(L)):\n",
        "        TL.append(L[i][\"train\"])\n",
        "        VL.append(L[i][\"valid\"])\n",
        "\n",
        "    x_Axis = np.arange(1, len(L)+1)\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(x_Axis, TL, \"r\", label=\"Training Loss\")\n",
        "    plt.plot(x_Axis, VL, \"b--\", label=\"Validation Loss\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "    return BLE, checkpoint_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eyNNpbpkbRE"
      },
      "source": [
        "# Classifier Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRCJBe6Qkbi7"
      },
      "source": [
        "def train_classifier(model, tr_data, va_data, epochs, lr, wd):\n",
        "\n",
        "    def fit_(model=None, optimizer=None, scheduler=None, epochs=None,\n",
        "             trainloader=None, validloader=None, criterion=None, device=None,\n",
        "             path=None, verbose=None):\n",
        "        breaker()\n",
        "        print(\"Training ...\")\n",
        "        breaker()\n",
        "\n",
        "        model.to(device)\n",
        "        Losses, Accuracies = [], []\n",
        "        bestLoss, bestAccs = {\"train\" : np.inf, \"valid\" : np.inf}, {\"train\" : 0.0, \"valid\" : 0.0}\n",
        "        DLS = {\"train\" : trainloader, \"valid\" : validloader}\n",
        "\n",
        "        start_time = time()\n",
        "        for e in range(epochs):\n",
        "            e_st = time()\n",
        "            epochLoss = {\"train\" : 0.0, \"valid\" : 0.0}\n",
        "            epochAccs = {\"train\" : 0.0, \"valid\" : 0.0}\n",
        "\n",
        "            for phase in [\"train\", \"valid\"]:\n",
        "                if phase == \"train\":\n",
        "                    model.train()\n",
        "                else:\n",
        "                    model.eval()\n",
        "                \n",
        "                lossPerPass, accsPerPass = [], []\n",
        "\n",
        "                for X, y in DLS[phase]:\n",
        "                    X, y = X.to(device), y.to(device)\n",
        "\n",
        "                    optimizer.zero_grad()\n",
        "                    with torch.set_grad_enabled(phase == \"train\"):\n",
        "                        output = model(X)\n",
        "                        loss = criterion(output, y)\n",
        "                        if phase == \"train\":\n",
        "                            loss.backward()\n",
        "                            optimizer.step()\n",
        "                    lossPerPass.append(loss.item())\n",
        "                    accsPerPass.append(getAccuracy(output, y))\n",
        "                epochLoss[phase] = np.mean(np.array(lossPerPass))\n",
        "                epochAccs[phase] = np.mean(np.array(accsPerPass))\n",
        "            Losses.append(epochLoss)\n",
        "            Accuracies.append(epochAccs)\n",
        "            \n",
        "            if epochLoss[\"valid\"] < bestLoss[\"valid\"]:\n",
        "                bestLoss = epochLoss\n",
        "                BLE = e+1\n",
        "                torch.save({\"model_state_dict\" : model.state_dict(),\n",
        "                            \"optim_state_dict\" : optimizer.state_dict()},\n",
        "                            os.path.join(path, \"classifier_state.pt\"))\n",
        "            \n",
        "            if epochAccs[\"valid\"] > bestAccs[\"valid\"]:\n",
        "                bestAccs = epochAccs\n",
        "                BAE = e+1\n",
        "            \n",
        "            if scheduler:\n",
        "                scheduler.step(epochLoss[\"valid\"])\n",
        "            \n",
        "            if verbose:\n",
        "                print(\"Epoch: {} | Train Loss: {:.5f} | Valid Loss: {:.5f} | Train Accs : {:.5f} | \\\n",
        "Valid Accs : {:.5f} | Time: {:.2f} seconds\".format(e + 1,\n",
        "                                                    epochLoss[\"train\"], epochLoss[\"valid\"],\n",
        "                                                    epochAccs[\"train\"], epochAccs[\"valid\"],\n",
        "                                                    time() - e_st))\n",
        "\n",
        "\n",
        "\n",
        "        breaker()\n",
        "        print(\"Best Validation Loss at Epoch ---> {}\".format(BLE))\n",
        "        breaker()\n",
        "        print(\"Best Validation Accs at Epoch ---> {}\".format(BAE))\n",
        "        breaker()\n",
        "        print(\"Time Taken [{} Epochs] : {:.2f} minutes\".format(epochs, (time() - start_time) / 60))\n",
        "        breaker()\n",
        "        print(\"Training Completed\")\n",
        "        breaker()\n",
        "\n",
        "        return Losses, Accuracies, BLE, BAE\n",
        "\n",
        "\n",
        "    def getAccuracy(y_pred=None, y_true=None):\n",
        "        y_pred, y_true = torch.sigmoid(y_pred).detach(), y_true.detach()\n",
        "\n",
        "        y_pred[y_pred > 0.5] = 1\n",
        "        y_pred[y_pred <= 0.5] = 0\n",
        "\n",
        "        return torch.count_nonzero(y_pred == y_true).item() / len(y_pred)\n",
        "    \n",
        "    optimizer = model.getOptimizer(lr=lr, wd=wd)\n",
        "    checkpoint_path = os.path.join(\"/content/classifier_checkpoints\")\n",
        "    if not os.path.exists(checkpoint_path):\n",
        "        os.makedirs(checkpoint_path)\n",
        "\n",
        "    L, A, BLE, BAE = fit_(model=model, optimizer=optimizer, scheduler=None, epochs=epochs,\n",
        "                          trainloader=tr_data, validloader=va_data, device=DEVICE,\n",
        "                          criterion=nn.BCEWithLogitsLoss(),\n",
        "                          path=checkpoint_path, verbose=True)\n",
        "\n",
        "    TL, VL, TA, VA = [], [], [], []\n",
        "\n",
        "    for i in range(len(L)):\n",
        "        TL.append(L[i][\"train\"])\n",
        "        VL.append(L[i][\"valid\"])\n",
        "        TA.append(A[i][\"train\"])\n",
        "        VA.append(A[i][\"valid\"])\n",
        "\n",
        "    x_Axis = np.arange(1, len(L)+1)\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(x_Axis, TL, \"r\", label=\"Training Loss\")\n",
        "    plt.plot(x_Axis, VL, \"b--\", label=\"Validation Loss\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(x_Axis, TA, \"r\", label=\"Training Accuracy\")\n",
        "    plt.plot(x_Axis, VA, \"b--\", label=\"Validation Accuracy\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "    return BLE, checkpoint_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWTrDfvTkaAM"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WRGrZOy3bFr8",
        "outputId": "b9966739-81af-47b2-99fd-ca7926ccb478"
      },
      "source": [
        "def main():\n",
        "    ###\n",
        "    num_samples = 10000\n",
        "    batch_size = 512\n",
        "    epochs = 1000\n",
        "    e_lr, e_wd = 1e-6, 1e-6\n",
        "    c_lr, c_wd = 1e-3, 1e-5\n",
        "    ###\n",
        "\n",
        "    dataloaders = build_loaders(1, batch_size=batch_size, num_samples=num_samples, triplet=True)\n",
        "    embedder = build_embedder(embed=EMBED)\n",
        "    _, path = train_embedder(embedder, dataloaders[\"train\"], dataloaders[\"valid\"], epochs, e_lr, e_wd)\n",
        "\n",
        "    dataloaders = build_loaders(1, batch_size=batch_size, num_samples=num_samples, triplet=False)\n",
        "    classifier = build_classifier(embedder, path, embed=EMBED)\n",
        "    _, path = train_classifier(classifier, dataloaders[\"train\"], dataloaders[\"valid\"], epochs, c_lr, c_wd)\n",
        "\n",
        "    return classifier, path\n",
        "\n",
        "classifier, path = main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31m\n",
            "**************************************************\n",
            "\u001b[0m\n",
            "Building Pretrained Models ...\n",
            "\u001b[31m\n",
            "**************************************************\n",
            "\u001b[0m\n",
            "Building Dataloaders ...\n",
            "\u001b[31m\n",
            "**************************************************\n",
            "\u001b[0m\n",
            "Building Embedding Network ...\n",
            "\u001b[31m\n",
            "**************************************************\n",
            "\u001b[0m\n",
            "Training ...\n",
            "\u001b[31m\n",
            "**************************************************\n",
            "\u001b[0m\n",
            "Epoch: 1 | Train Loss: 1.25745 | Valid Loss: 0.72538 | Time: 0.23 seconds\n",
            "Epoch: 2 | Train Loss: 1.23371 | Valid Loss: 0.74150 | Time: 0.22 seconds\n",
            "Epoch: 3 | Train Loss: 1.21139 | Valid Loss: 0.73274 | Time: 0.21 seconds\n",
            "Epoch: 4 | Train Loss: 1.18611 | Valid Loss: 0.72548 | Time: 0.21 seconds\n",
            "Epoch: 5 | Train Loss: 1.16374 | Valid Loss: 0.72153 | Time: 0.22 seconds\n",
            "Epoch: 6 | Train Loss: 1.14199 | Valid Loss: 0.71425 | Time: 0.23 seconds\n",
            "Epoch: 7 | Train Loss: 1.11767 | Valid Loss: 0.70707 | Time: 0.22 seconds\n",
            "Epoch: 8 | Train Loss: 1.09885 | Valid Loss: 0.69599 | Time: 0.23 seconds\n",
            "Epoch: 9 | Train Loss: 1.07410 | Valid Loss: 0.68744 | Time: 0.23 seconds\n",
            "Epoch: 10 | Train Loss: 1.05462 | Valid Loss: 0.68340 | Time: 0.23 seconds\n",
            "Epoch: 11 | Train Loss: 1.03016 | Valid Loss: 0.67506 | Time: 0.22 seconds\n",
            "Epoch: 12 | Train Loss: 1.00959 | Valid Loss: 0.66968 | Time: 0.23 seconds\n",
            "Epoch: 13 | Train Loss: 0.98998 | Valid Loss: 0.65805 | Time: 0.23 seconds\n",
            "Epoch: 14 | Train Loss: 0.96748 | Valid Loss: 0.65190 | Time: 0.23 seconds\n",
            "Epoch: 15 | Train Loss: 0.94832 | Valid Loss: 0.63753 | Time: 0.23 seconds\n",
            "Epoch: 16 | Train Loss: 0.92707 | Valid Loss: 0.63486 | Time: 0.23 seconds\n",
            "Epoch: 17 | Train Loss: 0.90496 | Valid Loss: 0.62515 | Time: 0.32 seconds\n",
            "Epoch: 18 | Train Loss: 0.88592 | Valid Loss: 0.61806 | Time: 0.23 seconds\n",
            "Epoch: 19 | Train Loss: 0.86586 | Valid Loss: 0.60839 | Time: 0.23 seconds\n",
            "Epoch: 20 | Train Loss: 0.84654 | Valid Loss: 0.59872 | Time: 0.23 seconds\n",
            "Epoch: 21 | Train Loss: 0.82747 | Valid Loss: 0.58885 | Time: 0.23 seconds\n",
            "Epoch: 22 | Train Loss: 0.80618 | Valid Loss: 0.58536 | Time: 0.23 seconds\n",
            "Epoch: 23 | Train Loss: 0.78870 | Valid Loss: 0.57946 | Time: 0.24 seconds\n",
            "Epoch: 24 | Train Loss: 0.76883 | Valid Loss: 0.56908 | Time: 0.23 seconds\n",
            "Epoch: 25 | Train Loss: 0.75067 | Valid Loss: 0.56064 | Time: 0.23 seconds\n",
            "Epoch: 26 | Train Loss: 0.73210 | Valid Loss: 0.55520 | Time: 0.23 seconds\n",
            "Epoch: 27 | Train Loss: 0.71520 | Valid Loss: 0.54697 | Time: 0.23 seconds\n",
            "Epoch: 28 | Train Loss: 0.69692 | Valid Loss: 0.54388 | Time: 0.23 seconds\n",
            "Epoch: 29 | Train Loss: 0.67946 | Valid Loss: 0.53609 | Time: 0.23 seconds\n",
            "Epoch: 30 | Train Loss: 0.66267 | Valid Loss: 0.52846 | Time: 0.23 seconds\n",
            "Epoch: 31 | Train Loss: 0.64730 | Valid Loss: 0.52108 | Time: 0.24 seconds\n",
            "Epoch: 32 | Train Loss: 0.63007 | Valid Loss: 0.51471 | Time: 0.23 seconds\n",
            "Epoch: 33 | Train Loss: 0.61505 | Valid Loss: 0.51263 | Time: 0.23 seconds\n",
            "Epoch: 34 | Train Loss: 0.59717 | Valid Loss: 0.51286 | Time: 0.22 seconds\n",
            "Epoch: 35 | Train Loss: 0.58365 | Valid Loss: 0.50843 | Time: 0.22 seconds\n",
            "Epoch: 36 | Train Loss: 0.56982 | Valid Loss: 0.50163 | Time: 0.24 seconds\n",
            "Epoch: 37 | Train Loss: 0.55692 | Valid Loss: 0.49963 | Time: 0.23 seconds\n",
            "Epoch: 38 | Train Loss: 0.54174 | Valid Loss: 0.50242 | Time: 0.22 seconds\n",
            "Epoch: 39 | Train Loss: 0.52800 | Valid Loss: 0.49414 | Time: 0.23 seconds\n",
            "Epoch: 40 | Train Loss: 0.51468 | Valid Loss: 0.49536 | Time: 0.25 seconds\n",
            "Epoch: 41 | Train Loss: 0.50162 | Valid Loss: 0.48974 | Time: 0.23 seconds\n",
            "Epoch: 42 | Train Loss: 0.48907 | Valid Loss: 0.48639 | Time: 0.22 seconds\n",
            "Epoch: 43 | Train Loss: 0.47675 | Valid Loss: 0.48777 | Time: 0.22 seconds\n",
            "Epoch: 44 | Train Loss: 0.46557 | Valid Loss: 0.48508 | Time: 0.22 seconds\n",
            "Epoch: 45 | Train Loss: 0.45226 | Valid Loss: 0.48614 | Time: 0.22 seconds\n",
            "Epoch: 46 | Train Loss: 0.44003 | Valid Loss: 0.48631 | Time: 0.22 seconds\n",
            "Epoch: 47 | Train Loss: 0.43065 | Valid Loss: 0.48562 | Time: 0.22 seconds\n",
            "Epoch: 48 | Train Loss: 0.42005 | Valid Loss: 0.48600 | Time: 0.22 seconds\n",
            "Epoch: 49 | Train Loss: 0.40873 | Valid Loss: 0.49235 | Time: 0.22 seconds\n",
            "Epoch: 50 | Train Loss: 0.39906 | Valid Loss: 0.48868 | Time: 0.23 seconds\n",
            "Epoch: 51 | Train Loss: 0.38926 | Valid Loss: 0.49301 | Time: 0.22 seconds\n",
            "Epoch: 52 | Train Loss: 0.38017 | Valid Loss: 0.49415 | Time: 0.22 seconds\n",
            "Epoch: 53 | Train Loss: 0.36983 | Valid Loss: 0.49142 | Time: 0.22 seconds\n",
            "Epoch: 54 | Train Loss: 0.35989 | Valid Loss: 0.49417 | Time: 0.22 seconds\n",
            "Epoch: 55 | Train Loss: 0.35197 | Valid Loss: 0.49927 | Time: 0.22 seconds\n",
            "Epoch: 56 | Train Loss: 0.34269 | Valid Loss: 0.50066 | Time: 0.21 seconds\n",
            "Epoch: 57 | Train Loss: 0.33207 | Valid Loss: 0.49685 | Time: 0.22 seconds\n",
            "Epoch: 58 | Train Loss: 0.32719 | Valid Loss: 0.49698 | Time: 0.22 seconds\n",
            "Epoch: 59 | Train Loss: 0.31894 | Valid Loss: 0.50092 | Time: 0.23 seconds\n",
            "Epoch: 60 | Train Loss: 0.31070 | Valid Loss: 0.50049 | Time: 0.29 seconds\n",
            "Epoch: 61 | Train Loss: 0.30303 | Valid Loss: 0.50614 | Time: 0.22 seconds\n",
            "Epoch: 62 | Train Loss: 0.29552 | Valid Loss: 0.50703 | Time: 0.22 seconds\n",
            "Epoch: 63 | Train Loss: 0.28710 | Valid Loss: 0.51295 | Time: 0.23 seconds\n",
            "Epoch: 64 | Train Loss: 0.28059 | Valid Loss: 0.51362 | Time: 0.22 seconds\n",
            "Epoch: 65 | Train Loss: 0.27308 | Valid Loss: 0.51602 | Time: 0.22 seconds\n",
            "Epoch: 66 | Train Loss: 0.26936 | Valid Loss: 0.51483 | Time: 0.22 seconds\n",
            "Epoch: 67 | Train Loss: 0.25868 | Valid Loss: 0.52292 | Time: 0.23 seconds\n",
            "Epoch: 68 | Train Loss: 0.25371 | Valid Loss: 0.51789 | Time: 0.22 seconds\n",
            "Epoch: 69 | Train Loss: 0.24786 | Valid Loss: 0.52216 | Time: 0.21 seconds\n",
            "Epoch: 70 | Train Loss: 0.24218 | Valid Loss: 0.52196 | Time: 0.22 seconds\n",
            "Epoch: 71 | Train Loss: 0.23621 | Valid Loss: 0.52779 | Time: 0.21 seconds\n",
            "Epoch: 72 | Train Loss: 0.23066 | Valid Loss: 0.53361 | Time: 0.22 seconds\n",
            "Epoch: 73 | Train Loss: 0.22342 | Valid Loss: 0.52791 | Time: 0.22 seconds\n",
            "Epoch: 74 | Train Loss: 0.22044 | Valid Loss: 0.52942 | Time: 0.22 seconds\n",
            "Epoch: 75 | Train Loss: 0.21311 | Valid Loss: 0.53284 | Time: 0.22 seconds\n",
            "Epoch: 76 | Train Loss: 0.20867 | Valid Loss: 0.52981 | Time: 0.22 seconds\n",
            "Epoch: 77 | Train Loss: 0.20492 | Valid Loss: 0.53485 | Time: 0.22 seconds\n",
            "Epoch: 78 | Train Loss: 0.19984 | Valid Loss: 0.53699 | Time: 0.23 seconds\n",
            "Epoch: 79 | Train Loss: 0.19434 | Valid Loss: 0.53227 | Time: 0.22 seconds\n",
            "Epoch: 80 | Train Loss: 0.18937 | Valid Loss: 0.53548 | Time: 0.22 seconds\n",
            "Epoch: 81 | Train Loss: 0.18552 | Valid Loss: 0.53526 | Time: 0.22 seconds\n",
            "Epoch: 82 | Train Loss: 0.18072 | Valid Loss: 0.53355 | Time: 0.22 seconds\n",
            "Epoch: 83 | Train Loss: 0.17696 | Valid Loss: 0.54112 | Time: 0.22 seconds\n",
            "Epoch: 84 | Train Loss: 0.17315 | Valid Loss: 0.54316 | Time: 0.21 seconds\n",
            "Epoch: 85 | Train Loss: 0.16829 | Valid Loss: 0.54144 | Time: 0.22 seconds\n",
            "Epoch: 86 | Train Loss: 0.16556 | Valid Loss: 0.54180 | Time: 0.23 seconds\n",
            "Epoch: 87 | Train Loss: 0.16096 | Valid Loss: 0.53993 | Time: 0.21 seconds\n",
            "Epoch: 88 | Train Loss: 0.15748 | Valid Loss: 0.54182 | Time: 0.22 seconds\n",
            "Epoch: 89 | Train Loss: 0.15309 | Valid Loss: 0.54065 | Time: 0.21 seconds\n",
            "Epoch: 90 | Train Loss: 0.14983 | Valid Loss: 0.54485 | Time: 0.21 seconds\n",
            "Epoch: 91 | Train Loss: 0.14711 | Valid Loss: 0.53648 | Time: 0.22 seconds\n",
            "Epoch: 92 | Train Loss: 0.14387 | Valid Loss: 0.54289 | Time: 0.22 seconds\n",
            "Epoch: 93 | Train Loss: 0.14119 | Valid Loss: 0.54301 | Time: 0.22 seconds\n",
            "Epoch: 94 | Train Loss: 0.13949 | Valid Loss: 0.54553 | Time: 0.22 seconds\n",
            "Epoch: 95 | Train Loss: 0.13378 | Valid Loss: 0.53801 | Time: 0.23 seconds\n",
            "Epoch: 96 | Train Loss: 0.13111 | Valid Loss: 0.53866 | Time: 0.22 seconds\n",
            "Epoch: 97 | Train Loss: 0.12860 | Valid Loss: 0.53178 | Time: 0.22 seconds\n",
            "Epoch: 98 | Train Loss: 0.12480 | Valid Loss: 0.54330 | Time: 0.23 seconds\n",
            "Epoch: 99 | Train Loss: 0.12378 | Valid Loss: 0.53772 | Time: 0.22 seconds\n",
            "Epoch: 100 | Train Loss: 0.11968 | Valid Loss: 0.54184 | Time: 0.22 seconds\n",
            "Epoch: 101 | Train Loss: 0.11773 | Valid Loss: 0.54579 | Time: 0.22 seconds\n",
            "Epoch: 102 | Train Loss: 0.11610 | Valid Loss: 0.54208 | Time: 0.22 seconds\n",
            "Epoch: 103 | Train Loss: 0.11241 | Valid Loss: 0.54073 | Time: 0.30 seconds\n",
            "Epoch: 104 | Train Loss: 0.11037 | Valid Loss: 0.53671 | Time: 0.22 seconds\n",
            "Epoch: 105 | Train Loss: 0.10708 | Valid Loss: 0.54139 | Time: 0.22 seconds\n",
            "Epoch: 106 | Train Loss: 0.10564 | Valid Loss: 0.53334 | Time: 0.22 seconds\n",
            "Epoch: 107 | Train Loss: 0.10284 | Valid Loss: 0.53273 | Time: 0.21 seconds\n",
            "Epoch: 108 | Train Loss: 0.10150 | Valid Loss: 0.53645 | Time: 0.22 seconds\n",
            "Epoch: 109 | Train Loss: 0.09940 | Valid Loss: 0.53703 | Time: 0.23 seconds\n",
            "Epoch: 110 | Train Loss: 0.09709 | Valid Loss: 0.53974 | Time: 0.22 seconds\n",
            "Epoch: 111 | Train Loss: 0.09550 | Valid Loss: 0.53961 | Time: 0.23 seconds\n",
            "Epoch: 112 | Train Loss: 0.09353 | Valid Loss: 0.53720 | Time: 0.22 seconds\n",
            "Epoch: 113 | Train Loss: 0.09156 | Valid Loss: 0.53836 | Time: 0.22 seconds\n",
            "Epoch: 114 | Train Loss: 0.09014 | Valid Loss: 0.52342 | Time: 0.22 seconds\n",
            "Epoch: 115 | Train Loss: 0.08741 | Valid Loss: 0.53761 | Time: 0.22 seconds\n",
            "Epoch: 116 | Train Loss: 0.08458 | Valid Loss: 0.53081 | Time: 0.22 seconds\n",
            "Epoch: 117 | Train Loss: 0.08393 | Valid Loss: 0.52673 | Time: 0.22 seconds\n",
            "Epoch: 118 | Train Loss: 0.08158 | Valid Loss: 0.53166 | Time: 0.22 seconds\n",
            "Epoch: 119 | Train Loss: 0.07957 | Valid Loss: 0.52787 | Time: 0.22 seconds\n",
            "Epoch: 120 | Train Loss: 0.07829 | Valid Loss: 0.53107 | Time: 0.22 seconds\n",
            "Epoch: 121 | Train Loss: 0.07643 | Valid Loss: 0.53121 | Time: 0.22 seconds\n",
            "Epoch: 122 | Train Loss: 0.07599 | Valid Loss: 0.52856 | Time: 0.22 seconds\n",
            "Epoch: 123 | Train Loss: 0.07468 | Valid Loss: 0.52898 | Time: 0.22 seconds\n",
            "Epoch: 124 | Train Loss: 0.07386 | Valid Loss: 0.52048 | Time: 0.22 seconds\n",
            "Epoch: 125 | Train Loss: 0.07196 | Valid Loss: 0.52385 | Time: 0.22 seconds\n",
            "Epoch: 126 | Train Loss: 0.07075 | Valid Loss: 0.52166 | Time: 0.22 seconds\n",
            "Epoch: 127 | Train Loss: 0.06947 | Valid Loss: 0.52023 | Time: 0.22 seconds\n",
            "Epoch: 128 | Train Loss: 0.06735 | Valid Loss: 0.51850 | Time: 0.22 seconds\n",
            "Epoch: 129 | Train Loss: 0.06645 | Valid Loss: 0.52712 | Time: 0.22 seconds\n",
            "Epoch: 130 | Train Loss: 0.06413 | Valid Loss: 0.51725 | Time: 0.22 seconds\n",
            "Epoch: 131 | Train Loss: 0.06428 | Valid Loss: 0.52251 | Time: 0.22 seconds\n",
            "Epoch: 132 | Train Loss: 0.06263 | Valid Loss: 0.51886 | Time: 0.22 seconds\n",
            "Epoch: 133 | Train Loss: 0.06091 | Valid Loss: 0.52094 | Time: 0.22 seconds\n",
            "Epoch: 134 | Train Loss: 0.06109 | Valid Loss: 0.51931 | Time: 0.21 seconds\n",
            "Epoch: 135 | Train Loss: 0.05962 | Valid Loss: 0.51888 | Time: 0.22 seconds\n",
            "Epoch: 136 | Train Loss: 0.05817 | Valid Loss: 0.51667 | Time: 0.22 seconds\n",
            "Epoch: 137 | Train Loss: 0.05726 | Valid Loss: 0.51602 | Time: 0.22 seconds\n",
            "Epoch: 138 | Train Loss: 0.05532 | Valid Loss: 0.51698 | Time: 0.23 seconds\n",
            "Epoch: 139 | Train Loss: 0.05505 | Valid Loss: 0.51907 | Time: 0.23 seconds\n",
            "Epoch: 140 | Train Loss: 0.05472 | Valid Loss: 0.51625 | Time: 0.22 seconds\n",
            "Epoch: 141 | Train Loss: 0.05222 | Valid Loss: 0.51318 | Time: 0.22 seconds\n",
            "Epoch: 142 | Train Loss: 0.05163 | Valid Loss: 0.51777 | Time: 0.22 seconds\n",
            "Epoch: 143 | Train Loss: 0.05276 | Valid Loss: 0.51586 | Time: 0.23 seconds\n",
            "Epoch: 144 | Train Loss: 0.04983 | Valid Loss: 0.51008 | Time: 0.22 seconds\n",
            "Epoch: 145 | Train Loss: 0.04900 | Valid Loss: 0.51302 | Time: 0.22 seconds\n",
            "Epoch: 146 | Train Loss: 0.04918 | Valid Loss: 0.50875 | Time: 0.29 seconds\n",
            "Epoch: 147 | Train Loss: 0.04817 | Valid Loss: 0.51164 | Time: 0.22 seconds\n",
            "Epoch: 148 | Train Loss: 0.04693 | Valid Loss: 0.51167 | Time: 0.22 seconds\n",
            "Epoch: 149 | Train Loss: 0.04618 | Valid Loss: 0.50723 | Time: 0.22 seconds\n",
            "Epoch: 150 | Train Loss: 0.04503 | Valid Loss: 0.51590 | Time: 0.22 seconds\n",
            "Epoch: 151 | Train Loss: 0.04484 | Valid Loss: 0.51047 | Time: 0.22 seconds\n",
            "Epoch: 152 | Train Loss: 0.04399 | Valid Loss: 0.51146 | Time: 0.23 seconds\n",
            "Epoch: 153 | Train Loss: 0.04323 | Valid Loss: 0.50042 | Time: 0.22 seconds\n",
            "Epoch: 154 | Train Loss: 0.04264 | Valid Loss: 0.50693 | Time: 0.22 seconds\n",
            "Epoch: 155 | Train Loss: 0.04177 | Valid Loss: 0.51002 | Time: 0.23 seconds\n",
            "Epoch: 156 | Train Loss: 0.04145 | Valid Loss: 0.50066 | Time: 0.22 seconds\n",
            "Epoch: 157 | Train Loss: 0.04082 | Valid Loss: 0.50125 | Time: 0.23 seconds\n",
            "Epoch: 158 | Train Loss: 0.03900 | Valid Loss: 0.50137 | Time: 0.22 seconds\n",
            "Epoch: 159 | Train Loss: 0.03889 | Valid Loss: 0.50451 | Time: 0.23 seconds\n",
            "Epoch: 160 | Train Loss: 0.03826 | Valid Loss: 0.49959 | Time: 0.22 seconds\n",
            "Epoch: 161 | Train Loss: 0.03778 | Valid Loss: 0.50282 | Time: 0.22 seconds\n",
            "Epoch: 162 | Train Loss: 0.03760 | Valid Loss: 0.49787 | Time: 0.22 seconds\n",
            "Epoch: 163 | Train Loss: 0.03636 | Valid Loss: 0.50080 | Time: 0.22 seconds\n",
            "Epoch: 164 | Train Loss: 0.03582 | Valid Loss: 0.49266 | Time: 0.22 seconds\n",
            "Epoch: 165 | Train Loss: 0.03486 | Valid Loss: 0.50078 | Time: 0.22 seconds\n",
            "Epoch: 166 | Train Loss: 0.03471 | Valid Loss: 0.49988 | Time: 0.22 seconds\n",
            "Epoch: 167 | Train Loss: 0.03476 | Valid Loss: 0.49436 | Time: 0.22 seconds\n",
            "Epoch: 168 | Train Loss: 0.03355 | Valid Loss: 0.49445 | Time: 0.22 seconds\n",
            "Epoch: 169 | Train Loss: 0.03309 | Valid Loss: 0.49296 | Time: 0.22 seconds\n",
            "Epoch: 170 | Train Loss: 0.03221 | Valid Loss: 0.49306 | Time: 0.22 seconds\n",
            "Epoch: 171 | Train Loss: 0.03156 | Valid Loss: 0.49768 | Time: 0.22 seconds\n",
            "Epoch: 172 | Train Loss: 0.03149 | Valid Loss: 0.49016 | Time: 0.22 seconds\n",
            "Epoch: 173 | Train Loss: 0.03132 | Valid Loss: 0.48902 | Time: 0.22 seconds\n",
            "Epoch: 174 | Train Loss: 0.03077 | Valid Loss: 0.48877 | Time: 0.22 seconds\n",
            "Epoch: 175 | Train Loss: 0.02966 | Valid Loss: 0.48909 | Time: 0.22 seconds\n",
            "Epoch: 176 | Train Loss: 0.02950 | Valid Loss: 0.48766 | Time: 0.22 seconds\n",
            "Epoch: 177 | Train Loss: 0.02879 | Valid Loss: 0.48777 | Time: 0.22 seconds\n",
            "Epoch: 178 | Train Loss: 0.02895 | Valid Loss: 0.48407 | Time: 0.23 seconds\n",
            "Epoch: 179 | Train Loss: 0.02871 | Valid Loss: 0.48568 | Time: 0.22 seconds\n",
            "Epoch: 180 | Train Loss: 0.02812 | Valid Loss: 0.48155 | Time: 0.23 seconds\n",
            "Epoch: 181 | Train Loss: 0.02703 | Valid Loss: 0.48677 | Time: 0.22 seconds\n",
            "Epoch: 182 | Train Loss: 0.02779 | Valid Loss: 0.48651 | Time: 0.22 seconds\n",
            "Epoch: 183 | Train Loss: 0.02732 | Valid Loss: 0.48411 | Time: 0.22 seconds\n",
            "Epoch: 184 | Train Loss: 0.02590 | Valid Loss: 0.48255 | Time: 0.22 seconds\n",
            "Epoch: 185 | Train Loss: 0.02599 | Valid Loss: 0.48344 | Time: 0.22 seconds\n",
            "Epoch: 186 | Train Loss: 0.02509 | Valid Loss: 0.48088 | Time: 0.23 seconds\n",
            "Epoch: 187 | Train Loss: 0.02544 | Valid Loss: 0.48581 | Time: 0.22 seconds\n",
            "Epoch: 188 | Train Loss: 0.02476 | Valid Loss: 0.47768 | Time: 0.22 seconds\n",
            "Epoch: 189 | Train Loss: 0.02442 | Valid Loss: 0.48755 | Time: 0.29 seconds\n",
            "Epoch: 190 | Train Loss: 0.02397 | Valid Loss: 0.48317 | Time: 0.22 seconds\n",
            "Epoch: 191 | Train Loss: 0.02308 | Valid Loss: 0.48049 | Time: 0.22 seconds\n",
            "Epoch: 192 | Train Loss: 0.02350 | Valid Loss: 0.48242 | Time: 0.22 seconds\n",
            "Epoch: 193 | Train Loss: 0.02293 | Valid Loss: 0.48108 | Time: 0.22 seconds\n",
            "Epoch: 194 | Train Loss: 0.02246 | Valid Loss: 0.47490 | Time: 0.22 seconds\n",
            "Epoch: 195 | Train Loss: 0.02233 | Valid Loss: 0.47975 | Time: 0.23 seconds\n",
            "Epoch: 196 | Train Loss: 0.02196 | Valid Loss: 0.47270 | Time: 0.23 seconds\n",
            "Epoch: 197 | Train Loss: 0.02211 | Valid Loss: 0.48154 | Time: 0.22 seconds\n",
            "Epoch: 198 | Train Loss: 0.02122 | Valid Loss: 0.47330 | Time: 0.22 seconds\n",
            "Epoch: 199 | Train Loss: 0.02071 | Valid Loss: 0.47982 | Time: 0.22 seconds\n",
            "Epoch: 200 | Train Loss: 0.02042 | Valid Loss: 0.47181 | Time: 0.23 seconds\n",
            "Epoch: 201 | Train Loss: 0.02004 | Valid Loss: 0.47072 | Time: 0.24 seconds\n",
            "Epoch: 202 | Train Loss: 0.02024 | Valid Loss: 0.47885 | Time: 0.22 seconds\n",
            "Epoch: 203 | Train Loss: 0.01945 | Valid Loss: 0.47633 | Time: 0.22 seconds\n",
            "Epoch: 204 | Train Loss: 0.01921 | Valid Loss: 0.47424 | Time: 0.23 seconds\n",
            "Epoch: 205 | Train Loss: 0.01942 | Valid Loss: 0.47317 | Time: 0.22 seconds\n",
            "Epoch: 206 | Train Loss: 0.01931 | Valid Loss: 0.46722 | Time: 0.23 seconds\n",
            "Epoch: 207 | Train Loss: 0.01906 | Valid Loss: 0.46807 | Time: 0.22 seconds\n",
            "Epoch: 208 | Train Loss: 0.01807 | Valid Loss: 0.47156 | Time: 0.22 seconds\n",
            "Epoch: 209 | Train Loss: 0.01811 | Valid Loss: 0.47724 | Time: 0.22 seconds\n",
            "Epoch: 210 | Train Loss: 0.01759 | Valid Loss: 0.47460 | Time: 0.22 seconds\n",
            "Epoch: 211 | Train Loss: 0.01732 | Valid Loss: 0.47036 | Time: 0.22 seconds\n",
            "Epoch: 212 | Train Loss: 0.01742 | Valid Loss: 0.46459 | Time: 0.23 seconds\n",
            "Epoch: 213 | Train Loss: 0.01829 | Valid Loss: 0.47146 | Time: 0.23 seconds\n",
            "Epoch: 214 | Train Loss: 0.01636 | Valid Loss: 0.47097 | Time: 0.22 seconds\n",
            "Epoch: 215 | Train Loss: 0.01643 | Valid Loss: 0.46257 | Time: 0.23 seconds\n",
            "Epoch: 216 | Train Loss: 0.01619 | Valid Loss: 0.46285 | Time: 0.22 seconds\n",
            "Epoch: 217 | Train Loss: 0.01587 | Valid Loss: 0.46728 | Time: 0.23 seconds\n",
            "Epoch: 218 | Train Loss: 0.01659 | Valid Loss: 0.46185 | Time: 0.23 seconds\n",
            "Epoch: 219 | Train Loss: 0.01499 | Valid Loss: 0.46586 | Time: 0.22 seconds\n",
            "Epoch: 220 | Train Loss: 0.01543 | Valid Loss: 0.45728 | Time: 0.23 seconds\n",
            "Epoch: 221 | Train Loss: 0.01547 | Valid Loss: 0.45996 | Time: 0.24 seconds\n",
            "Epoch: 222 | Train Loss: 0.01443 | Valid Loss: 0.46547 | Time: 0.24 seconds\n",
            "Epoch: 223 | Train Loss: 0.01494 | Valid Loss: 0.46754 | Time: 0.23 seconds\n",
            "Epoch: 224 | Train Loss: 0.01390 | Valid Loss: 0.45931 | Time: 0.24 seconds\n",
            "Epoch: 225 | Train Loss: 0.01379 | Valid Loss: 0.46070 | Time: 0.22 seconds\n",
            "Epoch: 226 | Train Loss: 0.01448 | Valid Loss: 0.46506 | Time: 0.23 seconds\n",
            "Epoch: 227 | Train Loss: 0.01370 | Valid Loss: 0.45849 | Time: 0.22 seconds\n",
            "Epoch: 228 | Train Loss: 0.01386 | Valid Loss: 0.46112 | Time: 0.22 seconds\n",
            "Epoch: 229 | Train Loss: 0.01406 | Valid Loss: 0.45882 | Time: 0.22 seconds\n",
            "Epoch: 230 | Train Loss: 0.01373 | Valid Loss: 0.45616 | Time: 0.23 seconds\n",
            "Epoch: 231 | Train Loss: 0.01293 | Valid Loss: 0.45409 | Time: 0.31 seconds\n",
            "Epoch: 232 | Train Loss: 0.01323 | Valid Loss: 0.45945 | Time: 0.23 seconds\n",
            "Epoch: 233 | Train Loss: 0.01297 | Valid Loss: 0.45270 | Time: 0.23 seconds\n",
            "Epoch: 234 | Train Loss: 0.01277 | Valid Loss: 0.45910 | Time: 0.22 seconds\n",
            "Epoch: 235 | Train Loss: 0.01208 | Valid Loss: 0.45112 | Time: 0.23 seconds\n",
            "Epoch: 236 | Train Loss: 0.01224 | Valid Loss: 0.45798 | Time: 0.22 seconds\n",
            "Epoch: 237 | Train Loss: 0.01194 | Valid Loss: 0.45671 | Time: 0.22 seconds\n",
            "Epoch: 238 | Train Loss: 0.01198 | Valid Loss: 0.45858 | Time: 0.22 seconds\n",
            "Epoch: 239 | Train Loss: 0.01183 | Valid Loss: 0.45563 | Time: 0.22 seconds\n",
            "Epoch: 240 | Train Loss: 0.01136 | Valid Loss: 0.45394 | Time: 0.22 seconds\n",
            "Epoch: 241 | Train Loss: 0.01186 | Valid Loss: 0.45548 | Time: 0.22 seconds\n",
            "Epoch: 242 | Train Loss: 0.01096 | Valid Loss: 0.44642 | Time: 0.23 seconds\n",
            "Epoch: 243 | Train Loss: 0.01109 | Valid Loss: 0.45279 | Time: 0.22 seconds\n",
            "Epoch: 244 | Train Loss: 0.01061 | Valid Loss: 0.45577 | Time: 0.22 seconds\n",
            "Epoch: 245 | Train Loss: 0.01089 | Valid Loss: 0.45138 | Time: 0.21 seconds\n",
            "Epoch: 246 | Train Loss: 0.01028 | Valid Loss: 0.45108 | Time: 0.22 seconds\n",
            "Epoch: 247 | Train Loss: 0.01030 | Valid Loss: 0.45208 | Time: 0.22 seconds\n",
            "Epoch: 248 | Train Loss: 0.01081 | Valid Loss: 0.45395 | Time: 0.22 seconds\n",
            "Epoch: 249 | Train Loss: 0.01034 | Valid Loss: 0.45892 | Time: 0.24 seconds\n",
            "Epoch: 250 | Train Loss: 0.01014 | Valid Loss: 0.44392 | Time: 0.23 seconds\n",
            "Epoch: 251 | Train Loss: 0.01006 | Valid Loss: 0.45107 | Time: 0.22 seconds\n",
            "Epoch: 252 | Train Loss: 0.00957 | Valid Loss: 0.45084 | Time: 0.22 seconds\n",
            "Epoch: 253 | Train Loss: 0.00944 | Valid Loss: 0.45096 | Time: 0.23 seconds\n",
            "Epoch: 254 | Train Loss: 0.00978 | Valid Loss: 0.44518 | Time: 0.22 seconds\n",
            "Epoch: 255 | Train Loss: 0.00944 | Valid Loss: 0.44688 | Time: 0.22 seconds\n",
            "Epoch: 256 | Train Loss: 0.00934 | Valid Loss: 0.45061 | Time: 0.22 seconds\n",
            "Epoch: 257 | Train Loss: 0.00901 | Valid Loss: 0.44855 | Time: 0.23 seconds\n",
            "Epoch: 258 | Train Loss: 0.00883 | Valid Loss: 0.45221 | Time: 0.22 seconds\n",
            "Epoch: 259 | Train Loss: 0.00904 | Valid Loss: 0.44223 | Time: 0.22 seconds\n",
            "Epoch: 260 | Train Loss: 0.00865 | Valid Loss: 0.44888 | Time: 0.22 seconds\n",
            "Epoch: 261 | Train Loss: 0.00860 | Valid Loss: 0.44383 | Time: 0.22 seconds\n",
            "Epoch: 262 | Train Loss: 0.00884 | Valid Loss: 0.45147 | Time: 0.22 seconds\n",
            "Epoch: 263 | Train Loss: 0.00823 | Valid Loss: 0.44926 | Time: 0.22 seconds\n",
            "Epoch: 264 | Train Loss: 0.00823 | Valid Loss: 0.45715 | Time: 0.22 seconds\n",
            "Epoch: 265 | Train Loss: 0.00791 | Valid Loss: 0.45067 | Time: 0.22 seconds\n",
            "Epoch: 266 | Train Loss: 0.00787 | Valid Loss: 0.44694 | Time: 0.22 seconds\n",
            "Epoch: 267 | Train Loss: 0.00797 | Valid Loss: 0.44730 | Time: 0.22 seconds\n",
            "Epoch: 268 | Train Loss: 0.00802 | Valid Loss: 0.45258 | Time: 0.22 seconds\n",
            "Epoch: 269 | Train Loss: 0.00778 | Valid Loss: 0.44073 | Time: 0.23 seconds\n",
            "Epoch: 270 | Train Loss: 0.00736 | Valid Loss: 0.45008 | Time: 0.22 seconds\n",
            "Epoch: 271 | Train Loss: 0.00753 | Valid Loss: 0.44389 | Time: 0.23 seconds\n",
            "Epoch: 272 | Train Loss: 0.00725 | Valid Loss: 0.44959 | Time: 0.23 seconds\n",
            "Epoch: 273 | Train Loss: 0.00725 | Valid Loss: 0.44822 | Time: 0.22 seconds\n",
            "Epoch: 274 | Train Loss: 0.00736 | Valid Loss: 0.43982 | Time: 0.29 seconds\n",
            "Epoch: 275 | Train Loss: 0.00706 | Valid Loss: 0.44673 | Time: 0.23 seconds\n",
            "Epoch: 276 | Train Loss: 0.00686 | Valid Loss: 0.44687 | Time: 0.22 seconds\n",
            "Epoch: 277 | Train Loss: 0.00697 | Valid Loss: 0.44828 | Time: 0.22 seconds\n",
            "Epoch: 278 | Train Loss: 0.00687 | Valid Loss: 0.44530 | Time: 0.22 seconds\n",
            "Epoch: 279 | Train Loss: 0.00674 | Valid Loss: 0.44149 | Time: 0.21 seconds\n",
            "Epoch: 280 | Train Loss: 0.00651 | Valid Loss: 0.44786 | Time: 0.23 seconds\n",
            "Epoch: 281 | Train Loss: 0.00673 | Valid Loss: 0.44560 | Time: 0.22 seconds\n",
            "Epoch: 282 | Train Loss: 0.00631 | Valid Loss: 0.45051 | Time: 0.22 seconds\n",
            "Epoch: 283 | Train Loss: 0.00664 | Valid Loss: 0.44777 | Time: 0.22 seconds\n",
            "Epoch: 284 | Train Loss: 0.00649 | Valid Loss: 0.44130 | Time: 0.22 seconds\n",
            "Epoch: 285 | Train Loss: 0.00639 | Valid Loss: 0.45447 | Time: 0.23 seconds\n",
            "Epoch: 286 | Train Loss: 0.00635 | Valid Loss: 0.45324 | Time: 0.23 seconds\n",
            "Epoch: 287 | Train Loss: 0.00600 | Valid Loss: 0.44652 | Time: 0.22 seconds\n",
            "Epoch: 288 | Train Loss: 0.00634 | Valid Loss: 0.45521 | Time: 0.22 seconds\n",
            "Epoch: 289 | Train Loss: 0.00592 | Valid Loss: 0.44581 | Time: 0.22 seconds\n",
            "Epoch: 290 | Train Loss: 0.00608 | Valid Loss: 0.44522 | Time: 0.22 seconds\n",
            "Epoch: 291 | Train Loss: 0.00566 | Valid Loss: 0.44665 | Time: 0.22 seconds\n",
            "Epoch: 292 | Train Loss: 0.00517 | Valid Loss: 0.44857 | Time: 0.22 seconds\n",
            "Epoch: 293 | Train Loss: 0.00543 | Valid Loss: 0.44754 | Time: 0.22 seconds\n",
            "Epoch: 294 | Train Loss: 0.00553 | Valid Loss: 0.44205 | Time: 0.22 seconds\n",
            "Epoch: 295 | Train Loss: 0.00540 | Valid Loss: 0.44310 | Time: 0.22 seconds\n",
            "Epoch: 296 | Train Loss: 0.00528 | Valid Loss: 0.44782 | Time: 0.22 seconds\n",
            "Epoch: 297 | Train Loss: 0.00522 | Valid Loss: 0.44413 | Time: 0.22 seconds\n",
            "Epoch: 298 | Train Loss: 0.00523 | Valid Loss: 0.44956 | Time: 0.22 seconds\n",
            "Epoch: 299 | Train Loss: 0.00517 | Valid Loss: 0.44378 | Time: 0.23 seconds\n",
            "Epoch: 300 | Train Loss: 0.00490 | Valid Loss: 0.45245 | Time: 0.23 seconds\n",
            "Epoch: 301 | Train Loss: 0.00532 | Valid Loss: 0.44073 | Time: 0.23 seconds\n",
            "Epoch: 302 | Train Loss: 0.00476 | Valid Loss: 0.44608 | Time: 0.22 seconds\n",
            "Epoch: 303 | Train Loss: 0.00460 | Valid Loss: 0.44941 | Time: 0.22 seconds\n",
            "Epoch: 304 | Train Loss: 0.00449 | Valid Loss: 0.44017 | Time: 0.22 seconds\n",
            "Epoch: 305 | Train Loss: 0.00482 | Valid Loss: 0.44641 | Time: 0.23 seconds\n",
            "Epoch: 306 | Train Loss: 0.00451 | Valid Loss: 0.44884 | Time: 0.22 seconds\n",
            "Epoch: 307 | Train Loss: 0.00461 | Valid Loss: 0.44316 | Time: 0.22 seconds\n",
            "Epoch: 308 | Train Loss: 0.00452 | Valid Loss: 0.43942 | Time: 0.24 seconds\n",
            "Epoch: 309 | Train Loss: 0.00439 | Valid Loss: 0.44218 | Time: 0.22 seconds\n",
            "Epoch: 310 | Train Loss: 0.00480 | Valid Loss: 0.44618 | Time: 0.22 seconds\n",
            "Epoch: 311 | Train Loss: 0.00413 | Valid Loss: 0.43811 | Time: 0.23 seconds\n",
            "Epoch: 312 | Train Loss: 0.00440 | Valid Loss: 0.44776 | Time: 0.22 seconds\n",
            "Epoch: 313 | Train Loss: 0.00415 | Valid Loss: 0.44838 | Time: 0.22 seconds\n",
            "Epoch: 314 | Train Loss: 0.00415 | Valid Loss: 0.43955 | Time: 0.22 seconds\n",
            "Epoch: 315 | Train Loss: 0.00430 | Valid Loss: 0.45549 | Time: 0.22 seconds\n",
            "Epoch: 316 | Train Loss: 0.00430 | Valid Loss: 0.44646 | Time: 0.22 seconds\n",
            "Epoch: 317 | Train Loss: 0.00375 | Valid Loss: 0.44543 | Time: 0.29 seconds\n",
            "Epoch: 318 | Train Loss: 0.00391 | Valid Loss: 0.44484 | Time: 0.22 seconds\n",
            "Epoch: 319 | Train Loss: 0.00378 | Valid Loss: 0.44126 | Time: 0.22 seconds\n",
            "Epoch: 320 | Train Loss: 0.00360 | Valid Loss: 0.44696 | Time: 0.23 seconds\n",
            "Epoch: 321 | Train Loss: 0.00356 | Valid Loss: 0.44750 | Time: 0.22 seconds\n",
            "Epoch: 322 | Train Loss: 0.00379 | Valid Loss: 0.44118 | Time: 0.22 seconds\n",
            "Epoch: 323 | Train Loss: 0.00337 | Valid Loss: 0.44828 | Time: 0.22 seconds\n",
            "Epoch: 324 | Train Loss: 0.00365 | Valid Loss: 0.44061 | Time: 0.22 seconds\n",
            "Epoch: 325 | Train Loss: 0.00355 | Valid Loss: 0.44671 | Time: 0.22 seconds\n",
            "Epoch: 326 | Train Loss: 0.00331 | Valid Loss: 0.44666 | Time: 0.22 seconds\n",
            "Epoch: 327 | Train Loss: 0.00347 | Valid Loss: 0.44398 | Time: 0.22 seconds\n",
            "Epoch: 328 | Train Loss: 0.00336 | Valid Loss: 0.44770 | Time: 0.22 seconds\n",
            "Epoch: 329 | Train Loss: 0.00316 | Valid Loss: 0.44180 | Time: 0.22 seconds\n",
            "Epoch: 330 | Train Loss: 0.00316 | Valid Loss: 0.44650 | Time: 0.22 seconds\n",
            "Epoch: 331 | Train Loss: 0.00358 | Valid Loss: 0.43620 | Time: 0.23 seconds\n",
            "Epoch: 332 | Train Loss: 0.00327 | Valid Loss: 0.44728 | Time: 0.22 seconds\n",
            "Epoch: 333 | Train Loss: 0.00293 | Valid Loss: 0.44076 | Time: 0.21 seconds\n",
            "Epoch: 334 | Train Loss: 0.00308 | Valid Loss: 0.44604 | Time: 0.22 seconds\n",
            "Epoch: 335 | Train Loss: 0.00306 | Valid Loss: 0.45081 | Time: 0.22 seconds\n",
            "Epoch: 336 | Train Loss: 0.00289 | Valid Loss: 0.44307 | Time: 0.22 seconds\n",
            "Epoch: 337 | Train Loss: 0.00312 | Valid Loss: 0.44694 | Time: 0.22 seconds\n",
            "Epoch: 338 | Train Loss: 0.00336 | Valid Loss: 0.44608 | Time: 0.22 seconds\n",
            "Epoch: 339 | Train Loss: 0.00280 | Valid Loss: 0.44719 | Time: 0.22 seconds\n",
            "Epoch: 340 | Train Loss: 0.00276 | Valid Loss: 0.44518 | Time: 0.22 seconds\n",
            "Epoch: 341 | Train Loss: 0.00270 | Valid Loss: 0.44146 | Time: 0.22 seconds\n",
            "Epoch: 342 | Train Loss: 0.00255 | Valid Loss: 0.43943 | Time: 0.22 seconds\n",
            "Epoch: 343 | Train Loss: 0.00277 | Valid Loss: 0.44938 | Time: 0.22 seconds\n",
            "Epoch: 344 | Train Loss: 0.00266 | Valid Loss: 0.44550 | Time: 0.22 seconds\n",
            "Epoch: 345 | Train Loss: 0.00260 | Valid Loss: 0.44350 | Time: 0.22 seconds\n",
            "Epoch: 346 | Train Loss: 0.00301 | Valid Loss: 0.44380 | Time: 0.21 seconds\n",
            "Epoch: 347 | Train Loss: 0.00272 | Valid Loss: 0.44381 | Time: 0.22 seconds\n",
            "Epoch: 348 | Train Loss: 0.00237 | Valid Loss: 0.44822 | Time: 0.22 seconds\n",
            "Epoch: 349 | Train Loss: 0.00272 | Valid Loss: 0.44543 | Time: 0.23 seconds\n",
            "Epoch: 350 | Train Loss: 0.00252 | Valid Loss: 0.44636 | Time: 0.22 seconds\n",
            "Epoch: 351 | Train Loss: 0.00233 | Valid Loss: 0.44199 | Time: 0.22 seconds\n",
            "Epoch: 352 | Train Loss: 0.00256 | Valid Loss: 0.44647 | Time: 0.22 seconds\n",
            "Epoch: 353 | Train Loss: 0.00250 | Valid Loss: 0.44506 | Time: 0.23 seconds\n",
            "Epoch: 354 | Train Loss: 0.00246 | Valid Loss: 0.44366 | Time: 0.22 seconds\n",
            "Epoch: 355 | Train Loss: 0.00231 | Valid Loss: 0.44511 | Time: 0.22 seconds\n",
            "Epoch: 356 | Train Loss: 0.00209 | Valid Loss: 0.44771 | Time: 0.22 seconds\n",
            "Epoch: 357 | Train Loss: 0.00230 | Valid Loss: 0.44315 | Time: 0.22 seconds\n",
            "Epoch: 358 | Train Loss: 0.00214 | Valid Loss: 0.44571 | Time: 0.23 seconds\n",
            "Epoch: 359 | Train Loss: 0.00253 | Valid Loss: 0.44748 | Time: 0.22 seconds\n",
            "Epoch: 360 | Train Loss: 0.00205 | Valid Loss: 0.44966 | Time: 0.29 seconds\n",
            "Epoch: 361 | Train Loss: 0.00200 | Valid Loss: 0.44613 | Time: 0.23 seconds\n",
            "Epoch: 362 | Train Loss: 0.00215 | Valid Loss: 0.44594 | Time: 0.23 seconds\n",
            "Epoch: 363 | Train Loss: 0.00218 | Valid Loss: 0.44443 | Time: 0.22 seconds\n",
            "Epoch: 364 | Train Loss: 0.00230 | Valid Loss: 0.44841 | Time: 0.22 seconds\n",
            "Epoch: 365 | Train Loss: 0.00213 | Valid Loss: 0.44701 | Time: 0.22 seconds\n",
            "Epoch: 366 | Train Loss: 0.00196 | Valid Loss: 0.44767 | Time: 0.23 seconds\n",
            "Epoch: 367 | Train Loss: 0.00169 | Valid Loss: 0.45147 | Time: 0.23 seconds\n",
            "Epoch: 368 | Train Loss: 0.00185 | Valid Loss: 0.44147 | Time: 0.23 seconds\n",
            "Epoch: 369 | Train Loss: 0.00173 | Valid Loss: 0.44433 | Time: 0.23 seconds\n",
            "Epoch: 370 | Train Loss: 0.00166 | Valid Loss: 0.44605 | Time: 0.23 seconds\n",
            "Epoch: 371 | Train Loss: 0.00201 | Valid Loss: 0.44639 | Time: 0.23 seconds\n",
            "Epoch: 372 | Train Loss: 0.00168 | Valid Loss: 0.44409 | Time: 0.23 seconds\n",
            "Epoch: 373 | Train Loss: 0.00181 | Valid Loss: 0.45091 | Time: 0.22 seconds\n",
            "Epoch: 374 | Train Loss: 0.00169 | Valid Loss: 0.44957 | Time: 0.23 seconds\n",
            "Epoch: 375 | Train Loss: 0.00162 | Valid Loss: 0.45291 | Time: 0.23 seconds\n",
            "Epoch: 376 | Train Loss: 0.00181 | Valid Loss: 0.44297 | Time: 0.22 seconds\n",
            "Epoch: 377 | Train Loss: 0.00179 | Valid Loss: 0.44927 | Time: 0.22 seconds\n",
            "Epoch: 378 | Train Loss: 0.00167 | Valid Loss: 0.44678 | Time: 0.22 seconds\n",
            "Epoch: 379 | Train Loss: 0.00173 | Valid Loss: 0.44403 | Time: 0.22 seconds\n",
            "Epoch: 380 | Train Loss: 0.00155 | Valid Loss: 0.44873 | Time: 0.22 seconds\n",
            "Epoch: 381 | Train Loss: 0.00169 | Valid Loss: 0.44603 | Time: 0.22 seconds\n",
            "Epoch: 382 | Train Loss: 0.00157 | Valid Loss: 0.44032 | Time: 0.22 seconds\n",
            "Epoch: 383 | Train Loss: 0.00156 | Valid Loss: 0.44502 | Time: 0.22 seconds\n",
            "Epoch: 384 | Train Loss: 0.00175 | Valid Loss: 0.44220 | Time: 0.22 seconds\n",
            "Epoch: 385 | Train Loss: 0.00139 | Valid Loss: 0.44471 | Time: 0.23 seconds\n",
            "Epoch: 386 | Train Loss: 0.00154 | Valid Loss: 0.44123 | Time: 0.22 seconds\n",
            "Epoch: 387 | Train Loss: 0.00132 | Valid Loss: 0.44535 | Time: 0.22 seconds\n",
            "Epoch: 388 | Train Loss: 0.00150 | Valid Loss: 0.44451 | Time: 0.22 seconds\n",
            "Epoch: 389 | Train Loss: 0.00137 | Valid Loss: 0.45040 | Time: 0.23 seconds\n",
            "Epoch: 390 | Train Loss: 0.00122 | Valid Loss: 0.44790 | Time: 0.22 seconds\n",
            "Epoch: 391 | Train Loss: 0.00134 | Valid Loss: 0.44476 | Time: 0.22 seconds\n",
            "Epoch: 392 | Train Loss: 0.00139 | Valid Loss: 0.44768 | Time: 0.22 seconds\n",
            "Epoch: 393 | Train Loss: 0.00117 | Valid Loss: 0.44293 | Time: 0.23 seconds\n",
            "Epoch: 394 | Train Loss: 0.00133 | Valid Loss: 0.44662 | Time: 0.23 seconds\n",
            "Epoch: 395 | Train Loss: 0.00118 | Valid Loss: 0.44930 | Time: 0.21 seconds\n",
            "Epoch: 396 | Train Loss: 0.00141 | Valid Loss: 0.44639 | Time: 0.22 seconds\n",
            "Epoch: 397 | Train Loss: 0.00130 | Valid Loss: 0.44488 | Time: 0.22 seconds\n",
            "Epoch: 398 | Train Loss: 0.00134 | Valid Loss: 0.44711 | Time: 0.24 seconds\n",
            "Epoch: 399 | Train Loss: 0.00131 | Valid Loss: 0.45057 | Time: 0.22 seconds\n",
            "Epoch: 400 | Train Loss: 0.00100 | Valid Loss: 0.44383 | Time: 0.22 seconds\n",
            "Epoch: 401 | Train Loss: 0.00116 | Valid Loss: 0.45315 | Time: 0.22 seconds\n",
            "Epoch: 402 | Train Loss: 0.00107 | Valid Loss: 0.44593 | Time: 0.22 seconds\n",
            "Epoch: 403 | Train Loss: 0.00112 | Valid Loss: 0.45002 | Time: 0.29 seconds\n",
            "Epoch: 404 | Train Loss: 0.00116 | Valid Loss: 0.44409 | Time: 0.23 seconds\n",
            "Epoch: 405 | Train Loss: 0.00096 | Valid Loss: 0.44804 | Time: 0.22 seconds\n",
            "Epoch: 406 | Train Loss: 0.00117 | Valid Loss: 0.44654 | Time: 0.22 seconds\n",
            "Epoch: 407 | Train Loss: 0.00109 | Valid Loss: 0.45472 | Time: 0.22 seconds\n",
            "Epoch: 408 | Train Loss: 0.00113 | Valid Loss: 0.45246 | Time: 0.22 seconds\n",
            "Epoch: 409 | Train Loss: 0.00110 | Valid Loss: 0.45281 | Time: 0.22 seconds\n",
            "Epoch: 410 | Train Loss: 0.00105 | Valid Loss: 0.45276 | Time: 0.21 seconds\n",
            "Epoch: 411 | Train Loss: 0.00099 | Valid Loss: 0.44821 | Time: 0.22 seconds\n",
            "Epoch: 412 | Train Loss: 0.00090 | Valid Loss: 0.45092 | Time: 0.22 seconds\n",
            "Epoch: 413 | Train Loss: 0.00091 | Valid Loss: 0.44539 | Time: 0.22 seconds\n",
            "Epoch: 414 | Train Loss: 0.00094 | Valid Loss: 0.44431 | Time: 0.21 seconds\n",
            "Epoch: 415 | Train Loss: 0.00101 | Valid Loss: 0.44558 | Time: 0.22 seconds\n",
            "Epoch: 416 | Train Loss: 0.00093 | Valid Loss: 0.44869 | Time: 0.22 seconds\n",
            "Epoch: 417 | Train Loss: 0.00107 | Valid Loss: 0.44929 | Time: 0.22 seconds\n",
            "Epoch: 418 | Train Loss: 0.00109 | Valid Loss: 0.45200 | Time: 0.21 seconds\n",
            "Epoch: 419 | Train Loss: 0.00085 | Valid Loss: 0.44110 | Time: 0.22 seconds\n",
            "Epoch: 420 | Train Loss: 0.00085 | Valid Loss: 0.45043 | Time: 0.22 seconds\n",
            "Epoch: 421 | Train Loss: 0.00103 | Valid Loss: 0.44676 | Time: 0.22 seconds\n",
            "Epoch: 422 | Train Loss: 0.00088 | Valid Loss: 0.44120 | Time: 0.22 seconds\n",
            "Epoch: 423 | Train Loss: 0.00121 | Valid Loss: 0.45020 | Time: 0.22 seconds\n",
            "Epoch: 424 | Train Loss: 0.00078 | Valid Loss: 0.44425 | Time: 0.22 seconds\n",
            "Epoch: 425 | Train Loss: 0.00070 | Valid Loss: 0.44757 | Time: 0.22 seconds\n",
            "Epoch: 426 | Train Loss: 0.00074 | Valid Loss: 0.44580 | Time: 0.22 seconds\n",
            "Epoch: 427 | Train Loss: 0.00079 | Valid Loss: 0.44921 | Time: 0.22 seconds\n",
            "Epoch: 428 | Train Loss: 0.00073 | Valid Loss: 0.44414 | Time: 0.22 seconds\n",
            "Epoch: 429 | Train Loss: 0.00063 | Valid Loss: 0.44021 | Time: 0.22 seconds\n",
            "Epoch: 430 | Train Loss: 0.00075 | Valid Loss: 0.44384 | Time: 0.22 seconds\n",
            "Epoch: 431 | Train Loss: 0.00072 | Valid Loss: 0.44925 | Time: 0.22 seconds\n",
            "Epoch: 432 | Train Loss: 0.00087 | Valid Loss: 0.44331 | Time: 0.21 seconds\n",
            "Epoch: 433 | Train Loss: 0.00070 | Valid Loss: 0.44447 | Time: 0.21 seconds\n",
            "Epoch: 434 | Train Loss: 0.00068 | Valid Loss: 0.44179 | Time: 0.22 seconds\n",
            "Epoch: 435 | Train Loss: 0.00082 | Valid Loss: 0.44641 | Time: 0.23 seconds\n",
            "Epoch: 436 | Train Loss: 0.00079 | Valid Loss: 0.43936 | Time: 0.22 seconds\n",
            "Epoch: 437 | Train Loss: 0.00062 | Valid Loss: 0.44363 | Time: 0.22 seconds\n",
            "Epoch: 438 | Train Loss: 0.00053 | Valid Loss: 0.44269 | Time: 0.22 seconds\n",
            "Epoch: 439 | Train Loss: 0.00052 | Valid Loss: 0.44355 | Time: 0.23 seconds\n",
            "Epoch: 440 | Train Loss: 0.00048 | Valid Loss: 0.44778 | Time: 0.22 seconds\n",
            "Epoch: 441 | Train Loss: 0.00051 | Valid Loss: 0.44875 | Time: 0.22 seconds\n",
            "Epoch: 442 | Train Loss: 0.00062 | Valid Loss: 0.44679 | Time: 0.22 seconds\n",
            "Epoch: 443 | Train Loss: 0.00079 | Valid Loss: 0.43987 | Time: 0.22 seconds\n",
            "Epoch: 444 | Train Loss: 0.00056 | Valid Loss: 0.44365 | Time: 0.23 seconds\n",
            "Epoch: 445 | Train Loss: 0.00052 | Valid Loss: 0.44406 | Time: 0.22 seconds\n",
            "Epoch: 446 | Train Loss: 0.00057 | Valid Loss: 0.44528 | Time: 0.29 seconds\n",
            "Epoch: 447 | Train Loss: 0.00053 | Valid Loss: 0.44194 | Time: 0.22 seconds\n",
            "Epoch: 448 | Train Loss: 0.00049 | Valid Loss: 0.44496 | Time: 0.22 seconds\n",
            "Epoch: 449 | Train Loss: 0.00054 | Valid Loss: 0.44443 | Time: 0.22 seconds\n",
            "Epoch: 450 | Train Loss: 0.00049 | Valid Loss: 0.44328 | Time: 0.23 seconds\n",
            "Epoch: 451 | Train Loss: 0.00039 | Valid Loss: 0.44429 | Time: 0.22 seconds\n",
            "Epoch: 452 | Train Loss: 0.00046 | Valid Loss: 0.44407 | Time: 0.22 seconds\n",
            "Epoch: 453 | Train Loss: 0.00060 | Valid Loss: 0.43971 | Time: 0.23 seconds\n",
            "Epoch: 454 | Train Loss: 0.00038 | Valid Loss: 0.44867 | Time: 0.22 seconds\n",
            "Epoch: 455 | Train Loss: 0.00073 | Valid Loss: 0.45048 | Time: 0.22 seconds\n",
            "Epoch: 456 | Train Loss: 0.00044 | Valid Loss: 0.44815 | Time: 0.22 seconds\n",
            "Epoch: 457 | Train Loss: 0.00046 | Valid Loss: 0.44218 | Time: 0.22 seconds\n",
            "Epoch: 458 | Train Loss: 0.00039 | Valid Loss: 0.44187 | Time: 0.22 seconds\n",
            "Epoch: 459 | Train Loss: 0.00041 | Valid Loss: 0.44289 | Time: 0.23 seconds\n",
            "Epoch: 460 | Train Loss: 0.00050 | Valid Loss: 0.44082 | Time: 0.22 seconds\n",
            "Epoch: 461 | Train Loss: 0.00032 | Valid Loss: 0.44094 | Time: 0.22 seconds\n",
            "Epoch: 462 | Train Loss: 0.00039 | Valid Loss: 0.44390 | Time: 0.23 seconds\n",
            "Epoch: 463 | Train Loss: 0.00036 | Valid Loss: 0.44734 | Time: 0.22 seconds\n",
            "Epoch: 464 | Train Loss: 0.00040 | Valid Loss: 0.43941 | Time: 0.23 seconds\n",
            "Epoch: 465 | Train Loss: 0.00050 | Valid Loss: 0.43879 | Time: 0.22 seconds\n",
            "Epoch: 466 | Train Loss: 0.00032 | Valid Loss: 0.44918 | Time: 0.23 seconds\n",
            "Epoch: 467 | Train Loss: 0.00033 | Valid Loss: 0.44206 | Time: 0.22 seconds\n",
            "Epoch: 468 | Train Loss: 0.00036 | Valid Loss: 0.44152 | Time: 0.22 seconds\n",
            "Epoch: 469 | Train Loss: 0.00042 | Valid Loss: 0.44422 | Time: 0.22 seconds\n",
            "Epoch: 470 | Train Loss: 0.00039 | Valid Loss: 0.44399 | Time: 0.22 seconds\n",
            "Epoch: 471 | Train Loss: 0.00038 | Valid Loss: 0.44520 | Time: 0.22 seconds\n",
            "Epoch: 472 | Train Loss: 0.00028 | Valid Loss: 0.44098 | Time: 0.22 seconds\n",
            "Epoch: 473 | Train Loss: 0.00043 | Valid Loss: 0.44094 | Time: 0.22 seconds\n",
            "Epoch: 474 | Train Loss: 0.00040 | Valid Loss: 0.44324 | Time: 0.22 seconds\n",
            "Epoch: 475 | Train Loss: 0.00024 | Valid Loss: 0.44211 | Time: 0.23 seconds\n",
            "Epoch: 476 | Train Loss: 0.00024 | Valid Loss: 0.44544 | Time: 0.23 seconds\n",
            "Epoch: 477 | Train Loss: 0.00034 | Valid Loss: 0.44737 | Time: 0.22 seconds\n",
            "Epoch: 478 | Train Loss: 0.00037 | Valid Loss: 0.44682 | Time: 0.22 seconds\n",
            "Epoch: 479 | Train Loss: 0.00029 | Valid Loss: 0.44231 | Time: 0.22 seconds\n",
            "Epoch: 480 | Train Loss: 0.00020 | Valid Loss: 0.44348 | Time: 0.22 seconds\n",
            "Epoch: 481 | Train Loss: 0.00048 | Valid Loss: 0.44031 | Time: 0.23 seconds\n",
            "Epoch: 482 | Train Loss: 0.00036 | Valid Loss: 0.44724 | Time: 0.22 seconds\n",
            "Epoch: 483 | Train Loss: 0.00030 | Valid Loss: 0.44556 | Time: 0.22 seconds\n",
            "Epoch: 484 | Train Loss: 0.00029 | Valid Loss: 0.44068 | Time: 0.22 seconds\n",
            "Epoch: 485 | Train Loss: 0.00018 | Valid Loss: 0.44769 | Time: 0.22 seconds\n",
            "Epoch: 486 | Train Loss: 0.00036 | Valid Loss: 0.45280 | Time: 0.22 seconds\n",
            "Epoch: 487 | Train Loss: 0.00026 | Valid Loss: 0.44498 | Time: 0.22 seconds\n",
            "Epoch: 488 | Train Loss: 0.00021 | Valid Loss: 0.44383 | Time: 0.22 seconds\n",
            "Epoch: 489 | Train Loss: 0.00017 | Valid Loss: 0.45081 | Time: 0.30 seconds\n",
            "Epoch: 490 | Train Loss: 0.00012 | Valid Loss: 0.45001 | Time: 0.21 seconds\n",
            "Epoch: 491 | Train Loss: 0.00018 | Valid Loss: 0.45104 | Time: 0.22 seconds\n",
            "Epoch: 492 | Train Loss: 0.00025 | Valid Loss: 0.44919 | Time: 0.22 seconds\n",
            "Epoch: 493 | Train Loss: 0.00017 | Valid Loss: 0.44927 | Time: 0.22 seconds\n",
            "Epoch: 494 | Train Loss: 0.00017 | Valid Loss: 0.45119 | Time: 0.22 seconds\n",
            "Epoch: 495 | Train Loss: 0.00019 | Valid Loss: 0.45196 | Time: 0.22 seconds\n",
            "Epoch: 496 | Train Loss: 0.00012 | Valid Loss: 0.45346 | Time: 0.22 seconds\n",
            "Epoch: 497 | Train Loss: 0.00017 | Valid Loss: 0.45323 | Time: 0.22 seconds\n",
            "Epoch: 498 | Train Loss: 0.00017 | Valid Loss: 0.45629 | Time: 0.22 seconds\n",
            "Epoch: 499 | Train Loss: 0.00024 | Valid Loss: 0.44838 | Time: 0.22 seconds\n",
            "Epoch: 500 | Train Loss: 0.00024 | Valid Loss: 0.44075 | Time: 0.22 seconds\n",
            "Epoch: 501 | Train Loss: 0.00028 | Valid Loss: 0.44878 | Time: 0.22 seconds\n",
            "Epoch: 502 | Train Loss: 0.00027 | Valid Loss: 0.44783 | Time: 0.22 seconds\n",
            "Epoch: 503 | Train Loss: 0.00016 | Valid Loss: 0.44385 | Time: 0.22 seconds\n",
            "Epoch: 504 | Train Loss: 0.00015 | Valid Loss: 0.44176 | Time: 0.22 seconds\n",
            "Epoch: 505 | Train Loss: 0.00013 | Valid Loss: 0.44472 | Time: 0.22 seconds\n",
            "Epoch: 506 | Train Loss: 0.00025 | Valid Loss: 0.44878 | Time: 0.22 seconds\n",
            "Epoch: 507 | Train Loss: 0.00015 | Valid Loss: 0.45147 | Time: 0.23 seconds\n",
            "Epoch: 508 | Train Loss: 0.00016 | Valid Loss: 0.44567 | Time: 0.22 seconds\n",
            "Epoch: 509 | Train Loss: 0.00020 | Valid Loss: 0.44956 | Time: 0.22 seconds\n",
            "Epoch: 510 | Train Loss: 0.00013 | Valid Loss: 0.45206 | Time: 0.22 seconds\n",
            "Epoch: 511 | Train Loss: 0.00012 | Valid Loss: 0.45305 | Time: 0.22 seconds\n",
            "Epoch: 512 | Train Loss: 0.00011 | Valid Loss: 0.45394 | Time: 0.22 seconds\n",
            "Epoch: 513 | Train Loss: 0.00012 | Valid Loss: 0.45506 | Time: 0.22 seconds\n",
            "Epoch: 514 | Train Loss: 0.00023 | Valid Loss: 0.44537 | Time: 0.22 seconds\n",
            "Epoch: 515 | Train Loss: 0.00017 | Valid Loss: 0.44847 | Time: 0.22 seconds\n",
            "Epoch: 516 | Train Loss: 0.00014 | Valid Loss: 0.44668 | Time: 0.24 seconds\n",
            "Epoch: 517 | Train Loss: 0.00014 | Valid Loss: 0.44540 | Time: 0.22 seconds\n",
            "Epoch: 518 | Train Loss: 0.00014 | Valid Loss: 0.44483 | Time: 0.22 seconds\n",
            "Epoch: 519 | Train Loss: 0.00017 | Valid Loss: 0.44667 | Time: 0.22 seconds\n",
            "Epoch: 520 | Train Loss: 0.00012 | Valid Loss: 0.44474 | Time: 0.22 seconds\n",
            "Epoch: 521 | Train Loss: 0.00007 | Valid Loss: 0.44894 | Time: 0.22 seconds\n",
            "Epoch: 522 | Train Loss: 0.00007 | Valid Loss: 0.44764 | Time: 0.22 seconds\n",
            "Epoch: 523 | Train Loss: 0.00010 | Valid Loss: 0.44595 | Time: 0.21 seconds\n",
            "Epoch: 524 | Train Loss: 0.00013 | Valid Loss: 0.44029 | Time: 0.22 seconds\n",
            "Epoch: 525 | Train Loss: 0.00011 | Valid Loss: 0.44644 | Time: 0.22 seconds\n",
            "Epoch: 526 | Train Loss: 0.00005 | Valid Loss: 0.44784 | Time: 0.22 seconds\n",
            "Epoch: 527 | Train Loss: 0.00009 | Valid Loss: 0.45167 | Time: 0.22 seconds\n",
            "Epoch: 528 | Train Loss: 0.00014 | Valid Loss: 0.44757 | Time: 0.22 seconds\n",
            "Epoch: 529 | Train Loss: 0.00015 | Valid Loss: 0.45053 | Time: 0.22 seconds\n",
            "Epoch: 530 | Train Loss: 0.00008 | Valid Loss: 0.45065 | Time: 0.22 seconds\n",
            "Epoch: 531 | Train Loss: 0.00005 | Valid Loss: 0.44895 | Time: 0.22 seconds\n",
            "Epoch: 532 | Train Loss: 0.00015 | Valid Loss: 0.45032 | Time: 0.29 seconds\n",
            "Epoch: 533 | Train Loss: 0.00013 | Valid Loss: 0.44893 | Time: 0.22 seconds\n",
            "Epoch: 534 | Train Loss: 0.00009 | Valid Loss: 0.45022 | Time: 0.22 seconds\n",
            "Epoch: 535 | Train Loss: 0.00007 | Valid Loss: 0.44891 | Time: 0.22 seconds\n",
            "Epoch: 536 | Train Loss: 0.00009 | Valid Loss: 0.44850 | Time: 0.22 seconds\n",
            "Epoch: 537 | Train Loss: 0.00013 | Valid Loss: 0.45305 | Time: 0.22 seconds\n",
            "Epoch: 538 | Train Loss: 0.00010 | Valid Loss: 0.44767 | Time: 0.22 seconds\n",
            "Epoch: 539 | Train Loss: 0.00009 | Valid Loss: 0.45008 | Time: 0.23 seconds\n",
            "Epoch: 540 | Train Loss: 0.00021 | Valid Loss: 0.45485 | Time: 0.22 seconds\n",
            "Epoch: 541 | Train Loss: 0.00013 | Valid Loss: 0.44571 | Time: 0.22 seconds\n",
            "Epoch: 542 | Train Loss: 0.00015 | Valid Loss: 0.44563 | Time: 0.22 seconds\n",
            "Epoch: 543 | Train Loss: 0.00015 | Valid Loss: 0.44801 | Time: 0.22 seconds\n",
            "Epoch: 544 | Train Loss: 0.00012 | Valid Loss: 0.44499 | Time: 0.24 seconds\n",
            "Epoch: 545 | Train Loss: 0.00008 | Valid Loss: 0.43885 | Time: 0.22 seconds\n",
            "Epoch: 546 | Train Loss: 0.00009 | Valid Loss: 0.44709 | Time: 0.22 seconds\n",
            "Epoch: 547 | Train Loss: 0.00010 | Valid Loss: 0.43804 | Time: 0.22 seconds\n",
            "Epoch: 548 | Train Loss: 0.00007 | Valid Loss: 0.44951 | Time: 0.22 seconds\n",
            "Epoch: 549 | Train Loss: 0.00005 | Valid Loss: 0.44362 | Time: 0.22 seconds\n",
            "Epoch: 550 | Train Loss: 0.00005 | Valid Loss: 0.44341 | Time: 0.22 seconds\n",
            "Epoch: 551 | Train Loss: 0.00012 | Valid Loss: 0.44481 | Time: 0.22 seconds\n",
            "Epoch: 552 | Train Loss: 0.00011 | Valid Loss: 0.44576 | Time: 0.22 seconds\n",
            "Epoch: 553 | Train Loss: 0.00012 | Valid Loss: 0.44900 | Time: 0.22 seconds\n",
            "Epoch: 554 | Train Loss: 0.00005 | Valid Loss: 0.45041 | Time: 0.22 seconds\n",
            "Epoch: 555 | Train Loss: 0.00012 | Valid Loss: 0.44336 | Time: 0.22 seconds\n",
            "Epoch: 556 | Train Loss: 0.00004 | Valid Loss: 0.44062 | Time: 0.22 seconds\n",
            "Epoch: 557 | Train Loss: 0.00007 | Valid Loss: 0.44313 | Time: 0.22 seconds\n",
            "Epoch: 558 | Train Loss: 0.00007 | Valid Loss: 0.44559 | Time: 0.22 seconds\n",
            "Epoch: 559 | Train Loss: 0.00006 | Valid Loss: 0.44622 | Time: 0.22 seconds\n",
            "Epoch: 560 | Train Loss: 0.00005 | Valid Loss: 0.44791 | Time: 0.22 seconds\n",
            "Epoch: 561 | Train Loss: 0.00007 | Valid Loss: 0.44768 | Time: 0.22 seconds\n",
            "Epoch: 562 | Train Loss: 0.00004 | Valid Loss: 0.44838 | Time: 0.23 seconds\n",
            "Epoch: 563 | Train Loss: 0.00005 | Valid Loss: 0.45237 | Time: 0.22 seconds\n",
            "Epoch: 564 | Train Loss: 0.00004 | Valid Loss: 0.45246 | Time: 0.22 seconds\n",
            "Epoch: 565 | Train Loss: 0.00007 | Valid Loss: 0.44862 | Time: 0.22 seconds\n",
            "Epoch: 566 | Train Loss: 0.00014 | Valid Loss: 0.44685 | Time: 0.22 seconds\n",
            "Epoch: 567 | Train Loss: 0.00015 | Valid Loss: 0.45184 | Time: 0.22 seconds\n",
            "Epoch: 568 | Train Loss: 0.00005 | Valid Loss: 0.44576 | Time: 0.22 seconds\n",
            "Epoch: 569 | Train Loss: 0.00008 | Valid Loss: 0.44715 | Time: 0.22 seconds\n",
            "Epoch: 570 | Train Loss: 0.00007 | Valid Loss: 0.44210 | Time: 0.21 seconds\n",
            "Epoch: 571 | Train Loss: 0.00007 | Valid Loss: 0.44716 | Time: 0.22 seconds\n",
            "Epoch: 572 | Train Loss: 0.00007 | Valid Loss: 0.44011 | Time: 0.21 seconds\n",
            "Epoch: 573 | Train Loss: 0.00006 | Valid Loss: 0.44789 | Time: 0.22 seconds\n",
            "Epoch: 574 | Train Loss: 0.00003 | Valid Loss: 0.44872 | Time: 0.22 seconds\n",
            "Epoch: 575 | Train Loss: 0.00006 | Valid Loss: 0.44858 | Time: 0.29 seconds\n",
            "Epoch: 576 | Train Loss: 0.00005 | Valid Loss: 0.44308 | Time: 0.22 seconds\n",
            "Epoch: 577 | Train Loss: 0.00002 | Valid Loss: 0.44856 | Time: 0.22 seconds\n",
            "Epoch: 578 | Train Loss: 0.00003 | Valid Loss: 0.44751 | Time: 0.22 seconds\n",
            "Epoch: 579 | Train Loss: 0.00002 | Valid Loss: 0.44686 | Time: 0.22 seconds\n",
            "Epoch: 580 | Train Loss: 0.00010 | Valid Loss: 0.44060 | Time: 0.22 seconds\n",
            "Epoch: 581 | Train Loss: 0.00003 | Valid Loss: 0.44107 | Time: 0.22 seconds\n",
            "Epoch: 582 | Train Loss: 0.00009 | Valid Loss: 0.44127 | Time: 0.23 seconds\n",
            "Epoch: 583 | Train Loss: 0.00003 | Valid Loss: 0.44453 | Time: 0.23 seconds\n",
            "Epoch: 584 | Train Loss: 0.00004 | Valid Loss: 0.44197 | Time: 0.24 seconds\n",
            "Epoch: 585 | Train Loss: 0.00008 | Valid Loss: 0.43609 | Time: 0.23 seconds\n",
            "Epoch: 586 | Train Loss: 0.00001 | Valid Loss: 0.44265 | Time: 0.24 seconds\n",
            "Epoch: 587 | Train Loss: 0.00002 | Valid Loss: 0.43879 | Time: 0.24 seconds\n",
            "Epoch: 588 | Train Loss: 0.00003 | Valid Loss: 0.44492 | Time: 0.24 seconds\n",
            "Epoch: 589 | Train Loss: 0.00005 | Valid Loss: 0.43719 | Time: 0.23 seconds\n",
            "Epoch: 590 | Train Loss: 0.00011 | Valid Loss: 0.44162 | Time: 0.23 seconds\n",
            "Epoch: 591 | Train Loss: 0.00004 | Valid Loss: 0.44255 | Time: 0.24 seconds\n",
            "Epoch: 592 | Train Loss: 0.00003 | Valid Loss: 0.43971 | Time: 0.23 seconds\n",
            "Epoch: 593 | Train Loss: 0.00001 | Valid Loss: 0.44464 | Time: 0.23 seconds\n",
            "Epoch: 594 | Train Loss: 0.00003 | Valid Loss: 0.44401 | Time: 0.22 seconds\n",
            "Epoch: 595 | Train Loss: 0.00004 | Valid Loss: 0.44548 | Time: 0.22 seconds\n",
            "Epoch: 596 | Train Loss: 0.00002 | Valid Loss: 0.44475 | Time: 0.22 seconds\n",
            "Epoch: 597 | Train Loss: 0.00002 | Valid Loss: 0.44443 | Time: 0.23 seconds\n",
            "Epoch: 598 | Train Loss: 0.00002 | Valid Loss: 0.44051 | Time: 0.25 seconds\n",
            "Epoch: 599 | Train Loss: 0.00007 | Valid Loss: 0.43905 | Time: 0.22 seconds\n",
            "Epoch: 600 | Train Loss: 0.00007 | Valid Loss: 0.43401 | Time: 0.23 seconds\n",
            "Epoch: 601 | Train Loss: 0.00005 | Valid Loss: 0.44166 | Time: 0.22 seconds\n",
            "Epoch: 602 | Train Loss: 0.00002 | Valid Loss: 0.44114 | Time: 0.23 seconds\n",
            "Epoch: 603 | Train Loss: 0.00004 | Valid Loss: 0.44670 | Time: 0.22 seconds\n",
            "Epoch: 604 | Train Loss: 0.00003 | Valid Loss: 0.44231 | Time: 0.22 seconds\n",
            "Epoch: 605 | Train Loss: 0.00002 | Valid Loss: 0.44098 | Time: 0.22 seconds\n",
            "Epoch: 606 | Train Loss: 0.00006 | Valid Loss: 0.44005 | Time: 0.22 seconds\n",
            "Epoch: 607 | Train Loss: 0.00001 | Valid Loss: 0.43627 | Time: 0.23 seconds\n",
            "Epoch: 608 | Train Loss: 0.00005 | Valid Loss: 0.44201 | Time: 0.22 seconds\n",
            "Epoch: 609 | Train Loss: 0.00003 | Valid Loss: 0.44353 | Time: 0.23 seconds\n",
            "Epoch: 610 | Train Loss: 0.00008 | Valid Loss: 0.44302 | Time: 0.22 seconds\n",
            "Epoch: 611 | Train Loss: 0.00004 | Valid Loss: 0.44682 | Time: 0.22 seconds\n",
            "Epoch: 612 | Train Loss: 0.00002 | Valid Loss: 0.44742 | Time: 0.22 seconds\n",
            "Epoch: 613 | Train Loss: 0.00001 | Valid Loss: 0.44887 | Time: 0.22 seconds\n",
            "Epoch: 614 | Train Loss: 0.00002 | Valid Loss: 0.44881 | Time: 0.22 seconds\n",
            "Epoch: 615 | Train Loss: 0.00005 | Valid Loss: 0.44674 | Time: 0.21 seconds\n",
            "Epoch: 616 | Train Loss: 0.00005 | Valid Loss: 0.44180 | Time: 0.22 seconds\n",
            "Epoch: 617 | Train Loss: 0.00004 | Valid Loss: 0.44457 | Time: 0.22 seconds\n",
            "Epoch: 618 | Train Loss: 0.00004 | Valid Loss: 0.44118 | Time: 0.29 seconds\n",
            "Epoch: 619 | Train Loss: 0.00003 | Valid Loss: 0.44870 | Time: 0.22 seconds\n",
            "Epoch: 620 | Train Loss: 0.00002 | Valid Loss: 0.44328 | Time: 0.23 seconds\n",
            "Epoch: 621 | Train Loss: 0.00006 | Valid Loss: 0.44266 | Time: 0.22 seconds\n",
            "Epoch: 622 | Train Loss: 0.00002 | Valid Loss: 0.45205 | Time: 0.22 seconds\n",
            "Epoch: 623 | Train Loss: 0.00002 | Valid Loss: 0.45195 | Time: 0.22 seconds\n",
            "Epoch: 624 | Train Loss: 0.00002 | Valid Loss: 0.45036 | Time: 0.22 seconds\n",
            "Epoch: 625 | Train Loss: 0.00015 | Valid Loss: 0.44689 | Time: 0.23 seconds\n",
            "Epoch: 626 | Train Loss: 0.00005 | Valid Loss: 0.45133 | Time: 0.22 seconds\n",
            "Epoch: 627 | Train Loss: 0.00002 | Valid Loss: 0.44764 | Time: 0.22 seconds\n",
            "Epoch: 628 | Train Loss: 0.00003 | Valid Loss: 0.44489 | Time: 0.22 seconds\n",
            "Epoch: 629 | Train Loss: 0.00005 | Valid Loss: 0.44619 | Time: 0.22 seconds\n",
            "Epoch: 630 | Train Loss: 0.00002 | Valid Loss: 0.45120 | Time: 0.22 seconds\n",
            "Epoch: 631 | Train Loss: 0.00003 | Valid Loss: 0.45196 | Time: 0.22 seconds\n",
            "Epoch: 632 | Train Loss: 0.00003 | Valid Loss: 0.45242 | Time: 0.22 seconds\n",
            "Epoch: 633 | Train Loss: 0.00005 | Valid Loss: 0.45120 | Time: 0.22 seconds\n",
            "Epoch: 634 | Train Loss: 0.00001 | Valid Loss: 0.44951 | Time: 0.23 seconds\n",
            "Epoch: 635 | Train Loss: 0.00003 | Valid Loss: 0.45010 | Time: 0.24 seconds\n",
            "Epoch: 636 | Train Loss: 0.00002 | Valid Loss: 0.44282 | Time: 0.22 seconds\n",
            "Epoch: 637 | Train Loss: 0.00001 | Valid Loss: 0.44943 | Time: 0.22 seconds\n",
            "Epoch: 638 | Train Loss: 0.00001 | Valid Loss: 0.44177 | Time: 0.23 seconds\n",
            "Epoch: 639 | Train Loss: 0.00007 | Valid Loss: 0.44869 | Time: 0.22 seconds\n",
            "Epoch: 640 | Train Loss: 0.00001 | Valid Loss: 0.44358 | Time: 0.22 seconds\n",
            "Epoch: 641 | Train Loss: 0.00002 | Valid Loss: 0.44634 | Time: 0.22 seconds\n",
            "Epoch: 642 | Train Loss: 0.00001 | Valid Loss: 0.44346 | Time: 0.22 seconds\n",
            "Epoch: 643 | Train Loss: 0.00001 | Valid Loss: 0.44720 | Time: 0.23 seconds\n",
            "Epoch: 644 | Train Loss: 0.00001 | Valid Loss: 0.44314 | Time: 0.22 seconds\n",
            "Epoch: 645 | Train Loss: 0.00006 | Valid Loss: 0.44323 | Time: 0.22 seconds\n",
            "Epoch: 646 | Train Loss: 0.00002 | Valid Loss: 0.44199 | Time: 0.22 seconds\n",
            "Epoch: 647 | Train Loss: 0.00003 | Valid Loss: 0.44073 | Time: 0.22 seconds\n",
            "Epoch: 648 | Train Loss: 0.00000 | Valid Loss: 0.44040 | Time: 0.22 seconds\n",
            "Epoch: 649 | Train Loss: 0.00003 | Valid Loss: 0.44134 | Time: 0.22 seconds\n",
            "Epoch: 650 | Train Loss: 0.00001 | Valid Loss: 0.43772 | Time: 0.22 seconds\n",
            "Epoch: 651 | Train Loss: 0.00005 | Valid Loss: 0.44517 | Time: 0.22 seconds\n",
            "Epoch: 652 | Train Loss: 0.00001 | Valid Loss: 0.44010 | Time: 0.23 seconds\n",
            "Epoch: 653 | Train Loss: 0.00000 | Valid Loss: 0.44082 | Time: 0.23 seconds\n",
            "Epoch: 654 | Train Loss: 0.00001 | Valid Loss: 0.44237 | Time: 0.23 seconds\n",
            "Epoch: 655 | Train Loss: 0.00004 | Valid Loss: 0.42934 | Time: 0.23 seconds\n",
            "Epoch: 656 | Train Loss: 0.00006 | Valid Loss: 0.43960 | Time: 0.23 seconds\n",
            "Epoch: 657 | Train Loss: 0.00000 | Valid Loss: 0.43745 | Time: 0.22 seconds\n",
            "Epoch: 658 | Train Loss: 0.00002 | Valid Loss: 0.43552 | Time: 0.22 seconds\n",
            "Epoch: 659 | Train Loss: 0.00002 | Valid Loss: 0.43627 | Time: 0.22 seconds\n",
            "Epoch: 660 | Train Loss: 0.00001 | Valid Loss: 0.43854 | Time: 0.23 seconds\n",
            "Epoch: 661 | Train Loss: 0.00002 | Valid Loss: 0.43797 | Time: 0.29 seconds\n",
            "Epoch: 662 | Train Loss: 0.00001 | Valid Loss: 0.44228 | Time: 0.23 seconds\n",
            "Epoch: 663 | Train Loss: 0.00007 | Valid Loss: 0.44302 | Time: 0.24 seconds\n",
            "Epoch: 664 | Train Loss: 0.00006 | Valid Loss: 0.43824 | Time: 0.24 seconds\n",
            "Epoch: 665 | Train Loss: 0.00001 | Valid Loss: 0.44294 | Time: 0.23 seconds\n",
            "Epoch: 666 | Train Loss: 0.00000 | Valid Loss: 0.44076 | Time: 0.23 seconds\n",
            "Epoch: 667 | Train Loss: 0.00001 | Valid Loss: 0.44233 | Time: 0.23 seconds\n",
            "Epoch: 668 | Train Loss: 0.00000 | Valid Loss: 0.44194 | Time: 0.23 seconds\n",
            "Epoch: 669 | Train Loss: 0.00000 | Valid Loss: 0.43953 | Time: 0.23 seconds\n",
            "Epoch: 670 | Train Loss: 0.00000 | Valid Loss: 0.43725 | Time: 0.22 seconds\n",
            "Epoch: 671 | Train Loss: 0.00001 | Valid Loss: 0.43555 | Time: 0.22 seconds\n",
            "Epoch: 672 | Train Loss: 0.00000 | Valid Loss: 0.44014 | Time: 0.22 seconds\n",
            "Epoch: 673 | Train Loss: 0.00000 | Valid Loss: 0.44011 | Time: 0.22 seconds\n",
            "Epoch: 674 | Train Loss: 0.00001 | Valid Loss: 0.43612 | Time: 0.22 seconds\n",
            "Epoch: 675 | Train Loss: 0.00001 | Valid Loss: 0.43893 | Time: 0.21 seconds\n",
            "Epoch: 676 | Train Loss: 0.00002 | Valid Loss: 0.44008 | Time: 0.22 seconds\n",
            "Epoch: 677 | Train Loss: 0.00002 | Valid Loss: 0.44474 | Time: 0.22 seconds\n",
            "Epoch: 678 | Train Loss: 0.00002 | Valid Loss: 0.43563 | Time: 0.22 seconds\n",
            "Epoch: 679 | Train Loss: 0.00003 | Valid Loss: 0.43934 | Time: 0.23 seconds\n",
            "Epoch: 680 | Train Loss: 0.00001 | Valid Loss: 0.44066 | Time: 0.22 seconds\n",
            "Epoch: 681 | Train Loss: 0.00002 | Valid Loss: 0.44079 | Time: 0.22 seconds\n",
            "Epoch: 682 | Train Loss: 0.00001 | Valid Loss: 0.44734 | Time: 0.21 seconds\n",
            "Epoch: 683 | Train Loss: 0.00005 | Valid Loss: 0.44424 | Time: 0.22 seconds\n",
            "Epoch: 684 | Train Loss: 0.00001 | Valid Loss: 0.43880 | Time: 0.22 seconds\n",
            "Epoch: 685 | Train Loss: 0.00000 | Valid Loss: 0.44100 | Time: 0.22 seconds\n",
            "Epoch: 686 | Train Loss: 0.00002 | Valid Loss: 0.45066 | Time: 0.22 seconds\n",
            "Epoch: 687 | Train Loss: 0.00000 | Valid Loss: 0.44400 | Time: 0.22 seconds\n",
            "Epoch: 688 | Train Loss: 0.00001 | Valid Loss: 0.44191 | Time: 0.22 seconds\n",
            "Epoch: 689 | Train Loss: 0.00000 | Valid Loss: 0.44374 | Time: 0.22 seconds\n",
            "Epoch: 690 | Train Loss: 0.00000 | Valid Loss: 0.43751 | Time: 0.23 seconds\n",
            "Epoch: 691 | Train Loss: 0.00000 | Valid Loss: 0.44486 | Time: 0.22 seconds\n",
            "Epoch: 692 | Train Loss: 0.00001 | Valid Loss: 0.44615 | Time: 0.23 seconds\n",
            "Epoch: 693 | Train Loss: 0.00002 | Valid Loss: 0.44057 | Time: 0.22 seconds\n",
            "Epoch: 694 | Train Loss: 0.00001 | Valid Loss: 0.44042 | Time: 0.32 seconds\n",
            "Epoch: 695 | Train Loss: 0.00001 | Valid Loss: 0.45379 | Time: 0.23 seconds\n",
            "Epoch: 696 | Train Loss: 0.00001 | Valid Loss: 0.44801 | Time: 0.22 seconds\n",
            "Epoch: 697 | Train Loss: 0.00000 | Valid Loss: 0.43744 | Time: 0.22 seconds\n",
            "Epoch: 698 | Train Loss: 0.00000 | Valid Loss: 0.45089 | Time: 0.22 seconds\n",
            "Epoch: 699 | Train Loss: 0.00000 | Valid Loss: 0.44717 | Time: 0.22 seconds\n",
            "Epoch: 700 | Train Loss: 0.00004 | Valid Loss: 0.44750 | Time: 0.23 seconds\n",
            "Epoch: 701 | Train Loss: 0.00029 | Valid Loss: 0.43748 | Time: 0.23 seconds\n",
            "Epoch: 702 | Train Loss: 0.00001 | Valid Loss: 0.45018 | Time: 0.22 seconds\n",
            "Epoch: 703 | Train Loss: 0.00004 | Valid Loss: 0.44785 | Time: 0.23 seconds\n",
            "Epoch: 704 | Train Loss: 0.00006 | Valid Loss: 0.44993 | Time: 0.29 seconds\n",
            "Epoch: 705 | Train Loss: 0.00001 | Valid Loss: 0.44679 | Time: 0.22 seconds\n",
            "Epoch: 706 | Train Loss: 0.00002 | Valid Loss: 0.45637 | Time: 0.22 seconds\n",
            "Epoch: 707 | Train Loss: 0.00000 | Valid Loss: 0.44549 | Time: 0.22 seconds\n",
            "Epoch: 708 | Train Loss: 0.00002 | Valid Loss: 0.44805 | Time: 0.22 seconds\n",
            "Epoch: 709 | Train Loss: 0.00000 | Valid Loss: 0.44979 | Time: 0.22 seconds\n",
            "Epoch: 710 | Train Loss: 0.00001 | Valid Loss: 0.44483 | Time: 0.23 seconds\n",
            "Epoch: 711 | Train Loss: 0.00001 | Valid Loss: 0.44912 | Time: 0.23 seconds\n",
            "Epoch: 712 | Train Loss: 0.00001 | Valid Loss: 0.44585 | Time: 0.22 seconds\n",
            "Epoch: 713 | Train Loss: 0.00000 | Valid Loss: 0.45063 | Time: 0.22 seconds\n",
            "Epoch: 714 | Train Loss: 0.00002 | Valid Loss: 0.45007 | Time: 0.24 seconds\n",
            "Epoch: 715 | Train Loss: 0.00001 | Valid Loss: 0.44507 | Time: 0.22 seconds\n",
            "Epoch: 716 | Train Loss: 0.00003 | Valid Loss: 0.44100 | Time: 0.22 seconds\n",
            "Epoch: 717 | Train Loss: 0.00002 | Valid Loss: 0.44375 | Time: 0.22 seconds\n",
            "Epoch: 718 | Train Loss: 0.00005 | Valid Loss: 0.44450 | Time: 0.23 seconds\n",
            "Epoch: 719 | Train Loss: 0.00001 | Valid Loss: 0.44700 | Time: 0.23 seconds\n",
            "Epoch: 720 | Train Loss: 0.00000 | Valid Loss: 0.44977 | Time: 0.23 seconds\n",
            "Epoch: 721 | Train Loss: 0.00003 | Valid Loss: 0.44713 | Time: 0.22 seconds\n",
            "Epoch: 722 | Train Loss: 0.00002 | Valid Loss: 0.44930 | Time: 0.22 seconds\n",
            "Epoch: 723 | Train Loss: 0.00001 | Valid Loss: 0.44246 | Time: 0.23 seconds\n",
            "Epoch: 724 | Train Loss: 0.00000 | Valid Loss: 0.45164 | Time: 0.23 seconds\n",
            "Epoch: 725 | Train Loss: 0.00000 | Valid Loss: 0.44882 | Time: 0.23 seconds\n",
            "Epoch: 726 | Train Loss: 0.00003 | Valid Loss: 0.44547 | Time: 0.22 seconds\n",
            "Epoch: 727 | Train Loss: 0.00000 | Valid Loss: 0.44588 | Time: 0.23 seconds\n",
            "Epoch: 728 | Train Loss: 0.00000 | Valid Loss: 0.44489 | Time: 0.23 seconds\n",
            "Epoch: 729 | Train Loss: 0.00000 | Valid Loss: 0.44980 | Time: 0.23 seconds\n",
            "Epoch: 730 | Train Loss: 0.00001 | Valid Loss: 0.44540 | Time: 0.23 seconds\n",
            "Epoch: 731 | Train Loss: 0.00000 | Valid Loss: 0.45362 | Time: 0.23 seconds\n",
            "Epoch: 732 | Train Loss: 0.00004 | Valid Loss: 0.43964 | Time: 0.23 seconds\n",
            "Epoch: 733 | Train Loss: 0.00001 | Valid Loss: 0.44559 | Time: 0.23 seconds\n",
            "Epoch: 734 | Train Loss: 0.00001 | Valid Loss: 0.44795 | Time: 0.22 seconds\n",
            "Epoch: 735 | Train Loss: 0.00000 | Valid Loss: 0.44381 | Time: 0.22 seconds\n",
            "Epoch: 736 | Train Loss: 0.00002 | Valid Loss: 0.43918 | Time: 0.23 seconds\n",
            "Epoch: 737 | Train Loss: 0.00000 | Valid Loss: 0.44495 | Time: 0.24 seconds\n",
            "Epoch: 738 | Train Loss: 0.00001 | Valid Loss: 0.44406 | Time: 0.23 seconds\n",
            "Epoch: 739 | Train Loss: 0.00003 | Valid Loss: 0.43536 | Time: 0.23 seconds\n",
            "Epoch: 740 | Train Loss: 0.00001 | Valid Loss: 0.44817 | Time: 0.22 seconds\n",
            "Epoch: 741 | Train Loss: 0.00003 | Valid Loss: 0.44250 | Time: 0.23 seconds\n",
            "Epoch: 742 | Train Loss: 0.00000 | Valid Loss: 0.44462 | Time: 0.22 seconds\n",
            "Epoch: 743 | Train Loss: 0.00001 | Valid Loss: 0.45068 | Time: 0.23 seconds\n",
            "Epoch: 744 | Train Loss: 0.00001 | Valid Loss: 0.44677 | Time: 0.23 seconds\n",
            "Epoch: 745 | Train Loss: 0.00001 | Valid Loss: 0.43819 | Time: 0.23 seconds\n",
            "Epoch: 746 | Train Loss: 0.00000 | Valid Loss: 0.44560 | Time: 0.23 seconds\n",
            "Epoch: 747 | Train Loss: 0.00000 | Valid Loss: 0.44645 | Time: 0.29 seconds\n",
            "Epoch: 748 | Train Loss: 0.00000 | Valid Loss: 0.44616 | Time: 0.22 seconds\n",
            "Epoch: 749 | Train Loss: 0.00003 | Valid Loss: 0.44639 | Time: 0.22 seconds\n",
            "Epoch: 750 | Train Loss: 0.00000 | Valid Loss: 0.44465 | Time: 0.23 seconds\n",
            "Epoch: 751 | Train Loss: 0.00001 | Valid Loss: 0.44394 | Time: 0.22 seconds\n",
            "Epoch: 752 | Train Loss: 0.00000 | Valid Loss: 0.44216 | Time: 0.23 seconds\n",
            "Epoch: 753 | Train Loss: 0.00000 | Valid Loss: 0.44110 | Time: 0.22 seconds\n",
            "Epoch: 754 | Train Loss: 0.00000 | Valid Loss: 0.44714 | Time: 0.24 seconds\n",
            "Epoch: 755 | Train Loss: 0.00000 | Valid Loss: 0.44233 | Time: 0.22 seconds\n",
            "Epoch: 756 | Train Loss: 0.00000 | Valid Loss: 0.44752 | Time: 0.22 seconds\n",
            "Epoch: 757 | Train Loss: 0.00001 | Valid Loss: 0.44429 | Time: 0.23 seconds\n",
            "Epoch: 758 | Train Loss: 0.00002 | Valid Loss: 0.44634 | Time: 0.23 seconds\n",
            "Epoch: 759 | Train Loss: 0.00001 | Valid Loss: 0.43938 | Time: 0.23 seconds\n",
            "Epoch: 760 | Train Loss: 0.00000 | Valid Loss: 0.44230 | Time: 0.22 seconds\n",
            "Epoch: 761 | Train Loss: 0.00001 | Valid Loss: 0.44691 | Time: 0.22 seconds\n",
            "Epoch: 762 | Train Loss: 0.00001 | Valid Loss: 0.44129 | Time: 0.22 seconds\n",
            "Epoch: 763 | Train Loss: 0.00001 | Valid Loss: 0.44312 | Time: 0.22 seconds\n",
            "Epoch: 764 | Train Loss: 0.00000 | Valid Loss: 0.44304 | Time: 0.22 seconds\n",
            "Epoch: 765 | Train Loss: 0.00000 | Valid Loss: 0.44439 | Time: 0.23 seconds\n",
            "Epoch: 766 | Train Loss: 0.00000 | Valid Loss: 0.44877 | Time: 0.22 seconds\n",
            "Epoch: 767 | Train Loss: 0.00000 | Valid Loss: 0.44553 | Time: 0.23 seconds\n",
            "Epoch: 768 | Train Loss: 0.00001 | Valid Loss: 0.44531 | Time: 0.24 seconds\n",
            "Epoch: 769 | Train Loss: 0.00000 | Valid Loss: 0.44942 | Time: 0.23 seconds\n",
            "Epoch: 770 | Train Loss: 0.00000 | Valid Loss: 0.43845 | Time: 0.22 seconds\n",
            "Epoch: 771 | Train Loss: 0.00006 | Valid Loss: 0.44657 | Time: 0.22 seconds\n",
            "Epoch: 772 | Train Loss: 0.00003 | Valid Loss: 0.45081 | Time: 0.22 seconds\n",
            "Epoch: 773 | Train Loss: 0.00003 | Valid Loss: 0.44389 | Time: 0.22 seconds\n",
            "Epoch: 774 | Train Loss: 0.00000 | Valid Loss: 0.43714 | Time: 0.22 seconds\n",
            "Epoch: 775 | Train Loss: 0.00003 | Valid Loss: 0.44394 | Time: 0.23 seconds\n",
            "Epoch: 776 | Train Loss: 0.00001 | Valid Loss: 0.44054 | Time: 0.22 seconds\n",
            "Epoch: 777 | Train Loss: 0.00001 | Valid Loss: 0.44252 | Time: 0.23 seconds\n",
            "Epoch: 778 | Train Loss: 0.00000 | Valid Loss: 0.44692 | Time: 0.22 seconds\n",
            "Epoch: 779 | Train Loss: 0.00000 | Valid Loss: 0.44681 | Time: 0.22 seconds\n",
            "Epoch: 780 | Train Loss: 0.00000 | Valid Loss: 0.44712 | Time: 0.23 seconds\n",
            "Epoch: 781 | Train Loss: 0.00000 | Valid Loss: 0.44817 | Time: 0.23 seconds\n",
            "Epoch: 782 | Train Loss: 0.00000 | Valid Loss: 0.45006 | Time: 0.22 seconds\n",
            "Epoch: 783 | Train Loss: 0.00000 | Valid Loss: 0.45121 | Time: 0.22 seconds\n",
            "Epoch: 784 | Train Loss: 0.00000 | Valid Loss: 0.44044 | Time: 0.24 seconds\n",
            "Epoch: 785 | Train Loss: 0.00001 | Valid Loss: 0.44430 | Time: 0.23 seconds\n",
            "Epoch: 786 | Train Loss: 0.00003 | Valid Loss: 0.43622 | Time: 0.24 seconds\n",
            "Epoch: 787 | Train Loss: 0.00001 | Valid Loss: 0.44469 | Time: 0.23 seconds\n",
            "Epoch: 788 | Train Loss: 0.00000 | Valid Loss: 0.44125 | Time: 0.23 seconds\n",
            "Epoch: 789 | Train Loss: 0.00000 | Valid Loss: 0.44129 | Time: 0.23 seconds\n",
            "Epoch: 790 | Train Loss: 0.00000 | Valid Loss: 0.44173 | Time: 0.30 seconds\n",
            "Epoch: 791 | Train Loss: 0.00000 | Valid Loss: 0.44393 | Time: 0.22 seconds\n",
            "Epoch: 792 | Train Loss: 0.00002 | Valid Loss: 0.44532 | Time: 0.22 seconds\n",
            "Epoch: 793 | Train Loss: 0.00000 | Valid Loss: 0.44528 | Time: 0.22 seconds\n",
            "Epoch: 794 | Train Loss: 0.00002 | Valid Loss: 0.44878 | Time: 0.23 seconds\n",
            "Epoch: 795 | Train Loss: 0.00000 | Valid Loss: 0.44622 | Time: 0.23 seconds\n",
            "Epoch: 796 | Train Loss: 0.00000 | Valid Loss: 0.44277 | Time: 0.23 seconds\n",
            "Epoch: 797 | Train Loss: 0.00000 | Valid Loss: 0.44167 | Time: 0.22 seconds\n",
            "Epoch: 798 | Train Loss: 0.00000 | Valid Loss: 0.44311 | Time: 0.22 seconds\n",
            "Epoch: 799 | Train Loss: 0.00000 | Valid Loss: 0.44503 | Time: 0.23 seconds\n",
            "Epoch: 800 | Train Loss: 0.00000 | Valid Loss: 0.44605 | Time: 0.22 seconds\n",
            "Epoch: 801 | Train Loss: 0.00002 | Valid Loss: 0.43999 | Time: 0.23 seconds\n",
            "Epoch: 802 | Train Loss: 0.00000 | Valid Loss: 0.44743 | Time: 0.23 seconds\n",
            "Epoch: 803 | Train Loss: 0.00000 | Valid Loss: 0.44264 | Time: 0.23 seconds\n",
            "Epoch: 804 | Train Loss: 0.00000 | Valid Loss: 0.43739 | Time: 0.23 seconds\n",
            "Epoch: 805 | Train Loss: 0.00000 | Valid Loss: 0.43731 | Time: 0.22 seconds\n",
            "Epoch: 806 | Train Loss: 0.00000 | Valid Loss: 0.44601 | Time: 0.23 seconds\n",
            "Epoch: 807 | Train Loss: 0.00000 | Valid Loss: 0.43782 | Time: 0.23 seconds\n",
            "Epoch: 808 | Train Loss: 0.00000 | Valid Loss: 0.43815 | Time: 0.24 seconds\n",
            "Epoch: 809 | Train Loss: 0.00001 | Valid Loss: 0.44490 | Time: 0.23 seconds\n",
            "Epoch: 810 | Train Loss: 0.00000 | Valid Loss: 0.44022 | Time: 0.23 seconds\n",
            "Epoch: 811 | Train Loss: 0.00002 | Valid Loss: 0.43517 | Time: 0.22 seconds\n",
            "Epoch: 812 | Train Loss: 0.00002 | Valid Loss: 0.45033 | Time: 0.23 seconds\n",
            "Epoch: 813 | Train Loss: 0.00000 | Valid Loss: 0.44025 | Time: 0.24 seconds\n",
            "Epoch: 814 | Train Loss: 0.00001 | Valid Loss: 0.44023 | Time: 0.22 seconds\n",
            "Epoch: 815 | Train Loss: 0.00000 | Valid Loss: 0.42809 | Time: 0.23 seconds\n",
            "Epoch: 816 | Train Loss: 0.00000 | Valid Loss: 0.43837 | Time: 0.23 seconds\n",
            "Epoch: 817 | Train Loss: 0.00000 | Valid Loss: 0.43320 | Time: 0.23 seconds\n",
            "Epoch: 818 | Train Loss: 0.00000 | Valid Loss: 0.43809 | Time: 0.22 seconds\n",
            "Epoch: 819 | Train Loss: 0.00000 | Valid Loss: 0.43770 | Time: 0.23 seconds\n",
            "Epoch: 820 | Train Loss: 0.00000 | Valid Loss: 0.44064 | Time: 0.23 seconds\n",
            "Epoch: 821 | Train Loss: 0.00000 | Valid Loss: 0.43986 | Time: 0.23 seconds\n",
            "Epoch: 822 | Train Loss: 0.00000 | Valid Loss: 0.44064 | Time: 0.22 seconds\n",
            "Epoch: 823 | Train Loss: 0.00000 | Valid Loss: 0.43854 | Time: 0.23 seconds\n",
            "Epoch: 824 | Train Loss: 0.00001 | Valid Loss: 0.43825 | Time: 0.22 seconds\n",
            "Epoch: 825 | Train Loss: 0.00000 | Valid Loss: 0.43817 | Time: 0.23 seconds\n",
            "Epoch: 826 | Train Loss: 0.00000 | Valid Loss: 0.43604 | Time: 0.24 seconds\n",
            "Epoch: 827 | Train Loss: 0.00002 | Valid Loss: 0.44036 | Time: 0.22 seconds\n",
            "Epoch: 828 | Train Loss: 0.00004 | Valid Loss: 0.44810 | Time: 0.23 seconds\n",
            "Epoch: 829 | Train Loss: 0.00000 | Valid Loss: 0.43495 | Time: 0.22 seconds\n",
            "Epoch: 830 | Train Loss: 0.00000 | Valid Loss: 0.43313 | Time: 0.23 seconds\n",
            "Epoch: 831 | Train Loss: 0.00000 | Valid Loss: 0.43264 | Time: 0.22 seconds\n",
            "Epoch: 832 | Train Loss: 0.00000 | Valid Loss: 0.44140 | Time: 0.22 seconds\n",
            "Epoch: 833 | Train Loss: 0.00000 | Valid Loss: 0.43311 | Time: 0.29 seconds\n",
            "Epoch: 834 | Train Loss: 0.00000 | Valid Loss: 0.44231 | Time: 0.23 seconds\n",
            "Epoch: 835 | Train Loss: 0.00000 | Valid Loss: 0.44161 | Time: 0.22 seconds\n",
            "Epoch: 836 | Train Loss: 0.00001 | Valid Loss: 0.43427 | Time: 0.22 seconds\n",
            "Epoch: 837 | Train Loss: 0.00001 | Valid Loss: 0.44081 | Time: 0.22 seconds\n",
            "Epoch: 838 | Train Loss: 0.00000 | Valid Loss: 0.43804 | Time: 0.23 seconds\n",
            "Epoch: 839 | Train Loss: 0.00002 | Valid Loss: 0.43948 | Time: 0.24 seconds\n",
            "Epoch: 840 | Train Loss: 0.00000 | Valid Loss: 0.43398 | Time: 0.24 seconds\n",
            "Epoch: 841 | Train Loss: 0.00000 | Valid Loss: 0.43718 | Time: 0.22 seconds\n",
            "Epoch: 842 | Train Loss: 0.00000 | Valid Loss: 0.43564 | Time: 0.23 seconds\n",
            "Epoch: 843 | Train Loss: 0.00001 | Valid Loss: 0.43403 | Time: 0.23 seconds\n",
            "Epoch: 844 | Train Loss: 0.00000 | Valid Loss: 0.44089 | Time: 0.22 seconds\n",
            "Epoch: 845 | Train Loss: 0.00000 | Valid Loss: 0.43075 | Time: 0.23 seconds\n",
            "Epoch: 846 | Train Loss: 0.00001 | Valid Loss: 0.43536 | Time: 0.23 seconds\n",
            "Epoch: 847 | Train Loss: 0.00001 | Valid Loss: 0.43578 | Time: 0.22 seconds\n",
            "Epoch: 848 | Train Loss: 0.00000 | Valid Loss: 0.43952 | Time: 0.22 seconds\n",
            "Epoch: 849 | Train Loss: 0.00000 | Valid Loss: 0.44068 | Time: 0.23 seconds\n",
            "Epoch: 850 | Train Loss: 0.00001 | Valid Loss: 0.43924 | Time: 0.23 seconds\n",
            "Epoch: 851 | Train Loss: 0.00000 | Valid Loss: 0.44069 | Time: 0.23 seconds\n",
            "Epoch: 852 | Train Loss: 0.00000 | Valid Loss: 0.44288 | Time: 0.23 seconds\n",
            "Epoch: 853 | Train Loss: 0.00000 | Valid Loss: 0.43785 | Time: 0.22 seconds\n",
            "Epoch: 854 | Train Loss: 0.00000 | Valid Loss: 0.43040 | Time: 0.22 seconds\n",
            "Epoch: 855 | Train Loss: 0.00000 | Valid Loss: 0.43832 | Time: 0.23 seconds\n",
            "Epoch: 856 | Train Loss: 0.00000 | Valid Loss: 0.44265 | Time: 0.24 seconds\n",
            "Epoch: 857 | Train Loss: 0.00000 | Valid Loss: 0.44234 | Time: 0.23 seconds\n",
            "Epoch: 858 | Train Loss: 0.00000 | Valid Loss: 0.43657 | Time: 0.22 seconds\n",
            "Epoch: 859 | Train Loss: 0.00000 | Valid Loss: 0.43935 | Time: 0.22 seconds\n",
            "Epoch: 860 | Train Loss: 0.00000 | Valid Loss: 0.44071 | Time: 0.23 seconds\n",
            "Epoch: 861 | Train Loss: 0.00001 | Valid Loss: 0.43626 | Time: 0.23 seconds\n",
            "Epoch: 862 | Train Loss: 0.00000 | Valid Loss: 0.43434 | Time: 0.23 seconds\n",
            "Epoch: 863 | Train Loss: 0.00000 | Valid Loss: 0.44027 | Time: 0.23 seconds\n",
            "Epoch: 864 | Train Loss: 0.00001 | Valid Loss: 0.44093 | Time: 0.22 seconds\n",
            "Epoch: 865 | Train Loss: 0.00000 | Valid Loss: 0.44257 | Time: 0.23 seconds\n",
            "Epoch: 866 | Train Loss: 0.00001 | Valid Loss: 0.44089 | Time: 0.23 seconds\n",
            "Epoch: 867 | Train Loss: 0.00001 | Valid Loss: 0.43495 | Time: 0.22 seconds\n",
            "Epoch: 868 | Train Loss: 0.00000 | Valid Loss: 0.43820 | Time: 0.23 seconds\n",
            "Epoch: 869 | Train Loss: 0.00000 | Valid Loss: 0.44090 | Time: 0.23 seconds\n",
            "Epoch: 870 | Train Loss: 0.00000 | Valid Loss: 0.43532 | Time: 0.23 seconds\n",
            "Epoch: 871 | Train Loss: 0.00000 | Valid Loss: 0.43716 | Time: 0.22 seconds\n",
            "Epoch: 872 | Train Loss: 0.00001 | Valid Loss: 0.43975 | Time: 0.22 seconds\n",
            "Epoch: 873 | Train Loss: 0.00003 | Valid Loss: 0.43870 | Time: 0.22 seconds\n",
            "Epoch: 874 | Train Loss: 0.00000 | Valid Loss: 0.43377 | Time: 0.23 seconds\n",
            "Epoch: 875 | Train Loss: 0.00000 | Valid Loss: 0.43086 | Time: 0.23 seconds\n",
            "Epoch: 876 | Train Loss: 0.00000 | Valid Loss: 0.43198 | Time: 0.30 seconds\n",
            "Epoch: 877 | Train Loss: 0.00000 | Valid Loss: 0.42137 | Time: 0.23 seconds\n",
            "Epoch: 878 | Train Loss: 0.00001 | Valid Loss: 0.42992 | Time: 0.22 seconds\n",
            "Epoch: 879 | Train Loss: 0.00000 | Valid Loss: 0.42945 | Time: 0.22 seconds\n",
            "Epoch: 880 | Train Loss: 0.00001 | Valid Loss: 0.42892 | Time: 0.22 seconds\n",
            "Epoch: 881 | Train Loss: 0.00001 | Valid Loss: 0.43858 | Time: 0.22 seconds\n",
            "Epoch: 882 | Train Loss: 0.00000 | Valid Loss: 0.43073 | Time: 0.22 seconds\n",
            "Epoch: 883 | Train Loss: 0.00000 | Valid Loss: 0.43222 | Time: 0.22 seconds\n",
            "Epoch: 884 | Train Loss: 0.00000 | Valid Loss: 0.43169 | Time: 0.22 seconds\n",
            "Epoch: 885 | Train Loss: 0.00000 | Valid Loss: 0.43208 | Time: 0.22 seconds\n",
            "Epoch: 886 | Train Loss: 0.00000 | Valid Loss: 0.43623 | Time: 0.22 seconds\n",
            "Epoch: 887 | Train Loss: 0.00000 | Valid Loss: 0.43571 | Time: 0.23 seconds\n",
            "Epoch: 888 | Train Loss: 0.00000 | Valid Loss: 0.43461 | Time: 0.22 seconds\n",
            "Epoch: 889 | Train Loss: 0.00001 | Valid Loss: 0.44038 | Time: 0.22 seconds\n",
            "Epoch: 890 | Train Loss: 0.00000 | Valid Loss: 0.42203 | Time: 0.22 seconds\n",
            "Epoch: 891 | Train Loss: 0.00000 | Valid Loss: 0.43516 | Time: 0.23 seconds\n",
            "Epoch: 892 | Train Loss: 0.00000 | Valid Loss: 0.43064 | Time: 0.23 seconds\n",
            "Epoch: 893 | Train Loss: 0.00000 | Valid Loss: 0.42610 | Time: 0.22 seconds\n",
            "Epoch: 894 | Train Loss: 0.00000 | Valid Loss: 0.43440 | Time: 0.23 seconds\n",
            "Epoch: 895 | Train Loss: 0.00000 | Valid Loss: 0.43184 | Time: 0.22 seconds\n",
            "Epoch: 896 | Train Loss: 0.00000 | Valid Loss: 0.42678 | Time: 0.22 seconds\n",
            "Epoch: 897 | Train Loss: 0.00000 | Valid Loss: 0.43087 | Time: 0.23 seconds\n",
            "Epoch: 898 | Train Loss: 0.00001 | Valid Loss: 0.42906 | Time: 0.22 seconds\n",
            "Epoch: 899 | Train Loss: 0.00000 | Valid Loss: 0.43228 | Time: 0.23 seconds\n",
            "Epoch: 900 | Train Loss: 0.00000 | Valid Loss: 0.42742 | Time: 0.22 seconds\n",
            "Epoch: 901 | Train Loss: 0.00000 | Valid Loss: 0.42946 | Time: 0.23 seconds\n",
            "Epoch: 902 | Train Loss: 0.00000 | Valid Loss: 0.42771 | Time: 0.22 seconds\n",
            "Epoch: 903 | Train Loss: 0.00001 | Valid Loss: 0.43061 | Time: 0.22 seconds\n",
            "Epoch: 904 | Train Loss: 0.00001 | Valid Loss: 0.43226 | Time: 0.22 seconds\n",
            "Epoch: 905 | Train Loss: 0.00000 | Valid Loss: 0.42482 | Time: 0.22 seconds\n",
            "Epoch: 906 | Train Loss: 0.00000 | Valid Loss: 0.42877 | Time: 0.22 seconds\n",
            "Epoch: 907 | Train Loss: 0.00001 | Valid Loss: 0.42265 | Time: 0.22 seconds\n",
            "Epoch: 908 | Train Loss: 0.00000 | Valid Loss: 0.41789 | Time: 0.23 seconds\n",
            "Epoch: 909 | Train Loss: 0.00000 | Valid Loss: 0.41355 | Time: 0.23 seconds\n",
            "Epoch: 910 | Train Loss: 0.00000 | Valid Loss: 0.42190 | Time: 0.23 seconds\n",
            "Epoch: 911 | Train Loss: 0.00001 | Valid Loss: 0.42325 | Time: 0.23 seconds\n",
            "Epoch: 912 | Train Loss: 0.00000 | Valid Loss: 0.42226 | Time: 0.22 seconds\n",
            "Epoch: 913 | Train Loss: 0.00001 | Valid Loss: 0.41931 | Time: 0.22 seconds\n",
            "Epoch: 914 | Train Loss: 0.00000 | Valid Loss: 0.42952 | Time: 0.22 seconds\n",
            "Epoch: 915 | Train Loss: 0.00000 | Valid Loss: 0.42581 | Time: 0.23 seconds\n",
            "Epoch: 916 | Train Loss: 0.00000 | Valid Loss: 0.41943 | Time: 0.22 seconds\n",
            "Epoch: 917 | Train Loss: 0.00000 | Valid Loss: 0.42422 | Time: 0.22 seconds\n",
            "Epoch: 918 | Train Loss: 0.00000 | Valid Loss: 0.42311 | Time: 0.22 seconds\n",
            "Epoch: 919 | Train Loss: 0.00000 | Valid Loss: 0.42274 | Time: 0.30 seconds\n",
            "Epoch: 920 | Train Loss: 0.00000 | Valid Loss: 0.42178 | Time: 0.22 seconds\n",
            "Epoch: 921 | Train Loss: 0.00000 | Valid Loss: 0.42740 | Time: 0.22 seconds\n",
            "Epoch: 922 | Train Loss: 0.00000 | Valid Loss: 0.42479 | Time: 0.22 seconds\n",
            "Epoch: 923 | Train Loss: 0.00000 | Valid Loss: 0.42951 | Time: 0.23 seconds\n",
            "Epoch: 924 | Train Loss: 0.00000 | Valid Loss: 0.42673 | Time: 0.22 seconds\n",
            "Epoch: 925 | Train Loss: 0.00003 | Valid Loss: 0.42467 | Time: 0.22 seconds\n",
            "Epoch: 926 | Train Loss: 0.00000 | Valid Loss: 0.42827 | Time: 0.23 seconds\n",
            "Epoch: 927 | Train Loss: 0.00000 | Valid Loss: 0.42803 | Time: 0.22 seconds\n",
            "Epoch: 928 | Train Loss: 0.00000 | Valid Loss: 0.42714 | Time: 0.23 seconds\n",
            "Epoch: 929 | Train Loss: 0.00000 | Valid Loss: 0.42420 | Time: 0.22 seconds\n",
            "Epoch: 930 | Train Loss: 0.00000 | Valid Loss: 0.42609 | Time: 0.22 seconds\n",
            "Epoch: 931 | Train Loss: 0.00004 | Valid Loss: 0.42685 | Time: 0.22 seconds\n",
            "Epoch: 932 | Train Loss: 0.00000 | Valid Loss: 0.43092 | Time: 0.22 seconds\n",
            "Epoch: 933 | Train Loss: 0.00001 | Valid Loss: 0.43325 | Time: 0.23 seconds\n",
            "Epoch: 934 | Train Loss: 0.00000 | Valid Loss: 0.43463 | Time: 0.22 seconds\n",
            "Epoch: 935 | Train Loss: 0.00002 | Valid Loss: 0.43050 | Time: 0.23 seconds\n",
            "Epoch: 936 | Train Loss: 0.00001 | Valid Loss: 0.43168 | Time: 0.23 seconds\n",
            "Epoch: 937 | Train Loss: 0.00000 | Valid Loss: 0.43525 | Time: 0.23 seconds\n",
            "Epoch: 938 | Train Loss: 0.00000 | Valid Loss: 0.43336 | Time: 0.22 seconds\n",
            "Epoch: 939 | Train Loss: 0.00000 | Valid Loss: 0.44285 | Time: 0.22 seconds\n",
            "Epoch: 940 | Train Loss: 0.00000 | Valid Loss: 0.43930 | Time: 0.22 seconds\n",
            "Epoch: 941 | Train Loss: 0.00000 | Valid Loss: 0.43756 | Time: 0.21 seconds\n",
            "Epoch: 942 | Train Loss: 0.00001 | Valid Loss: 0.43590 | Time: 0.22 seconds\n",
            "Epoch: 943 | Train Loss: 0.00000 | Valid Loss: 0.43858 | Time: 0.22 seconds\n",
            "Epoch: 944 | Train Loss: 0.00000 | Valid Loss: 0.43619 | Time: 0.22 seconds\n",
            "Epoch: 945 | Train Loss: 0.00000 | Valid Loss: 0.44042 | Time: 0.21 seconds\n",
            "Epoch: 946 | Train Loss: 0.00000 | Valid Loss: 0.44097 | Time: 0.23 seconds\n",
            "Epoch: 947 | Train Loss: 0.00000 | Valid Loss: 0.44055 | Time: 0.22 seconds\n",
            "Epoch: 948 | Train Loss: 0.00000 | Valid Loss: 0.44160 | Time: 0.22 seconds\n",
            "Epoch: 949 | Train Loss: 0.00000 | Valid Loss: 0.43877 | Time: 0.22 seconds\n",
            "Epoch: 950 | Train Loss: 0.00000 | Valid Loss: 0.43933 | Time: 0.22 seconds\n",
            "Epoch: 951 | Train Loss: 0.00000 | Valid Loss: 0.43392 | Time: 0.22 seconds\n",
            "Epoch: 952 | Train Loss: 0.00000 | Valid Loss: 0.44086 | Time: 0.23 seconds\n",
            "Epoch: 953 | Train Loss: 0.00000 | Valid Loss: 0.43850 | Time: 0.23 seconds\n",
            "Epoch: 954 | Train Loss: 0.00001 | Valid Loss: 0.43875 | Time: 0.23 seconds\n",
            "Epoch: 955 | Train Loss: 0.00001 | Valid Loss: 0.44128 | Time: 0.26 seconds\n",
            "Epoch: 956 | Train Loss: 0.00001 | Valid Loss: 0.44116 | Time: 0.23 seconds\n",
            "Epoch: 957 | Train Loss: 0.00000 | Valid Loss: 0.43785 | Time: 0.22 seconds\n",
            "Epoch: 958 | Train Loss: 0.00000 | Valid Loss: 0.43425 | Time: 0.22 seconds\n",
            "Epoch: 959 | Train Loss: 0.00000 | Valid Loss: 0.43628 | Time: 0.23 seconds\n",
            "Epoch: 960 | Train Loss: 0.00000 | Valid Loss: 0.44029 | Time: 0.23 seconds\n",
            "Epoch: 961 | Train Loss: 0.00000 | Valid Loss: 0.43691 | Time: 0.23 seconds\n",
            "Epoch: 962 | Train Loss: 0.00000 | Valid Loss: 0.43845 | Time: 0.30 seconds\n",
            "Epoch: 963 | Train Loss: 0.00000 | Valid Loss: 0.44010 | Time: 0.23 seconds\n",
            "Epoch: 964 | Train Loss: 0.00000 | Valid Loss: 0.44076 | Time: 0.23 seconds\n",
            "Epoch: 965 | Train Loss: 0.00000 | Valid Loss: 0.43271 | Time: 0.23 seconds\n",
            "Epoch: 966 | Train Loss: 0.00001 | Valid Loss: 0.43654 | Time: 0.23 seconds\n",
            "Epoch: 967 | Train Loss: 0.00000 | Valid Loss: 0.44315 | Time: 0.22 seconds\n",
            "Epoch: 968 | Train Loss: 0.00000 | Valid Loss: 0.43966 | Time: 0.22 seconds\n",
            "Epoch: 969 | Train Loss: 0.00000 | Valid Loss: 0.42940 | Time: 0.23 seconds\n",
            "Epoch: 970 | Train Loss: 0.00000 | Valid Loss: 0.43357 | Time: 0.22 seconds\n",
            "Epoch: 971 | Train Loss: 0.00000 | Valid Loss: 0.42667 | Time: 0.23 seconds\n",
            "Epoch: 972 | Train Loss: 0.00000 | Valid Loss: 0.43358 | Time: 0.23 seconds\n",
            "Epoch: 973 | Train Loss: 0.00010 | Valid Loss: 0.44325 | Time: 0.23 seconds\n",
            "Epoch: 974 | Train Loss: 0.00001 | Valid Loss: 0.43878 | Time: 0.22 seconds\n",
            "Epoch: 975 | Train Loss: 0.00000 | Valid Loss: 0.44295 | Time: 0.22 seconds\n",
            "Epoch: 976 | Train Loss: 0.00002 | Valid Loss: 0.44919 | Time: 0.22 seconds\n",
            "Epoch: 977 | Train Loss: 0.00001 | Valid Loss: 0.44553 | Time: 0.22 seconds\n",
            "Epoch: 978 | Train Loss: 0.00000 | Valid Loss: 0.44510 | Time: 0.22 seconds\n",
            "Epoch: 979 | Train Loss: 0.00001 | Valid Loss: 0.44089 | Time: 0.22 seconds\n",
            "Epoch: 980 | Train Loss: 0.00001 | Valid Loss: 0.44197 | Time: 0.22 seconds\n",
            "Epoch: 981 | Train Loss: 0.00000 | Valid Loss: 0.42896 | Time: 0.23 seconds\n",
            "Epoch: 982 | Train Loss: 0.00000 | Valid Loss: 0.43734 | Time: 0.23 seconds\n",
            "Epoch: 983 | Train Loss: 0.00000 | Valid Loss: 0.43638 | Time: 0.22 seconds\n",
            "Epoch: 984 | Train Loss: 0.00000 | Valid Loss: 0.43449 | Time: 0.22 seconds\n",
            "Epoch: 985 | Train Loss: 0.00000 | Valid Loss: 0.43197 | Time: 0.22 seconds\n",
            "Epoch: 986 | Train Loss: 0.00000 | Valid Loss: 0.44133 | Time: 0.22 seconds\n",
            "Epoch: 987 | Train Loss: 0.00000 | Valid Loss: 0.44088 | Time: 0.22 seconds\n",
            "Epoch: 988 | Train Loss: 0.00000 | Valid Loss: 0.44061 | Time: 0.22 seconds\n",
            "Epoch: 989 | Train Loss: 0.00000 | Valid Loss: 0.43906 | Time: 0.22 seconds\n",
            "Epoch: 990 | Train Loss: 0.00000 | Valid Loss: 0.42971 | Time: 0.22 seconds\n",
            "Epoch: 991 | Train Loss: 0.00000 | Valid Loss: 0.43242 | Time: 0.22 seconds\n",
            "Epoch: 992 | Train Loss: 0.00001 | Valid Loss: 0.43642 | Time: 0.22 seconds\n",
            "Epoch: 993 | Train Loss: 0.00000 | Valid Loss: 0.43991 | Time: 0.22 seconds\n",
            "Epoch: 994 | Train Loss: 0.00000 | Valid Loss: 0.44400 | Time: 0.22 seconds\n",
            "Epoch: 995 | Train Loss: 0.00001 | Valid Loss: 0.43843 | Time: 0.22 seconds\n",
            "Epoch: 996 | Train Loss: 0.00000 | Valid Loss: 0.43284 | Time: 0.22 seconds\n",
            "Epoch: 997 | Train Loss: 0.00000 | Valid Loss: 0.44170 | Time: 0.21 seconds\n",
            "Epoch: 998 | Train Loss: 0.00000 | Valid Loss: 0.43828 | Time: 0.22 seconds\n",
            "Epoch: 999 | Train Loss: 0.00000 | Valid Loss: 0.44224 | Time: 0.22 seconds\n",
            "Epoch: 1000 | Train Loss: 0.00001 | Valid Loss: 0.43616 | Time: 0.22 seconds\n",
            "\u001b[31m\n",
            "**************************************************\n",
            "\u001b[0m\n",
            "Best Validation Loss at Epoch ---> 909\n",
            "\u001b[31m\n",
            "**************************************************\n",
            "\u001b[0m\n",
            "Time Taken [1000 Epochs] : 3.75 minutes\n",
            "\u001b[31m\n",
            "**************************************************\n",
            "\u001b[0m\n",
            "Training Completed\n",
            "\u001b[31m\n",
            "**************************************************\n",
            "\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[31m\n",
            "**************************************************\n",
            "\u001b[0m\n",
            "Building Pretrained Models ...\n",
            "\u001b[31m\n",
            "**************************************************\n",
            "\u001b[0m\n",
            "Building Dataloaders ...\n",
            "\u001b[31m\n",
            "**************************************************\n",
            "\u001b[0m\n",
            "Building Classifier ...\n",
            "\u001b[31m\n",
            "**************************************************\n",
            "\u001b[0m\n",
            "Training ...\n",
            "\u001b[31m\n",
            "**************************************************\n",
            "\u001b[0m\n",
            "Epoch: 1 | Train Loss: 0.68764 | Valid Loss: 0.66617 | Train Accs : 0.58386 | Valid Accs : 0.65848 | Time: 0.37 seconds\n",
            "Epoch: 2 | Train Loss: 0.64502 | Valid Loss: 0.62515 | Train Accs : 0.68597 | Valid Accs : 0.71982 | Time: 0.35 seconds\n",
            "Epoch: 3 | Train Loss: 0.61153 | Valid Loss: 0.59969 | Train Accs : 0.72607 | Valid Accs : 0.73661 | Time: 0.35 seconds\n",
            "Epoch: 4 | Train Loss: 0.58820 | Valid Loss: 0.58301 | Train Accs : 0.74127 | Valid Accs : 0.75036 | Time: 0.36 seconds\n",
            "Epoch: 5 | Train Loss: 0.57464 | Valid Loss: 0.57153 | Train Accs : 0.75928 | Valid Accs : 0.76696 | Time: 0.36 seconds\n",
            "Epoch: 6 | Train Loss: 0.56414 | Valid Loss: 0.56089 | Train Accs : 0.77258 | Valid Accs : 0.77289 | Time: 0.43 seconds\n",
            "Epoch: 7 | Train Loss: 0.55691 | Valid Loss: 0.55467 | Train Accs : 0.77997 | Valid Accs : 0.78610 | Time: 0.37 seconds\n",
            "Epoch: 8 | Train Loss: 0.55006 | Valid Loss: 0.54936 | Train Accs : 0.79651 | Valid Accs : 0.78914 | Time: 0.36 seconds\n",
            "Epoch: 9 | Train Loss: 0.54632 | Valid Loss: 0.54432 | Train Accs : 0.79675 | Valid Accs : 0.79751 | Time: 0.36 seconds\n",
            "Epoch: 10 | Train Loss: 0.54220 | Valid Loss: 0.54113 | Train Accs : 0.80542 | Valid Accs : 0.79932 | Time: 0.36 seconds\n",
            "Epoch: 11 | Train Loss: 0.53978 | Valid Loss: 0.53692 | Train Accs : 0.80310 | Valid Accs : 0.80553 | Time: 0.42 seconds\n",
            "Epoch: 12 | Train Loss: 0.53503 | Valid Loss: 0.53530 | Train Accs : 0.81384 | Valid Accs : 0.81502 | Time: 0.36 seconds\n",
            "Epoch: 13 | Train Loss: 0.53163 | Valid Loss: 0.53305 | Train Accs : 0.81616 | Valid Accs : 0.81096 | Time: 0.36 seconds\n",
            "Epoch: 14 | Train Loss: 0.52942 | Valid Loss: 0.53000 | Train Accs : 0.81860 | Valid Accs : 0.81017 | Time: 0.36 seconds\n",
            "Epoch: 15 | Train Loss: 0.52850 | Valid Loss: 0.52824 | Train Accs : 0.82153 | Valid Accs : 0.81898 | Time: 0.37 seconds\n",
            "Epoch: 16 | Train Loss: 0.52644 | Valid Loss: 0.52670 | Train Accs : 0.82098 | Valid Accs : 0.82195 | Time: 0.43 seconds\n",
            "Epoch: 17 | Train Loss: 0.52489 | Valid Loss: 0.52448 | Train Accs : 0.82330 | Valid Accs : 0.82657 | Time: 0.36 seconds\n",
            "Epoch: 18 | Train Loss: 0.52376 | Valid Loss: 0.52468 | Train Accs : 0.82910 | Valid Accs : 0.82444 | Time: 0.37 seconds\n",
            "Epoch: 19 | Train Loss: 0.52184 | Valid Loss: 0.52288 | Train Accs : 0.83069 | Valid Accs : 0.82396 | Time: 0.37 seconds\n",
            "Epoch: 20 | Train Loss: 0.52187 | Valid Loss: 0.52068 | Train Accs : 0.83020 | Valid Accs : 0.83190 | Time: 0.36 seconds\n",
            "Epoch: 21 | Train Loss: 0.52054 | Valid Loss: 0.52008 | Train Accs : 0.83380 | Valid Accs : 0.82899 | Time: 0.42 seconds\n",
            "Epoch: 22 | Train Loss: 0.51855 | Valid Loss: 0.51986 | Train Accs : 0.83588 | Valid Accs : 0.82782 | Time: 0.36 seconds\n",
            "Epoch: 23 | Train Loss: 0.52019 | Valid Loss: 0.51729 | Train Accs : 0.83374 | Valid Accs : 0.82643 | Time: 0.36 seconds\n",
            "Epoch: 24 | Train Loss: 0.51772 | Valid Loss: 0.51687 | Train Accs : 0.83765 | Valid Accs : 0.83845 | Time: 0.37 seconds\n",
            "Epoch: 25 | Train Loss: 0.51688 | Valid Loss: 0.51564 | Train Accs : 0.83740 | Valid Accs : 0.83070 | Time: 0.36 seconds\n",
            "Epoch: 26 | Train Loss: 0.51620 | Valid Loss: 0.51658 | Train Accs : 0.83856 | Valid Accs : 0.83385 | Time: 0.42 seconds\n",
            "Epoch: 27 | Train Loss: 0.51590 | Valid Loss: 0.51590 | Train Accs : 0.83789 | Valid Accs : 0.83712 | Time: 0.35 seconds\n",
            "Epoch: 28 | Train Loss: 0.51548 | Valid Loss: 0.51604 | Train Accs : 0.84070 | Valid Accs : 0.84003 | Time: 0.35 seconds\n",
            "Epoch: 29 | Train Loss: 0.51429 | Valid Loss: 0.51350 | Train Accs : 0.84088 | Valid Accs : 0.83907 | Time: 0.37 seconds\n",
            "Epoch: 30 | Train Loss: 0.51363 | Valid Loss: 0.51363 | Train Accs : 0.84082 | Valid Accs : 0.83979 | Time: 0.36 seconds\n",
            "Epoch: 31 | Train Loss: 0.51424 | Valid Loss: 0.51315 | Train Accs : 0.84241 | Valid Accs : 0.83943 | Time: 0.43 seconds\n",
            "Epoch: 32 | Train Loss: 0.51318 | Valid Loss: 0.51379 | Train Accs : 0.84064 | Valid Accs : 0.84052 | Time: 0.35 seconds\n",
            "Epoch: 33 | Train Loss: 0.51262 | Valid Loss: 0.51241 | Train Accs : 0.84247 | Valid Accs : 0.84136 | Time: 0.37 seconds\n",
            "Epoch: 34 | Train Loss: 0.51292 | Valid Loss: 0.51274 | Train Accs : 0.84424 | Valid Accs : 0.83979 | Time: 0.36 seconds\n",
            "Epoch: 35 | Train Loss: 0.51117 | Valid Loss: 0.51141 | Train Accs : 0.84436 | Valid Accs : 0.84476 | Time: 0.37 seconds\n",
            "Epoch: 36 | Train Loss: 0.51161 | Valid Loss: 0.51217 | Train Accs : 0.84308 | Valid Accs : 0.83870 | Time: 0.42 seconds\n",
            "Epoch: 37 | Train Loss: 0.51120 | Valid Loss: 0.51066 | Train Accs : 0.84369 | Valid Accs : 0.84512 | Time: 0.37 seconds\n",
            "Epoch: 38 | Train Loss: 0.51199 | Valid Loss: 0.51058 | Train Accs : 0.84326 | Valid Accs : 0.84422 | Time: 0.35 seconds\n",
            "Epoch: 39 | Train Loss: 0.51211 | Valid Loss: 0.51063 | Train Accs : 0.84082 | Valid Accs : 0.84713 | Time: 0.36 seconds\n",
            "Epoch: 40 | Train Loss: 0.51008 | Valid Loss: 0.50949 | Train Accs : 0.84772 | Valid Accs : 0.84229 | Time: 0.36 seconds\n",
            "Epoch: 41 | Train Loss: 0.51056 | Valid Loss: 0.50899 | Train Accs : 0.84644 | Valid Accs : 0.84580 | Time: 0.43 seconds\n",
            "Epoch: 42 | Train Loss: 0.51159 | Valid Loss: 0.50983 | Train Accs : 0.84479 | Valid Accs : 0.84681 | Time: 0.37 seconds\n",
            "Epoch: 43 | Train Loss: 0.50996 | Valid Loss: 0.51008 | Train Accs : 0.84467 | Valid Accs : 0.84493 | Time: 0.36 seconds\n",
            "Epoch: 44 | Train Loss: 0.51070 | Valid Loss: 0.50859 | Train Accs : 0.84741 | Valid Accs : 0.84411 | Time: 0.36 seconds\n",
            "Epoch: 45 | Train Loss: 0.51015 | Valid Loss: 0.50773 | Train Accs : 0.84460 | Valid Accs : 0.84908 | Time: 0.37 seconds\n",
            "Epoch: 46 | Train Loss: 0.50786 | Valid Loss: 0.50892 | Train Accs : 0.84698 | Valid Accs : 0.84694 | Time: 0.42 seconds\n",
            "Epoch: 47 | Train Loss: 0.51075 | Valid Loss: 0.50894 | Train Accs : 0.84882 | Valid Accs : 0.84428 | Time: 0.36 seconds\n",
            "Epoch: 48 | Train Loss: 0.50997 | Valid Loss: 0.50778 | Train Accs : 0.84814 | Valid Accs : 0.84816 | Time: 0.35 seconds\n",
            "Epoch: 49 | Train Loss: 0.50899 | Valid Loss: 0.50964 | Train Accs : 0.84735 | Valid Accs : 0.84912 | Time: 0.35 seconds\n",
            "Epoch: 50 | Train Loss: 0.50992 | Valid Loss: 0.50941 | Train Accs : 0.84656 | Valid Accs : 0.84437 | Time: 0.37 seconds\n",
            "Epoch: 51 | Train Loss: 0.50860 | Valid Loss: 0.50763 | Train Accs : 0.84491 | Valid Accs : 0.84816 | Time: 0.42 seconds\n",
            "Epoch: 52 | Train Loss: 0.50784 | Valid Loss: 0.50765 | Train Accs : 0.84955 | Valid Accs : 0.84906 | Time: 0.36 seconds\n",
            "Epoch: 53 | Train Loss: 0.50726 | Valid Loss: 0.50813 | Train Accs : 0.84760 | Valid Accs : 0.84809 | Time: 0.36 seconds\n",
            "Epoch: 54 | Train Loss: 0.51025 | Valid Loss: 0.50754 | Train Accs : 0.84668 | Valid Accs : 0.84798 | Time: 0.36 seconds\n",
            "Epoch: 55 | Train Loss: 0.50774 | Valid Loss: 0.50636 | Train Accs : 0.84808 | Valid Accs : 0.85263 | Time: 0.36 seconds\n",
            "Epoch: 56 | Train Loss: 0.50948 | Valid Loss: 0.50586 | Train Accs : 0.84497 | Valid Accs : 0.85198 | Time: 0.45 seconds\n",
            "Epoch: 57 | Train Loss: 0.50805 | Valid Loss: 0.50538 | Train Accs : 0.84698 | Valid Accs : 0.85301 | Time: 0.36 seconds\n",
            "Epoch: 58 | Train Loss: 0.50962 | Valid Loss: 0.50601 | Train Accs : 0.84839 | Valid Accs : 0.84961 | Time: 0.37 seconds\n",
            "Epoch: 59 | Train Loss: 0.50869 | Valid Loss: 0.50683 | Train Accs : 0.84796 | Valid Accs : 0.85081 | Time: 0.35 seconds\n",
            "Epoch: 60 | Train Loss: 0.50809 | Valid Loss: 0.50589 | Train Accs : 0.84924 | Valid Accs : 0.85094 | Time: 0.37 seconds\n",
            "Epoch: 61 | Train Loss: 0.50780 | Valid Loss: 0.50573 | Train Accs : 0.84821 | Valid Accs : 0.85126 | Time: 0.43 seconds\n",
            "Epoch: 62 | Train Loss: 0.50916 | Valid Loss: 0.50638 | Train Accs : 0.84875 | Valid Accs : 0.85306 | Time: 0.37 seconds\n",
            "Epoch: 63 | Train Loss: 0.50715 | Valid Loss: 0.50543 | Train Accs : 0.84918 | Valid Accs : 0.85077 | Time: 0.36 seconds\n",
            "Epoch: 64 | Train Loss: 0.50701 | Valid Loss: 0.50579 | Train Accs : 0.84900 | Valid Accs : 0.85483 | Time: 0.37 seconds\n",
            "Epoch: 65 | Train Loss: 0.50526 | Valid Loss: 0.50671 | Train Accs : 0.85193 | Valid Accs : 0.85081 | Time: 0.35 seconds\n",
            "Epoch: 66 | Train Loss: 0.50740 | Valid Loss: 0.50616 | Train Accs : 0.84747 | Valid Accs : 0.85402 | Time: 0.42 seconds\n",
            "Epoch: 67 | Train Loss: 0.50788 | Valid Loss: 0.50622 | Train Accs : 0.84821 | Valid Accs : 0.85113 | Time: 0.35 seconds\n",
            "Epoch: 68 | Train Loss: 0.50716 | Valid Loss: 0.50687 | Train Accs : 0.85028 | Valid Accs : 0.84752 | Time: 0.35 seconds\n",
            "Epoch: 69 | Train Loss: 0.50610 | Valid Loss: 0.50628 | Train Accs : 0.84863 | Valid Accs : 0.85258 | Time: 0.35 seconds\n",
            "Epoch: 70 | Train Loss: 0.50619 | Valid Loss: 0.50526 | Train Accs : 0.85089 | Valid Accs : 0.85312 | Time: 0.35 seconds\n",
            "Epoch: 71 | Train Loss: 0.50587 | Valid Loss: 0.50606 | Train Accs : 0.85101 | Valid Accs : 0.85143 | Time: 0.42 seconds\n",
            "Epoch: 72 | Train Loss: 0.50762 | Valid Loss: 0.50692 | Train Accs : 0.85034 | Valid Accs : 0.85040 | Time: 0.36 seconds\n",
            "Epoch: 73 | Train Loss: 0.50666 | Valid Loss: 0.50413 | Train Accs : 0.85095 | Valid Accs : 0.85614 | Time: 0.36 seconds\n",
            "Epoch: 74 | Train Loss: 0.50905 | Valid Loss: 0.50588 | Train Accs : 0.85101 | Valid Accs : 0.84961 | Time: 0.35 seconds\n",
            "Epoch: 75 | Train Loss: 0.50571 | Valid Loss: 0.50570 | Train Accs : 0.84955 | Valid Accs : 0.85184 | Time: 0.36 seconds\n",
            "Epoch: 76 | Train Loss: 0.50601 | Valid Loss: 0.50567 | Train Accs : 0.85028 | Valid Accs : 0.85301 | Time: 0.41 seconds\n",
            "Epoch: 77 | Train Loss: 0.50488 | Valid Loss: 0.50573 | Train Accs : 0.85052 | Valid Accs : 0.85293 | Time: 0.36 seconds\n",
            "Epoch: 78 | Train Loss: 0.50712 | Valid Loss: 0.50670 | Train Accs : 0.85077 | Valid Accs : 0.85141 | Time: 0.36 seconds\n",
            "Epoch: 79 | Train Loss: 0.50495 | Valid Loss: 0.50520 | Train Accs : 0.85028 | Valid Accs : 0.85575 | Time: 0.39 seconds\n",
            "Epoch: 80 | Train Loss: 0.50645 | Valid Loss: 0.50455 | Train Accs : 0.85065 | Valid Accs : 0.85628 | Time: 0.37 seconds\n",
            "Epoch: 81 | Train Loss: 0.50489 | Valid Loss: 0.50644 | Train Accs : 0.84998 | Valid Accs : 0.85286 | Time: 0.43 seconds\n",
            "Epoch: 82 | Train Loss: 0.50518 | Valid Loss: 0.50602 | Train Accs : 0.85236 | Valid Accs : 0.84942 | Time: 0.37 seconds\n",
            "Epoch: 83 | Train Loss: 0.50511 | Valid Loss: 0.50593 | Train Accs : 0.85175 | Valid Accs : 0.85288 | Time: 0.36 seconds\n",
            "Epoch: 84 | Train Loss: 0.50685 | Valid Loss: 0.50444 | Train Accs : 0.84967 | Valid Accs : 0.85367 | Time: 0.35 seconds\n",
            "Epoch: 85 | Train Loss: 0.50685 | Valid Loss: 0.50514 | Train Accs : 0.85150 | Valid Accs : 0.85306 | Time: 0.36 seconds\n",
            "Epoch: 86 | Train Loss: 0.50513 | Valid Loss: 0.50606 | Train Accs : 0.85028 | Valid Accs : 0.85171 | Time: 0.42 seconds\n",
            "Epoch: 87 | Train Loss: 0.50562 | Valid Loss: 0.50567 | Train Accs : 0.85022 | Valid Accs : 0.85577 | Time: 0.35 seconds\n",
            "Epoch: 88 | Train Loss: 0.50783 | Valid Loss: 0.50479 | Train Accs : 0.85034 | Valid Accs : 0.85337 | Time: 0.35 seconds\n",
            "Epoch: 89 | Train Loss: 0.50777 | Valid Loss: 0.50518 | Train Accs : 0.85016 | Valid Accs : 0.85261 | Time: 0.36 seconds\n",
            "Epoch: 90 | Train Loss: 0.50409 | Valid Loss: 0.50452 | Train Accs : 0.85022 | Valid Accs : 0.85631 | Time: 0.35 seconds\n",
            "Epoch: 91 | Train Loss: 0.50458 | Valid Loss: 0.50685 | Train Accs : 0.85248 | Valid Accs : 0.85049 | Time: 0.42 seconds\n",
            "Epoch: 92 | Train Loss: 0.50595 | Valid Loss: 0.50541 | Train Accs : 0.85010 | Valid Accs : 0.85626 | Time: 0.35 seconds\n",
            "Epoch: 93 | Train Loss: 0.50470 | Valid Loss: 0.50532 | Train Accs : 0.85223 | Valid Accs : 0.85305 | Time: 0.35 seconds\n",
            "Epoch: 94 | Train Loss: 0.50544 | Valid Loss: 0.50566 | Train Accs : 0.85052 | Valid Accs : 0.85098 | Time: 0.36 seconds\n",
            "Epoch: 95 | Train Loss: 0.50531 | Valid Loss: 0.50487 | Train Accs : 0.85223 | Valid Accs : 0.85626 | Time: 0.35 seconds\n",
            "Epoch: 96 | Train Loss: 0.50499 | Valid Loss: 0.50613 | Train Accs : 0.84918 | Valid Accs : 0.85406 | Time: 0.42 seconds\n",
            "Epoch: 97 | Train Loss: 0.50745 | Valid Loss: 0.50386 | Train Accs : 0.84821 | Valid Accs : 0.85560 | Time: 0.37 seconds\n",
            "Epoch: 98 | Train Loss: 0.50614 | Valid Loss: 0.50571 | Train Accs : 0.85101 | Valid Accs : 0.85421 | Time: 0.35 seconds\n",
            "Epoch: 99 | Train Loss: 0.50489 | Valid Loss: 0.50385 | Train Accs : 0.85016 | Valid Accs : 0.85845 | Time: 0.36 seconds\n",
            "Epoch: 100 | Train Loss: 0.50506 | Valid Loss: 0.50505 | Train Accs : 0.85266 | Valid Accs : 0.85331 | Time: 0.35 seconds\n",
            "Epoch: 101 | Train Loss: 0.50676 | Valid Loss: 0.50521 | Train Accs : 0.85040 | Valid Accs : 0.85778 | Time: 0.41 seconds\n",
            "Epoch: 102 | Train Loss: 0.50716 | Valid Loss: 0.50527 | Train Accs : 0.84967 | Valid Accs : 0.85979 | Time: 0.37 seconds\n",
            "Epoch: 103 | Train Loss: 0.50616 | Valid Loss: 0.50564 | Train Accs : 0.85175 | Valid Accs : 0.85387 | Time: 0.35 seconds\n",
            "Epoch: 104 | Train Loss: 0.50572 | Valid Loss: 0.50616 | Train Accs : 0.85266 | Valid Accs : 0.85019 | Time: 0.35 seconds\n",
            "Epoch: 105 | Train Loss: 0.50488 | Valid Loss: 0.50479 | Train Accs : 0.84882 | Valid Accs : 0.85716 | Time: 0.37 seconds\n",
            "Epoch: 106 | Train Loss: 0.50512 | Valid Loss: 0.50531 | Train Accs : 0.85132 | Valid Accs : 0.85722 | Time: 0.42 seconds\n",
            "Epoch: 107 | Train Loss: 0.50675 | Valid Loss: 0.50529 | Train Accs : 0.84998 | Valid Accs : 0.85506 | Time: 0.36 seconds\n",
            "Epoch: 108 | Train Loss: 0.50605 | Valid Loss: 0.50487 | Train Accs : 0.85175 | Valid Accs : 0.85675 | Time: 0.36 seconds\n",
            "Epoch: 109 | Train Loss: 0.50447 | Valid Loss: 0.50329 | Train Accs : 0.85236 | Valid Accs : 0.85699 | Time: 0.36 seconds\n",
            "Epoch: 110 | Train Loss: 0.50614 | Valid Loss: 0.50422 | Train Accs : 0.84991 | Valid Accs : 0.85691 | Time: 0.36 seconds\n",
            "Epoch: 111 | Train Loss: 0.50480 | Valid Loss: 0.50499 | Train Accs : 0.85071 | Valid Accs : 0.85408 | Time: 0.42 seconds\n",
            "Epoch: 112 | Train Loss: 0.50560 | Valid Loss: 0.50449 | Train Accs : 0.84979 | Valid Accs : 0.85498 | Time: 0.36 seconds\n",
            "Epoch: 113 | Train Loss: 0.50567 | Valid Loss: 0.50609 | Train Accs : 0.84888 | Valid Accs : 0.85199 | Time: 0.36 seconds\n",
            "Epoch: 114 | Train Loss: 0.50591 | Valid Loss: 0.50466 | Train Accs : 0.84991 | Valid Accs : 0.85660 | Time: 0.35 seconds\n",
            "Epoch: 115 | Train Loss: 0.50516 | Valid Loss: 0.50513 | Train Accs : 0.85046 | Valid Accs : 0.85290 | Time: 0.35 seconds\n",
            "Epoch: 116 | Train Loss: 0.50469 | Valid Loss: 0.50490 | Train Accs : 0.85150 | Valid Accs : 0.85491 | Time: 0.42 seconds\n",
            "Epoch: 117 | Train Loss: 0.50655 | Valid Loss: 0.50399 | Train Accs : 0.84961 | Valid Accs : 0.85496 | Time: 0.36 seconds\n",
            "Epoch: 118 | Train Loss: 0.50635 | Valid Loss: 0.50419 | Train Accs : 0.85211 | Valid Accs : 0.85346 | Time: 0.36 seconds\n",
            "Epoch: 119 | Train Loss: 0.50722 | Valid Loss: 0.50372 | Train Accs : 0.84949 | Valid Accs : 0.85812 | Time: 0.35 seconds\n",
            "Epoch: 120 | Train Loss: 0.50794 | Valid Loss: 0.50421 | Train Accs : 0.84949 | Valid Accs : 0.85468 | Time: 0.36 seconds\n",
            "Epoch: 121 | Train Loss: 0.50645 | Valid Loss: 0.50446 | Train Accs : 0.84802 | Valid Accs : 0.85464 | Time: 0.42 seconds\n",
            "Epoch: 122 | Train Loss: 0.50505 | Valid Loss: 0.50627 | Train Accs : 0.85144 | Valid Accs : 0.85059 | Time: 0.35 seconds\n",
            "Epoch: 123 | Train Loss: 0.50575 | Valid Loss: 0.50426 | Train Accs : 0.84967 | Valid Accs : 0.85656 | Time: 0.35 seconds\n",
            "Epoch: 124 | Train Loss: 0.50751 | Valid Loss: 0.50368 | Train Accs : 0.85040 | Valid Accs : 0.85787 | Time: 0.36 seconds\n",
            "Epoch: 125 | Train Loss: 0.50535 | Valid Loss: 0.50388 | Train Accs : 0.85156 | Valid Accs : 0.85498 | Time: 0.35 seconds\n",
            "Epoch: 126 | Train Loss: 0.50409 | Valid Loss: 0.50418 | Train Accs : 0.85187 | Valid Accs : 0.85630 | Time: 0.42 seconds\n",
            "Epoch: 127 | Train Loss: 0.50430 | Valid Loss: 0.50431 | Train Accs : 0.85120 | Valid Accs : 0.85586 | Time: 0.35 seconds\n",
            "Epoch: 128 | Train Loss: 0.50406 | Valid Loss: 0.50487 | Train Accs : 0.85193 | Valid Accs : 0.85434 | Time: 0.35 seconds\n",
            "Epoch: 129 | Train Loss: 0.50577 | Valid Loss: 0.50563 | Train Accs : 0.84821 | Valid Accs : 0.85477 | Time: 0.35 seconds\n",
            "Epoch: 130 | Train Loss: 0.50602 | Valid Loss: 0.50435 | Train Accs : 0.84918 | Valid Accs : 0.85618 | Time: 0.35 seconds\n",
            "Epoch: 131 | Train Loss: 0.50475 | Valid Loss: 0.50464 | Train Accs : 0.85150 | Valid Accs : 0.85588 | Time: 0.43 seconds\n",
            "Epoch: 132 | Train Loss: 0.50602 | Valid Loss: 0.50448 | Train Accs : 0.85181 | Valid Accs : 0.85564 | Time: 0.36 seconds\n",
            "Epoch: 133 | Train Loss: 0.50687 | Valid Loss: 0.50485 | Train Accs : 0.84839 | Valid Accs : 0.85539 | Time: 0.36 seconds\n",
            "Epoch: 134 | Train Loss: 0.50617 | Valid Loss: 0.50425 | Train Accs : 0.85059 | Valid Accs : 0.85519 | Time: 0.36 seconds\n",
            "Epoch: 135 | Train Loss: 0.50612 | Valid Loss: 0.50479 | Train Accs : 0.85034 | Valid Accs : 0.85485 | Time: 0.36 seconds\n",
            "Epoch: 136 | Train Loss: 0.50433 | Valid Loss: 0.50517 | Train Accs : 0.85242 | Valid Accs : 0.85618 | Time: 0.42 seconds\n",
            "Epoch: 137 | Train Loss: 0.50686 | Valid Loss: 0.50371 | Train Accs : 0.84991 | Valid Accs : 0.85515 | Time: 0.36 seconds\n",
            "Epoch: 138 | Train Loss: 0.50731 | Valid Loss: 0.50518 | Train Accs : 0.84741 | Valid Accs : 0.85654 | Time: 0.35 seconds\n",
            "Epoch: 139 | Train Loss: 0.50537 | Valid Loss: 0.50348 | Train Accs : 0.84930 | Valid Accs : 0.85690 | Time: 0.35 seconds\n",
            "Epoch: 140 | Train Loss: 0.50507 | Valid Loss: 0.50453 | Train Accs : 0.84998 | Valid Accs : 0.85665 | Time: 0.35 seconds\n",
            "Epoch: 141 | Train Loss: 0.50384 | Valid Loss: 0.50482 | Train Accs : 0.85199 | Valid Accs : 0.85545 | Time: 0.42 seconds\n",
            "Epoch: 142 | Train Loss: 0.50562 | Valid Loss: 0.50353 | Train Accs : 0.85022 | Valid Accs : 0.85799 | Time: 0.36 seconds\n",
            "Epoch: 143 | Train Loss: 0.50367 | Valid Loss: 0.50591 | Train Accs : 0.85065 | Valid Accs : 0.85562 | Time: 0.36 seconds\n",
            "Epoch: 144 | Train Loss: 0.50485 | Valid Loss: 0.50451 | Train Accs : 0.85004 | Valid Accs : 0.85545 | Time: 0.35 seconds\n",
            "Epoch: 145 | Train Loss: 0.50623 | Valid Loss: 0.50263 | Train Accs : 0.85187 | Valid Accs : 0.85791 | Time: 0.35 seconds\n",
            "Epoch: 146 | Train Loss: 0.50385 | Valid Loss: 0.50462 | Train Accs : 0.84906 | Valid Accs : 0.85757 | Time: 0.43 seconds\n",
            "Epoch: 147 | Train Loss: 0.50684 | Valid Loss: 0.50472 | Train Accs : 0.84827 | Valid Accs : 0.85558 | Time: 0.35 seconds\n",
            "Epoch: 148 | Train Loss: 0.50596 | Valid Loss: 0.50389 | Train Accs : 0.84973 | Valid Accs : 0.85750 | Time: 0.35 seconds\n",
            "Epoch: 149 | Train Loss: 0.50519 | Valid Loss: 0.50589 | Train Accs : 0.84967 | Valid Accs : 0.85412 | Time: 0.36 seconds\n",
            "Epoch: 150 | Train Loss: 0.50576 | Valid Loss: 0.50317 | Train Accs : 0.84949 | Valid Accs : 0.85812 | Time: 0.35 seconds\n",
            "Epoch: 151 | Train Loss: 0.50700 | Valid Loss: 0.50503 | Train Accs : 0.85132 | Valid Accs : 0.85477 | Time: 0.46 seconds\n",
            "Epoch: 152 | Train Loss: 0.50645 | Valid Loss: 0.50415 | Train Accs : 0.85034 | Valid Accs : 0.85800 | Time: 0.36 seconds\n",
            "Epoch: 153 | Train Loss: 0.50471 | Valid Loss: 0.50528 | Train Accs : 0.84967 | Valid Accs : 0.85494 | Time: 0.35 seconds\n",
            "Epoch: 154 | Train Loss: 0.50423 | Valid Loss: 0.50399 | Train Accs : 0.84900 | Valid Accs : 0.85641 | Time: 0.36 seconds\n",
            "Epoch: 155 | Train Loss: 0.50482 | Valid Loss: 0.50378 | Train Accs : 0.85156 | Valid Accs : 0.85551 | Time: 0.35 seconds\n",
            "Epoch: 156 | Train Loss: 0.50432 | Valid Loss: 0.50540 | Train Accs : 0.85199 | Valid Accs : 0.85391 | Time: 0.42 seconds\n",
            "Epoch: 157 | Train Loss: 0.50673 | Valid Loss: 0.50367 | Train Accs : 0.84979 | Valid Accs : 0.85652 | Time: 0.36 seconds\n",
            "Epoch: 158 | Train Loss: 0.50566 | Valid Loss: 0.50461 | Train Accs : 0.84869 | Valid Accs : 0.85770 | Time: 0.35 seconds\n",
            "Epoch: 159 | Train Loss: 0.50591 | Valid Loss: 0.50350 | Train Accs : 0.84949 | Valid Accs : 0.85799 | Time: 0.36 seconds\n",
            "Epoch: 160 | Train Loss: 0.50528 | Valid Loss: 0.50521 | Train Accs : 0.85248 | Valid Accs : 0.85382 | Time: 0.36 seconds\n",
            "Epoch: 161 | Train Loss: 0.50381 | Valid Loss: 0.50333 | Train Accs : 0.85199 | Valid Accs : 0.85678 | Time: 0.42 seconds\n",
            "Epoch: 162 | Train Loss: 0.50475 | Valid Loss: 0.50477 | Train Accs : 0.85168 | Valid Accs : 0.85399 | Time: 0.36 seconds\n",
            "Epoch: 163 | Train Loss: 0.50508 | Valid Loss: 0.50388 | Train Accs : 0.85010 | Valid Accs : 0.85720 | Time: 0.36 seconds\n",
            "Epoch: 164 | Train Loss: 0.50568 | Valid Loss: 0.50554 | Train Accs : 0.85034 | Valid Accs : 0.85282 | Time: 0.35 seconds\n",
            "Epoch: 165 | Train Loss: 0.50405 | Valid Loss: 0.50456 | Train Accs : 0.85138 | Valid Accs : 0.85804 | Time: 0.35 seconds\n",
            "Epoch: 166 | Train Loss: 0.50464 | Valid Loss: 0.50372 | Train Accs : 0.85089 | Valid Accs : 0.85782 | Time: 0.42 seconds\n",
            "Epoch: 167 | Train Loss: 0.50485 | Valid Loss: 0.50389 | Train Accs : 0.84882 | Valid Accs : 0.85459 | Time: 0.36 seconds\n",
            "Epoch: 168 | Train Loss: 0.50644 | Valid Loss: 0.50474 | Train Accs : 0.84833 | Valid Accs : 0.85513 | Time: 0.36 seconds\n",
            "Epoch: 169 | Train Loss: 0.50428 | Valid Loss: 0.50608 | Train Accs : 0.85211 | Valid Accs : 0.85199 | Time: 0.36 seconds\n",
            "Epoch: 170 | Train Loss: 0.50777 | Valid Loss: 0.50505 | Train Accs : 0.85010 | Valid Accs : 0.85222 | Time: 0.36 seconds\n",
            "Epoch: 171 | Train Loss: 0.50706 | Valid Loss: 0.50519 | Train Accs : 0.85120 | Valid Accs : 0.85104 | Time: 0.42 seconds\n",
            "Epoch: 172 | Train Loss: 0.50530 | Valid Loss: 0.50462 | Train Accs : 0.85083 | Valid Accs : 0.85738 | Time: 0.36 seconds\n",
            "Epoch: 173 | Train Loss: 0.50434 | Valid Loss: 0.50470 | Train Accs : 0.85156 | Valid Accs : 0.85532 | Time: 0.36 seconds\n",
            "Epoch: 174 | Train Loss: 0.50436 | Valid Loss: 0.50612 | Train Accs : 0.85248 | Valid Accs : 0.85352 | Time: 0.36 seconds\n",
            "Epoch: 175 | Train Loss: 0.50498 | Valid Loss: 0.50475 | Train Accs : 0.84839 | Valid Accs : 0.85641 | Time: 0.36 seconds\n",
            "Epoch: 176 | Train Loss: 0.50424 | Valid Loss: 0.50282 | Train Accs : 0.85150 | Valid Accs : 0.85823 | Time: 0.42 seconds\n",
            "Epoch: 177 | Train Loss: 0.50450 | Valid Loss: 0.50412 | Train Accs : 0.85126 | Valid Accs : 0.85554 | Time: 0.35 seconds\n",
            "Epoch: 178 | Train Loss: 0.50583 | Valid Loss: 0.50532 | Train Accs : 0.85052 | Valid Accs : 0.85350 | Time: 0.35 seconds\n",
            "Epoch: 179 | Train Loss: 0.50506 | Valid Loss: 0.50436 | Train Accs : 0.84979 | Valid Accs : 0.85596 | Time: 0.35 seconds\n",
            "Epoch: 180 | Train Loss: 0.50381 | Valid Loss: 0.50435 | Train Accs : 0.84943 | Valid Accs : 0.85367 | Time: 0.36 seconds\n",
            "Epoch: 181 | Train Loss: 0.50576 | Valid Loss: 0.50328 | Train Accs : 0.84821 | Valid Accs : 0.85660 | Time: 0.43 seconds\n",
            "Epoch: 182 | Train Loss: 0.50676 | Valid Loss: 0.50399 | Train Accs : 0.84918 | Valid Accs : 0.85421 | Time: 0.35 seconds\n",
            "Epoch: 183 | Train Loss: 0.50581 | Valid Loss: 0.50480 | Train Accs : 0.84882 | Valid Accs : 0.85579 | Time: 0.35 seconds\n",
            "Epoch: 184 | Train Loss: 0.50688 | Valid Loss: 0.50406 | Train Accs : 0.84924 | Valid Accs : 0.85690 | Time: 0.36 seconds\n",
            "Epoch: 185 | Train Loss: 0.50338 | Valid Loss: 0.50500 | Train Accs : 0.85132 | Valid Accs : 0.85639 | Time: 0.35 seconds\n",
            "Epoch: 186 | Train Loss: 0.50713 | Valid Loss: 0.50395 | Train Accs : 0.84753 | Valid Accs : 0.85568 | Time: 0.42 seconds\n",
            "Epoch: 187 | Train Loss: 0.50370 | Valid Loss: 0.50392 | Train Accs : 0.85138 | Valid Accs : 0.85605 | Time: 0.36 seconds\n",
            "Epoch: 188 | Train Loss: 0.50570 | Valid Loss: 0.50527 | Train Accs : 0.84930 | Valid Accs : 0.85479 | Time: 0.36 seconds\n",
            "Epoch: 189 | Train Loss: 0.50506 | Valid Loss: 0.50425 | Train Accs : 0.85156 | Valid Accs : 0.85543 | Time: 0.35 seconds\n",
            "Epoch: 190 | Train Loss: 0.50452 | Valid Loss: 0.50401 | Train Accs : 0.84937 | Valid Accs : 0.85701 | Time: 0.35 seconds\n",
            "Epoch: 191 | Train Loss: 0.50503 | Valid Loss: 0.50422 | Train Accs : 0.85065 | Valid Accs : 0.85641 | Time: 0.43 seconds\n",
            "Epoch: 192 | Train Loss: 0.50498 | Valid Loss: 0.50384 | Train Accs : 0.84869 | Valid Accs : 0.85579 | Time: 0.36 seconds\n",
            "Epoch: 193 | Train Loss: 0.50473 | Valid Loss: 0.50430 | Train Accs : 0.85071 | Valid Accs : 0.85410 | Time: 0.35 seconds\n",
            "Epoch: 194 | Train Loss: 0.50815 | Valid Loss: 0.50420 | Train Accs : 0.84906 | Valid Accs : 0.85603 | Time: 0.36 seconds\n",
            "Epoch: 195 | Train Loss: 0.50385 | Valid Loss: 0.50408 | Train Accs : 0.85138 | Valid Accs : 0.85755 | Time: 0.36 seconds\n",
            "Epoch: 196 | Train Loss: 0.50495 | Valid Loss: 0.50543 | Train Accs : 0.85248 | Valid Accs : 0.85368 | Time: 0.42 seconds\n",
            "Epoch: 197 | Train Loss: 0.50815 | Valid Loss: 0.50484 | Train Accs : 0.84576 | Valid Accs : 0.85318 | Time: 0.36 seconds\n",
            "Epoch: 198 | Train Loss: 0.50507 | Valid Loss: 0.50497 | Train Accs : 0.84985 | Valid Accs : 0.85447 | Time: 0.36 seconds\n",
            "Epoch: 199 | Train Loss: 0.50584 | Valid Loss: 0.50468 | Train Accs : 0.85052 | Valid Accs : 0.85635 | Time: 0.35 seconds\n",
            "Epoch: 200 | Train Loss: 0.50551 | Valid Loss: 0.50515 | Train Accs : 0.85168 | Valid Accs : 0.85466 | Time: 0.35 seconds\n",
            "Epoch: 201 | Train Loss: 0.50634 | Valid Loss: 0.50449 | Train Accs : 0.85004 | Valid Accs : 0.85434 | Time: 0.42 seconds\n",
            "Epoch: 202 | Train Loss: 0.50551 | Valid Loss: 0.50456 | Train Accs : 0.84772 | Valid Accs : 0.85588 | Time: 0.35 seconds\n",
            "Epoch: 203 | Train Loss: 0.50500 | Valid Loss: 0.50423 | Train Accs : 0.84784 | Valid Accs : 0.85725 | Time: 0.37 seconds\n",
            "Epoch: 204 | Train Loss: 0.50457 | Valid Loss: 0.50456 | Train Accs : 0.85126 | Valid Accs : 0.85660 | Time: 0.35 seconds\n",
            "Epoch: 205 | Train Loss: 0.50655 | Valid Loss: 0.50521 | Train Accs : 0.85217 | Valid Accs : 0.85440 | Time: 0.36 seconds\n",
            "Epoch: 206 | Train Loss: 0.50382 | Valid Loss: 0.50345 | Train Accs : 0.84991 | Valid Accs : 0.85530 | Time: 0.42 seconds\n",
            "Epoch: 207 | Train Loss: 0.50680 | Valid Loss: 0.50343 | Train Accs : 0.84985 | Valid Accs : 0.85795 | Time: 0.36 seconds\n",
            "Epoch: 208 | Train Loss: 0.50487 | Valid Loss: 0.50379 | Train Accs : 0.85333 | Valid Accs : 0.85483 | Time: 0.35 seconds\n",
            "Epoch: 209 | Train Loss: 0.50529 | Valid Loss: 0.50437 | Train Accs : 0.85187 | Valid Accs : 0.85774 | Time: 0.36 seconds\n",
            "Epoch: 210 | Train Loss: 0.50243 | Valid Loss: 0.50414 | Train Accs : 0.85168 | Valid Accs : 0.85744 | Time: 0.35 seconds\n",
            "Epoch: 211 | Train Loss: 0.50396 | Valid Loss: 0.50409 | Train Accs : 0.85345 | Valid Accs : 0.85532 | Time: 0.42 seconds\n",
            "Epoch: 212 | Train Loss: 0.50689 | Valid Loss: 0.50253 | Train Accs : 0.85114 | Valid Accs : 0.85714 | Time: 0.37 seconds\n",
            "Epoch: 213 | Train Loss: 0.50410 | Valid Loss: 0.50455 | Train Accs : 0.85187 | Valid Accs : 0.85519 | Time: 0.36 seconds\n",
            "Epoch: 214 | Train Loss: 0.50494 | Valid Loss: 0.50428 | Train Accs : 0.85022 | Valid Accs : 0.85652 | Time: 0.36 seconds\n",
            "Epoch: 215 | Train Loss: 0.50493 | Valid Loss: 0.50382 | Train Accs : 0.85022 | Valid Accs : 0.85707 | Time: 0.35 seconds\n",
            "Epoch: 216 | Train Loss: 0.50350 | Valid Loss: 0.50414 | Train Accs : 0.85284 | Valid Accs : 0.85537 | Time: 0.42 seconds\n",
            "Epoch: 217 | Train Loss: 0.50567 | Valid Loss: 0.50416 | Train Accs : 0.85278 | Valid Accs : 0.85716 | Time: 0.36 seconds\n",
            "Epoch: 218 | Train Loss: 0.50750 | Valid Loss: 0.50523 | Train Accs : 0.84839 | Valid Accs : 0.85442 | Time: 0.37 seconds\n",
            "Epoch: 219 | Train Loss: 0.50645 | Valid Loss: 0.50409 | Train Accs : 0.84961 | Valid Accs : 0.85635 | Time: 0.36 seconds\n",
            "Epoch: 220 | Train Loss: 0.50499 | Valid Loss: 0.50556 | Train Accs : 0.84937 | Valid Accs : 0.85541 | Time: 0.36 seconds\n",
            "Epoch: 221 | Train Loss: 0.50265 | Valid Loss: 0.50492 | Train Accs : 0.85333 | Valid Accs : 0.85378 | Time: 0.42 seconds\n",
            "Epoch: 222 | Train Loss: 0.50508 | Valid Loss: 0.50489 | Train Accs : 0.85181 | Valid Accs : 0.85367 | Time: 0.36 seconds\n",
            "Epoch: 223 | Train Loss: 0.50520 | Valid Loss: 0.50448 | Train Accs : 0.84930 | Valid Accs : 0.85423 | Time: 0.35 seconds\n",
            "Epoch: 224 | Train Loss: 0.50569 | Valid Loss: 0.50495 | Train Accs : 0.84991 | Valid Accs : 0.85609 | Time: 0.36 seconds\n",
            "Epoch: 225 | Train Loss: 0.50547 | Valid Loss: 0.50484 | Train Accs : 0.85126 | Valid Accs : 0.85635 | Time: 0.37 seconds\n",
            "Epoch: 226 | Train Loss: 0.50531 | Valid Loss: 0.50372 | Train Accs : 0.85114 | Valid Accs : 0.85690 | Time: 0.42 seconds\n",
            "Epoch: 227 | Train Loss: 0.50373 | Valid Loss: 0.50345 | Train Accs : 0.85309 | Valid Accs : 0.85440 | Time: 0.36 seconds\n",
            "Epoch: 228 | Train Loss: 0.50745 | Valid Loss: 0.50414 | Train Accs : 0.85016 | Valid Accs : 0.85404 | Time: 0.36 seconds\n",
            "Epoch: 229 | Train Loss: 0.50456 | Valid Loss: 0.50433 | Train Accs : 0.85095 | Valid Accs : 0.85524 | Time: 0.35 seconds\n",
            "Epoch: 230 | Train Loss: 0.50748 | Valid Loss: 0.50390 | Train Accs : 0.85107 | Valid Accs : 0.85594 | Time: 0.36 seconds\n",
            "Epoch: 231 | Train Loss: 0.50455 | Valid Loss: 0.50472 | Train Accs : 0.85089 | Valid Accs : 0.85500 | Time: 0.42 seconds\n",
            "Epoch: 232 | Train Loss: 0.50501 | Valid Loss: 0.50516 | Train Accs : 0.84991 | Valid Accs : 0.85511 | Time: 0.37 seconds\n",
            "Epoch: 233 | Train Loss: 0.50442 | Valid Loss: 0.50412 | Train Accs : 0.84711 | Valid Accs : 0.85457 | Time: 0.35 seconds\n",
            "Epoch: 234 | Train Loss: 0.50590 | Valid Loss: 0.50379 | Train Accs : 0.84796 | Valid Accs : 0.85549 | Time: 0.35 seconds\n",
            "Epoch: 235 | Train Loss: 0.50460 | Valid Loss: 0.50573 | Train Accs : 0.85071 | Valid Accs : 0.85293 | Time: 0.36 seconds\n",
            "Epoch: 236 | Train Loss: 0.50666 | Valid Loss: 0.50477 | Train Accs : 0.85028 | Valid Accs : 0.85367 | Time: 0.43 seconds\n",
            "Epoch: 237 | Train Loss: 0.50345 | Valid Loss: 0.50402 | Train Accs : 0.85120 | Valid Accs : 0.85684 | Time: 0.36 seconds\n",
            "Epoch: 238 | Train Loss: 0.50446 | Valid Loss: 0.50513 | Train Accs : 0.84979 | Valid Accs : 0.85768 | Time: 0.36 seconds\n",
            "Epoch: 239 | Train Loss: 0.50622 | Valid Loss: 0.50494 | Train Accs : 0.84998 | Valid Accs : 0.85605 | Time: 0.37 seconds\n",
            "Epoch: 240 | Train Loss: 0.50788 | Valid Loss: 0.50357 | Train Accs : 0.84698 | Valid Accs : 0.85620 | Time: 0.36 seconds\n",
            "Epoch: 241 | Train Loss: 0.50598 | Valid Loss: 0.50335 | Train Accs : 0.84894 | Valid Accs : 0.86001 | Time: 0.42 seconds\n",
            "Epoch: 242 | Train Loss: 0.50529 | Valid Loss: 0.50449 | Train Accs : 0.85004 | Valid Accs : 0.85787 | Time: 0.36 seconds\n",
            "Epoch: 243 | Train Loss: 0.50647 | Valid Loss: 0.50414 | Train Accs : 0.84747 | Valid Accs : 0.85682 | Time: 0.35 seconds\n",
            "Epoch: 244 | Train Loss: 0.50545 | Valid Loss: 0.50399 | Train Accs : 0.84857 | Valid Accs : 0.85511 | Time: 0.36 seconds\n",
            "Epoch: 245 | Train Loss: 0.50264 | Valid Loss: 0.50429 | Train Accs : 0.85419 | Valid Accs : 0.85573 | Time: 0.36 seconds\n",
            "Epoch: 246 | Train Loss: 0.50522 | Valid Loss: 0.50454 | Train Accs : 0.85010 | Valid Accs : 0.85652 | Time: 0.42 seconds\n",
            "Epoch: 247 | Train Loss: 0.50449 | Valid Loss: 0.50407 | Train Accs : 0.84985 | Valid Accs : 0.85872 | Time: 0.36 seconds\n",
            "Epoch: 248 | Train Loss: 0.50457 | Valid Loss: 0.50353 | Train Accs : 0.84937 | Valid Accs : 0.85536 | Time: 0.36 seconds\n",
            "Epoch: 249 | Train Loss: 0.50638 | Valid Loss: 0.50481 | Train Accs : 0.84863 | Valid Accs : 0.85451 | Time: 0.36 seconds\n",
            "Epoch: 250 | Train Loss: 0.50556 | Valid Loss: 0.50443 | Train Accs : 0.85052 | Valid Accs : 0.85579 | Time: 0.36 seconds\n",
            "Epoch: 251 | Train Loss: 0.50398 | Valid Loss: 0.50445 | Train Accs : 0.84985 | Valid Accs : 0.85457 | Time: 0.43 seconds\n",
            "Epoch: 252 | Train Loss: 0.50514 | Valid Loss: 0.50509 | Train Accs : 0.84937 | Valid Accs : 0.85737 | Time: 0.36 seconds\n",
            "Epoch: 253 | Train Loss: 0.50481 | Valid Loss: 0.50619 | Train Accs : 0.85114 | Valid Accs : 0.85442 | Time: 0.35 seconds\n",
            "Epoch: 254 | Train Loss: 0.50682 | Valid Loss: 0.50383 | Train Accs : 0.84918 | Valid Accs : 0.85768 | Time: 0.36 seconds\n",
            "Epoch: 255 | Train Loss: 0.50341 | Valid Loss: 0.50467 | Train Accs : 0.85175 | Valid Accs : 0.85524 | Time: 0.36 seconds\n",
            "Epoch: 256 | Train Loss: 0.50627 | Valid Loss: 0.50449 | Train Accs : 0.84888 | Valid Accs : 0.85549 | Time: 0.43 seconds\n",
            "Epoch: 257 | Train Loss: 0.50730 | Valid Loss: 0.50465 | Train Accs : 0.85040 | Valid Accs : 0.85549 | Time: 0.37 seconds\n",
            "Epoch: 258 | Train Loss: 0.50352 | Valid Loss: 0.50568 | Train Accs : 0.85144 | Valid Accs : 0.85737 | Time: 0.37 seconds\n",
            "Epoch: 259 | Train Loss: 0.50577 | Valid Loss: 0.50506 | Train Accs : 0.84961 | Valid Accs : 0.85507 | Time: 0.36 seconds\n",
            "Epoch: 260 | Train Loss: 0.50363 | Valid Loss: 0.50486 | Train Accs : 0.84985 | Valid Accs : 0.85573 | Time: 0.36 seconds\n",
            "Epoch: 261 | Train Loss: 0.50541 | Valid Loss: 0.50382 | Train Accs : 0.85150 | Valid Accs : 0.85891 | Time: 0.43 seconds\n",
            "Epoch: 262 | Train Loss: 0.50425 | Valid Loss: 0.50388 | Train Accs : 0.85199 | Valid Accs : 0.85628 | Time: 0.36 seconds\n",
            "Epoch: 263 | Train Loss: 0.50565 | Valid Loss: 0.50369 | Train Accs : 0.84930 | Valid Accs : 0.85628 | Time: 0.36 seconds\n",
            "Epoch: 264 | Train Loss: 0.50402 | Valid Loss: 0.50620 | Train Accs : 0.85004 | Valid Accs : 0.85245 | Time: 0.36 seconds\n",
            "Epoch: 265 | Train Loss: 0.50432 | Valid Loss: 0.50371 | Train Accs : 0.84882 | Valid Accs : 0.85646 | Time: 0.36 seconds\n",
            "Epoch: 266 | Train Loss: 0.50491 | Valid Loss: 0.50526 | Train Accs : 0.84924 | Valid Accs : 0.85658 | Time: 0.43 seconds\n",
            "Epoch: 267 | Train Loss: 0.50445 | Valid Loss: 0.50547 | Train Accs : 0.84967 | Valid Accs : 0.85530 | Time: 0.36 seconds\n",
            "Epoch: 268 | Train Loss: 0.50567 | Valid Loss: 0.50494 | Train Accs : 0.84692 | Valid Accs : 0.85592 | Time: 0.36 seconds\n",
            "Epoch: 269 | Train Loss: 0.50752 | Valid Loss: 0.50533 | Train Accs : 0.84949 | Valid Accs : 0.85342 | Time: 0.36 seconds\n",
            "Epoch: 270 | Train Loss: 0.50467 | Valid Loss: 0.50448 | Train Accs : 0.85248 | Valid Accs : 0.85622 | Time: 0.35 seconds\n",
            "Epoch: 271 | Train Loss: 0.50407 | Valid Loss: 0.50478 | Train Accs : 0.85114 | Valid Accs : 0.85417 | Time: 0.42 seconds\n",
            "Epoch: 272 | Train Loss: 0.50315 | Valid Loss: 0.50318 | Train Accs : 0.84875 | Valid Accs : 0.85902 | Time: 0.36 seconds\n",
            "Epoch: 273 | Train Loss: 0.50623 | Valid Loss: 0.50389 | Train Accs : 0.85126 | Valid Accs : 0.85562 | Time: 0.36 seconds\n",
            "Epoch: 274 | Train Loss: 0.50589 | Valid Loss: 0.50330 | Train Accs : 0.85071 | Valid Accs : 0.85648 | Time: 0.37 seconds\n",
            "Epoch: 275 | Train Loss: 0.50512 | Valid Loss: 0.50431 | Train Accs : 0.84900 | Valid Accs : 0.85421 | Time: 0.36 seconds\n",
            "Epoch: 276 | Train Loss: 0.50536 | Valid Loss: 0.50540 | Train Accs : 0.85028 | Valid Accs : 0.85171 | Time: 0.42 seconds\n",
            "Epoch: 277 | Train Loss: 0.50515 | Valid Loss: 0.50360 | Train Accs : 0.85071 | Valid Accs : 0.85609 | Time: 0.36 seconds\n",
            "Epoch: 278 | Train Loss: 0.50432 | Valid Loss: 0.50400 | Train Accs : 0.85272 | Valid Accs : 0.85502 | Time: 0.36 seconds\n",
            "Epoch: 279 | Train Loss: 0.50505 | Valid Loss: 0.50586 | Train Accs : 0.85065 | Valid Accs : 0.85389 | Time: 0.35 seconds\n",
            "Epoch: 280 | Train Loss: 0.50550 | Valid Loss: 0.50327 | Train Accs : 0.85162 | Valid Accs : 0.85524 | Time: 0.37 seconds\n",
            "Epoch: 281 | Train Loss: 0.50460 | Valid Loss: 0.50480 | Train Accs : 0.85187 | Valid Accs : 0.85385 | Time: 0.42 seconds\n",
            "Epoch: 282 | Train Loss: 0.50262 | Valid Loss: 0.50422 | Train Accs : 0.85297 | Valid Accs : 0.85476 | Time: 0.37 seconds\n",
            "Epoch: 283 | Train Loss: 0.50546 | Valid Loss: 0.50450 | Train Accs : 0.84778 | Valid Accs : 0.85438 | Time: 0.35 seconds\n",
            "Epoch: 284 | Train Loss: 0.50451 | Valid Loss: 0.50604 | Train Accs : 0.84973 | Valid Accs : 0.85250 | Time: 0.35 seconds\n",
            "Epoch: 285 | Train Loss: 0.50389 | Valid Loss: 0.50394 | Train Accs : 0.85193 | Valid Accs : 0.85725 | Time: 0.36 seconds\n",
            "Epoch: 286 | Train Loss: 0.50597 | Valid Loss: 0.50395 | Train Accs : 0.84967 | Valid Accs : 0.85601 | Time: 0.42 seconds\n",
            "Epoch: 287 | Train Loss: 0.50413 | Valid Loss: 0.50538 | Train Accs : 0.85089 | Valid Accs : 0.85524 | Time: 0.36 seconds\n",
            "Epoch: 288 | Train Loss: 0.50427 | Valid Loss: 0.50455 | Train Accs : 0.85272 | Valid Accs : 0.85453 | Time: 0.36 seconds\n",
            "Epoch: 289 | Train Loss: 0.50614 | Valid Loss: 0.50362 | Train Accs : 0.84851 | Valid Accs : 0.85622 | Time: 0.36 seconds\n",
            "Epoch: 290 | Train Loss: 0.50443 | Valid Loss: 0.50423 | Train Accs : 0.84912 | Valid Accs : 0.85695 | Time: 0.35 seconds\n",
            "Epoch: 291 | Train Loss: 0.50643 | Valid Loss: 0.50349 | Train Accs : 0.85040 | Valid Accs : 0.85742 | Time: 0.43 seconds\n",
            "Epoch: 292 | Train Loss: 0.50395 | Valid Loss: 0.50543 | Train Accs : 0.85150 | Valid Accs : 0.85658 | Time: 0.35 seconds\n",
            "Epoch: 293 | Train Loss: 0.50435 | Valid Loss: 0.50500 | Train Accs : 0.85187 | Valid Accs : 0.85196 | Time: 0.36 seconds\n",
            "Epoch: 294 | Train Loss: 0.50451 | Valid Loss: 0.50461 | Train Accs : 0.85144 | Valid Accs : 0.85288 | Time: 0.35 seconds\n",
            "Epoch: 295 | Train Loss: 0.50496 | Valid Loss: 0.50359 | Train Accs : 0.84949 | Valid Accs : 0.85827 | Time: 0.36 seconds\n",
            "Epoch: 296 | Train Loss: 0.50629 | Valid Loss: 0.50527 | Train Accs : 0.85059 | Valid Accs : 0.85459 | Time: 0.42 seconds\n",
            "Epoch: 297 | Train Loss: 0.50482 | Valid Loss: 0.50380 | Train Accs : 0.85046 | Valid Accs : 0.85669 | Time: 0.36 seconds\n",
            "Epoch: 298 | Train Loss: 0.50446 | Valid Loss: 0.50537 | Train Accs : 0.85339 | Valid Accs : 0.85258 | Time: 0.35 seconds\n",
            "Epoch: 299 | Train Loss: 0.50563 | Valid Loss: 0.50317 | Train Accs : 0.85132 | Valid Accs : 0.85468 | Time: 0.36 seconds\n",
            "Epoch: 300 | Train Loss: 0.50550 | Valid Loss: 0.50486 | Train Accs : 0.85150 | Valid Accs : 0.85483 | Time: 0.35 seconds\n",
            "Epoch: 301 | Train Loss: 0.50684 | Valid Loss: 0.50390 | Train Accs : 0.84814 | Valid Accs : 0.85554 | Time: 0.42 seconds\n",
            "Epoch: 302 | Train Loss: 0.50449 | Valid Loss: 0.50444 | Train Accs : 0.85065 | Valid Accs : 0.85367 | Time: 0.36 seconds\n",
            "Epoch: 303 | Train Loss: 0.50599 | Valid Loss: 0.50384 | Train Accs : 0.84979 | Valid Accs : 0.85695 | Time: 0.37 seconds\n",
            "Epoch: 304 | Train Loss: 0.50481 | Valid Loss: 0.50301 | Train Accs : 0.84827 | Valid Accs : 0.85718 | Time: 0.39 seconds\n",
            "Epoch: 305 | Train Loss: 0.50732 | Valid Loss: 0.50507 | Train Accs : 0.84985 | Valid Accs : 0.85415 | Time: 0.36 seconds\n",
            "Epoch: 306 | Train Loss: 0.50279 | Valid Loss: 0.50480 | Train Accs : 0.85144 | Valid Accs : 0.85462 | Time: 0.42 seconds\n",
            "Epoch: 307 | Train Loss: 0.50637 | Valid Loss: 0.50453 | Train Accs : 0.84796 | Valid Accs : 0.85622 | Time: 0.36 seconds\n",
            "Epoch: 308 | Train Loss: 0.50546 | Valid Loss: 0.50503 | Train Accs : 0.84937 | Valid Accs : 0.85573 | Time: 0.36 seconds\n",
            "Epoch: 309 | Train Loss: 0.50889 | Valid Loss: 0.50404 | Train Accs : 0.84778 | Valid Accs : 0.85429 | Time: 0.35 seconds\n",
            "Epoch: 310 | Train Loss: 0.50494 | Valid Loss: 0.50422 | Train Accs : 0.84760 | Valid Accs : 0.85432 | Time: 0.37 seconds\n",
            "Epoch: 311 | Train Loss: 0.50744 | Valid Loss: 0.50423 | Train Accs : 0.84839 | Valid Accs : 0.85793 | Time: 0.42 seconds\n",
            "Epoch: 312 | Train Loss: 0.50631 | Valid Loss: 0.50558 | Train Accs : 0.85028 | Valid Accs : 0.85329 | Time: 0.36 seconds\n",
            "Epoch: 313 | Train Loss: 0.50589 | Valid Loss: 0.50427 | Train Accs : 0.85144 | Valid Accs : 0.85494 | Time: 0.35 seconds\n",
            "Epoch: 314 | Train Loss: 0.50313 | Valid Loss: 0.50523 | Train Accs : 0.85071 | Valid Accs : 0.85335 | Time: 0.36 seconds\n",
            "Epoch: 315 | Train Loss: 0.50440 | Valid Loss: 0.50413 | Train Accs : 0.85291 | Valid Accs : 0.85586 | Time: 0.36 seconds\n",
            "Epoch: 316 | Train Loss: 0.50524 | Valid Loss: 0.50553 | Train Accs : 0.85077 | Valid Accs : 0.85305 | Time: 0.41 seconds\n",
            "Epoch: 317 | Train Loss: 0.50449 | Valid Loss: 0.50449 | Train Accs : 0.84930 | Valid Accs : 0.85646 | Time: 0.36 seconds\n",
            "Epoch: 318 | Train Loss: 0.50442 | Valid Loss: 0.50465 | Train Accs : 0.85168 | Valid Accs : 0.85714 | Time: 0.36 seconds\n",
            "Epoch: 319 | Train Loss: 0.50387 | Valid Loss: 0.50368 | Train Accs : 0.85052 | Valid Accs : 0.85573 | Time: 0.36 seconds\n",
            "Epoch: 320 | Train Loss: 0.50661 | Valid Loss: 0.50465 | Train Accs : 0.84979 | Valid Accs : 0.85549 | Time: 0.36 seconds\n",
            "Epoch: 321 | Train Loss: 0.50452 | Valid Loss: 0.50337 | Train Accs : 0.85089 | Valid Accs : 0.85635 | Time: 0.43 seconds\n",
            "Epoch: 322 | Train Loss: 0.50448 | Valid Loss: 0.50508 | Train Accs : 0.85059 | Valid Accs : 0.85573 | Time: 0.35 seconds\n",
            "Epoch: 323 | Train Loss: 0.50470 | Valid Loss: 0.50563 | Train Accs : 0.85089 | Valid Accs : 0.85457 | Time: 0.36 seconds\n",
            "Epoch: 324 | Train Loss: 0.50264 | Valid Loss: 0.50462 | Train Accs : 0.85083 | Valid Accs : 0.85691 | Time: 0.35 seconds\n",
            "Epoch: 325 | Train Loss: 0.50637 | Valid Loss: 0.50431 | Train Accs : 0.84827 | Valid Accs : 0.85682 | Time: 0.35 seconds\n",
            "Epoch: 326 | Train Loss: 0.50346 | Valid Loss: 0.50511 | Train Accs : 0.84949 | Valid Accs : 0.85755 | Time: 0.44 seconds\n",
            "Epoch: 327 | Train Loss: 0.50465 | Valid Loss: 0.50431 | Train Accs : 0.84955 | Valid Accs : 0.85836 | Time: 0.36 seconds\n",
            "Epoch: 328 | Train Loss: 0.50545 | Valid Loss: 0.50537 | Train Accs : 0.84845 | Valid Accs : 0.85269 | Time: 0.36 seconds\n",
            "Epoch: 329 | Train Loss: 0.50379 | Valid Loss: 0.50471 | Train Accs : 0.84918 | Valid Accs : 0.85707 | Time: 0.36 seconds\n",
            "Epoch: 330 | Train Loss: 0.50469 | Valid Loss: 0.50433 | Train Accs : 0.84900 | Valid Accs : 0.85590 | Time: 0.35 seconds\n",
            "Epoch: 331 | Train Loss: 0.50449 | Valid Loss: 0.50464 | Train Accs : 0.84937 | Valid Accs : 0.85470 | Time: 0.42 seconds\n",
            "Epoch: 332 | Train Loss: 0.50383 | Valid Loss: 0.50525 | Train Accs : 0.84894 | Valid Accs : 0.85397 | Time: 0.36 seconds\n",
            "Epoch: 333 | Train Loss: 0.50439 | Valid Loss: 0.50395 | Train Accs : 0.85132 | Valid Accs : 0.85707 | Time: 0.36 seconds\n",
            "Epoch: 334 | Train Loss: 0.50645 | Valid Loss: 0.50376 | Train Accs : 0.85101 | Valid Accs : 0.85712 | Time: 0.36 seconds\n",
            "Epoch: 335 | Train Loss: 0.50503 | Valid Loss: 0.50533 | Train Accs : 0.85223 | Valid Accs : 0.85476 | Time: 0.35 seconds\n",
            "Epoch: 336 | Train Loss: 0.50423 | Valid Loss: 0.50362 | Train Accs : 0.85034 | Valid Accs : 0.85712 | Time: 0.42 seconds\n",
            "Epoch: 337 | Train Loss: 0.50344 | Valid Loss: 0.50553 | Train Accs : 0.85211 | Valid Accs : 0.85342 | Time: 0.36 seconds\n",
            "Epoch: 338 | Train Loss: 0.50461 | Valid Loss: 0.50433 | Train Accs : 0.85040 | Valid Accs : 0.85601 | Time: 0.36 seconds\n",
            "Epoch: 339 | Train Loss: 0.50600 | Valid Loss: 0.50381 | Train Accs : 0.84998 | Valid Accs : 0.85566 | Time: 0.36 seconds\n",
            "Epoch: 340 | Train Loss: 0.50524 | Valid Loss: 0.50505 | Train Accs : 0.84991 | Valid Accs : 0.85494 | Time: 0.36 seconds\n",
            "Epoch: 341 | Train Loss: 0.50523 | Valid Loss: 0.50596 | Train Accs : 0.84772 | Valid Accs : 0.85628 | Time: 0.42 seconds\n",
            "Epoch: 342 | Train Loss: 0.50565 | Valid Loss: 0.50302 | Train Accs : 0.85272 | Valid Accs : 0.85470 | Time: 0.36 seconds\n",
            "Epoch: 343 | Train Loss: 0.50563 | Valid Loss: 0.50391 | Train Accs : 0.84979 | Valid Accs : 0.85434 | Time: 0.36 seconds\n",
            "Epoch: 344 | Train Loss: 0.50557 | Valid Loss: 0.50502 | Train Accs : 0.85132 | Valid Accs : 0.85421 | Time: 0.36 seconds\n",
            "Epoch: 345 | Train Loss: 0.50427 | Valid Loss: 0.50436 | Train Accs : 0.85089 | Valid Accs : 0.85554 | Time: 0.38 seconds\n",
            "Epoch: 346 | Train Loss: 0.50698 | Valid Loss: 0.50554 | Train Accs : 0.84851 | Valid Accs : 0.85331 | Time: 0.43 seconds\n",
            "Epoch: 347 | Train Loss: 0.50488 | Valid Loss: 0.50483 | Train Accs : 0.84882 | Valid Accs : 0.85568 | Time: 0.36 seconds\n",
            "Epoch: 348 | Train Loss: 0.50496 | Valid Loss: 0.50452 | Train Accs : 0.84863 | Valid Accs : 0.85554 | Time: 0.36 seconds\n",
            "Epoch: 349 | Train Loss: 0.50550 | Valid Loss: 0.50394 | Train Accs : 0.85223 | Valid Accs : 0.85537 | Time: 0.36 seconds\n",
            "Epoch: 350 | Train Loss: 0.50652 | Valid Loss: 0.50455 | Train Accs : 0.84857 | Valid Accs : 0.85725 | Time: 0.36 seconds\n",
            "Epoch: 351 | Train Loss: 0.50471 | Valid Loss: 0.50364 | Train Accs : 0.84851 | Valid Accs : 0.85682 | Time: 0.42 seconds\n",
            "Epoch: 352 | Train Loss: 0.50350 | Valid Loss: 0.50509 | Train Accs : 0.85089 | Valid Accs : 0.85530 | Time: 0.36 seconds\n",
            "Epoch: 353 | Train Loss: 0.50530 | Valid Loss: 0.50512 | Train Accs : 0.85022 | Valid Accs : 0.85440 | Time: 0.40 seconds\n",
            "Epoch: 354 | Train Loss: 0.50728 | Valid Loss: 0.50418 | Train Accs : 0.84985 | Valid Accs : 0.85603 | Time: 0.36 seconds\n",
            "Epoch: 355 | Train Loss: 0.50452 | Valid Loss: 0.50553 | Train Accs : 0.85175 | Valid Accs : 0.85635 | Time: 0.35 seconds\n",
            "Epoch: 356 | Train Loss: 0.50689 | Valid Loss: 0.50558 | Train Accs : 0.85052 | Valid Accs : 0.85427 | Time: 0.43 seconds\n",
            "Epoch: 357 | Train Loss: 0.50540 | Valid Loss: 0.50396 | Train Accs : 0.84741 | Valid Accs : 0.85590 | Time: 0.36 seconds\n",
            "Epoch: 358 | Train Loss: 0.50575 | Valid Loss: 0.50526 | Train Accs : 0.84814 | Valid Accs : 0.85616 | Time: 0.36 seconds\n",
            "Epoch: 359 | Train Loss: 0.50417 | Valid Loss: 0.50522 | Train Accs : 0.85193 | Valid Accs : 0.85682 | Time: 0.36 seconds\n",
            "Epoch: 360 | Train Loss: 0.50249 | Valid Loss: 0.50502 | Train Accs : 0.85120 | Valid Accs : 0.85470 | Time: 0.36 seconds\n",
            "Epoch: 361 | Train Loss: 0.50635 | Valid Loss: 0.50438 | Train Accs : 0.84821 | Valid Accs : 0.85701 | Time: 0.42 seconds\n",
            "Epoch: 362 | Train Loss: 0.50470 | Valid Loss: 0.50452 | Train Accs : 0.84845 | Valid Accs : 0.85761 | Time: 0.35 seconds\n",
            "Epoch: 363 | Train Loss: 0.50730 | Valid Loss: 0.50392 | Train Accs : 0.84546 | Valid Accs : 0.85639 | Time: 0.35 seconds\n",
            "Epoch: 364 | Train Loss: 0.50459 | Valid Loss: 0.50349 | Train Accs : 0.85120 | Valid Accs : 0.85658 | Time: 0.36 seconds\n",
            "Epoch: 365 | Train Loss: 0.50481 | Valid Loss: 0.50423 | Train Accs : 0.84961 | Valid Accs : 0.85737 | Time: 0.36 seconds\n",
            "Epoch: 366 | Train Loss: 0.50395 | Valid Loss: 0.50542 | Train Accs : 0.85010 | Valid Accs : 0.85451 | Time: 0.41 seconds\n",
            "Epoch: 367 | Train Loss: 0.50535 | Valid Loss: 0.50456 | Train Accs : 0.85010 | Valid Accs : 0.85616 | Time: 0.36 seconds\n",
            "Epoch: 368 | Train Loss: 0.50597 | Valid Loss: 0.50423 | Train Accs : 0.84949 | Valid Accs : 0.85459 | Time: 0.35 seconds\n",
            "Epoch: 369 | Train Loss: 0.50428 | Valid Loss: 0.50398 | Train Accs : 0.85272 | Valid Accs : 0.85489 | Time: 0.35 seconds\n",
            "Epoch: 370 | Train Loss: 0.50397 | Valid Loss: 0.50429 | Train Accs : 0.84882 | Valid Accs : 0.85720 | Time: 0.36 seconds\n",
            "Epoch: 371 | Train Loss: 0.50659 | Valid Loss: 0.50524 | Train Accs : 0.85034 | Valid Accs : 0.85216 | Time: 0.43 seconds\n",
            "Epoch: 372 | Train Loss: 0.50287 | Valid Loss: 0.50351 | Train Accs : 0.84991 | Valid Accs : 0.85859 | Time: 0.36 seconds\n",
            "Epoch: 373 | Train Loss: 0.50531 | Valid Loss: 0.50448 | Train Accs : 0.84961 | Valid Accs : 0.85459 | Time: 0.35 seconds\n",
            "Epoch: 374 | Train Loss: 0.50697 | Valid Loss: 0.50397 | Train Accs : 0.85010 | Valid Accs : 0.85592 | Time: 0.35 seconds\n",
            "Epoch: 375 | Train Loss: 0.50752 | Valid Loss: 0.50496 | Train Accs : 0.84985 | Valid Accs : 0.85423 | Time: 0.36 seconds\n",
            "Epoch: 376 | Train Loss: 0.50567 | Valid Loss: 0.50518 | Train Accs : 0.84918 | Valid Accs : 0.85609 | Time: 0.42 seconds\n",
            "Epoch: 377 | Train Loss: 0.50516 | Valid Loss: 0.50460 | Train Accs : 0.84991 | Valid Accs : 0.85571 | Time: 0.35 seconds\n",
            "Epoch: 378 | Train Loss: 0.50512 | Valid Loss: 0.50588 | Train Accs : 0.84998 | Valid Accs : 0.85410 | Time: 0.36 seconds\n",
            "Epoch: 379 | Train Loss: 0.50477 | Valid Loss: 0.50434 | Train Accs : 0.84827 | Valid Accs : 0.85468 | Time: 0.36 seconds\n",
            "Epoch: 380 | Train Loss: 0.50514 | Valid Loss: 0.50393 | Train Accs : 0.85046 | Valid Accs : 0.85671 | Time: 0.36 seconds\n",
            "Epoch: 381 | Train Loss: 0.50335 | Valid Loss: 0.50459 | Train Accs : 0.85254 | Valid Accs : 0.85611 | Time: 0.43 seconds\n",
            "Epoch: 382 | Train Loss: 0.50508 | Valid Loss: 0.50476 | Train Accs : 0.84839 | Valid Accs : 0.85609 | Time: 0.36 seconds\n",
            "Epoch: 383 | Train Loss: 0.50373 | Valid Loss: 0.50406 | Train Accs : 0.84900 | Valid Accs : 0.85707 | Time: 0.36 seconds\n",
            "Epoch: 384 | Train Loss: 0.50388 | Valid Loss: 0.50543 | Train Accs : 0.85211 | Valid Accs : 0.85581 | Time: 0.35 seconds\n",
            "Epoch: 385 | Train Loss: 0.50596 | Valid Loss: 0.50459 | Train Accs : 0.84973 | Valid Accs : 0.85579 | Time: 0.36 seconds\n",
            "Epoch: 386 | Train Loss: 0.50392 | Valid Loss: 0.50511 | Train Accs : 0.85101 | Valid Accs : 0.85457 | Time: 0.43 seconds\n",
            "Epoch: 387 | Train Loss: 0.50620 | Valid Loss: 0.50468 | Train Accs : 0.84882 | Valid Accs : 0.85536 | Time: 0.36 seconds\n",
            "Epoch: 388 | Train Loss: 0.50625 | Valid Loss: 0.50427 | Train Accs : 0.84912 | Valid Accs : 0.85372 | Time: 0.35 seconds\n",
            "Epoch: 389 | Train Loss: 0.50455 | Valid Loss: 0.50429 | Train Accs : 0.84821 | Valid Accs : 0.85804 | Time: 0.36 seconds\n",
            "Epoch: 390 | Train Loss: 0.50458 | Valid Loss: 0.50345 | Train Accs : 0.84888 | Valid Accs : 0.85536 | Time: 0.35 seconds\n",
            "Epoch: 391 | Train Loss: 0.50618 | Valid Loss: 0.50445 | Train Accs : 0.84875 | Valid Accs : 0.85489 | Time: 0.43 seconds\n",
            "Epoch: 392 | Train Loss: 0.50415 | Valid Loss: 0.50505 | Train Accs : 0.84955 | Valid Accs : 0.85530 | Time: 0.36 seconds\n",
            "Epoch: 393 | Train Loss: 0.50493 | Valid Loss: 0.50520 | Train Accs : 0.84802 | Valid Accs : 0.85500 | Time: 0.35 seconds\n",
            "Epoch: 394 | Train Loss: 0.50417 | Valid Loss: 0.50438 | Train Accs : 0.85187 | Valid Accs : 0.85633 | Time: 0.36 seconds\n",
            "Epoch: 395 | Train Loss: 0.50398 | Valid Loss: 0.50415 | Train Accs : 0.85077 | Valid Accs : 0.85737 | Time: 0.35 seconds\n",
            "Epoch: 396 | Train Loss: 0.50533 | Valid Loss: 0.50472 | Train Accs : 0.84912 | Valid Accs : 0.85537 | Time: 0.42 seconds\n",
            "Epoch: 397 | Train Loss: 0.50531 | Valid Loss: 0.50379 | Train Accs : 0.84967 | Valid Accs : 0.85663 | Time: 0.37 seconds\n",
            "Epoch: 398 | Train Loss: 0.50537 | Valid Loss: 0.50526 | Train Accs : 0.84894 | Valid Accs : 0.85393 | Time: 0.35 seconds\n",
            "Epoch: 399 | Train Loss: 0.50508 | Valid Loss: 0.50529 | Train Accs : 0.84882 | Valid Accs : 0.85645 | Time: 0.36 seconds\n",
            "Epoch: 400 | Train Loss: 0.50501 | Valid Loss: 0.50410 | Train Accs : 0.85132 | Valid Accs : 0.85573 | Time: 0.35 seconds\n",
            "Epoch: 401 | Train Loss: 0.50433 | Valid Loss: 0.50496 | Train Accs : 0.85022 | Valid Accs : 0.85652 | Time: 0.42 seconds\n",
            "Epoch: 402 | Train Loss: 0.50542 | Valid Loss: 0.50497 | Train Accs : 0.85101 | Valid Accs : 0.85658 | Time: 0.37 seconds\n",
            "Epoch: 403 | Train Loss: 0.50472 | Valid Loss: 0.50489 | Train Accs : 0.85144 | Valid Accs : 0.85549 | Time: 0.36 seconds\n",
            "Epoch: 404 | Train Loss: 0.50422 | Valid Loss: 0.50437 | Train Accs : 0.85071 | Valid Accs : 0.85451 | Time: 0.36 seconds\n",
            "Epoch: 405 | Train Loss: 0.50517 | Valid Loss: 0.50423 | Train Accs : 0.84949 | Valid Accs : 0.85573 | Time: 0.36 seconds\n",
            "Epoch: 406 | Train Loss: 0.50592 | Valid Loss: 0.50364 | Train Accs : 0.84674 | Valid Accs : 0.85682 | Time: 0.42 seconds\n",
            "Epoch: 407 | Train Loss: 0.50427 | Valid Loss: 0.50458 | Train Accs : 0.85217 | Valid Accs : 0.85676 | Time: 0.35 seconds\n",
            "Epoch: 408 | Train Loss: 0.50502 | Valid Loss: 0.50414 | Train Accs : 0.84784 | Valid Accs : 0.85834 | Time: 0.36 seconds\n",
            "Epoch: 409 | Train Loss: 0.50465 | Valid Loss: 0.50431 | Train Accs : 0.85028 | Valid Accs : 0.85669 | Time: 0.35 seconds\n",
            "Epoch: 410 | Train Loss: 0.50546 | Valid Loss: 0.50305 | Train Accs : 0.85138 | Valid Accs : 0.85742 | Time: 0.36 seconds\n",
            "Epoch: 411 | Train Loss: 0.50572 | Valid Loss: 0.50381 | Train Accs : 0.84833 | Valid Accs : 0.85481 | Time: 0.43 seconds\n",
            "Epoch: 412 | Train Loss: 0.50586 | Valid Loss: 0.50442 | Train Accs : 0.84894 | Valid Accs : 0.85489 | Time: 0.36 seconds\n",
            "Epoch: 413 | Train Loss: 0.50500 | Valid Loss: 0.50479 | Train Accs : 0.84924 | Valid Accs : 0.85536 | Time: 0.36 seconds\n",
            "Epoch: 414 | Train Loss: 0.50305 | Valid Loss: 0.50416 | Train Accs : 0.85199 | Valid Accs : 0.85476 | Time: 0.35 seconds\n",
            "Epoch: 415 | Train Loss: 0.50506 | Valid Loss: 0.50536 | Train Accs : 0.85059 | Valid Accs : 0.85239 | Time: 0.36 seconds\n",
            "Epoch: 416 | Train Loss: 0.50595 | Valid Loss: 0.50475 | Train Accs : 0.85144 | Valid Accs : 0.85355 | Time: 0.43 seconds\n",
            "Epoch: 417 | Train Loss: 0.50499 | Valid Loss: 0.50453 | Train Accs : 0.85095 | Valid Accs : 0.85549 | Time: 0.36 seconds\n",
            "Epoch: 418 | Train Loss: 0.50354 | Valid Loss: 0.50343 | Train Accs : 0.85254 | Valid Accs : 0.85603 | Time: 0.35 seconds\n",
            "Epoch: 419 | Train Loss: 0.50493 | Valid Loss: 0.50406 | Train Accs : 0.85126 | Valid Accs : 0.85676 | Time: 0.36 seconds\n",
            "Epoch: 420 | Train Loss: 0.50632 | Valid Loss: 0.50460 | Train Accs : 0.85187 | Valid Accs : 0.85233 | Time: 0.36 seconds\n",
            "Epoch: 421 | Train Loss: 0.50559 | Valid Loss: 0.50470 | Train Accs : 0.84821 | Valid Accs : 0.85378 | Time: 0.43 seconds\n",
            "Epoch: 422 | Train Loss: 0.50546 | Valid Loss: 0.50449 | Train Accs : 0.85010 | Valid Accs : 0.85397 | Time: 0.36 seconds\n",
            "Epoch: 423 | Train Loss: 0.50450 | Valid Loss: 0.50484 | Train Accs : 0.85040 | Valid Accs : 0.85541 | Time: 0.35 seconds\n",
            "Epoch: 424 | Train Loss: 0.50317 | Valid Loss: 0.50456 | Train Accs : 0.85266 | Valid Accs : 0.85633 | Time: 0.36 seconds\n",
            "Epoch: 425 | Train Loss: 0.50463 | Valid Loss: 0.50455 | Train Accs : 0.85089 | Valid Accs : 0.85408 | Time: 0.35 seconds\n",
            "Epoch: 426 | Train Loss: 0.50481 | Valid Loss: 0.50352 | Train Accs : 0.85126 | Valid Accs : 0.85603 | Time: 0.43 seconds\n",
            "Epoch: 427 | Train Loss: 0.50574 | Valid Loss: 0.50411 | Train Accs : 0.84705 | Valid Accs : 0.85701 | Time: 0.36 seconds\n",
            "Epoch: 428 | Train Loss: 0.50595 | Valid Loss: 0.50542 | Train Accs : 0.84955 | Valid Accs : 0.85584 | Time: 0.35 seconds\n",
            "Epoch: 429 | Train Loss: 0.50543 | Valid Loss: 0.50411 | Train Accs : 0.84961 | Valid Accs : 0.85530 | Time: 0.37 seconds\n",
            "Epoch: 430 | Train Loss: 0.50437 | Valid Loss: 0.50376 | Train Accs : 0.84961 | Valid Accs : 0.85459 | Time: 0.36 seconds\n",
            "Epoch: 431 | Train Loss: 0.50486 | Valid Loss: 0.50316 | Train Accs : 0.84998 | Valid Accs : 0.85579 | Time: 0.42 seconds\n",
            "Epoch: 432 | Train Loss: 0.50529 | Valid Loss: 0.50439 | Train Accs : 0.85010 | Valid Accs : 0.85566 | Time: 0.37 seconds\n",
            "Epoch: 433 | Train Loss: 0.50615 | Valid Loss: 0.50600 | Train Accs : 0.85052 | Valid Accs : 0.85342 | Time: 0.35 seconds\n",
            "Epoch: 434 | Train Loss: 0.50421 | Valid Loss: 0.50475 | Train Accs : 0.84863 | Valid Accs : 0.85737 | Time: 0.36 seconds\n",
            "Epoch: 435 | Train Loss: 0.50497 | Valid Loss: 0.50506 | Train Accs : 0.85089 | Valid Accs : 0.85472 | Time: 0.36 seconds\n",
            "Epoch: 436 | Train Loss: 0.50437 | Valid Loss: 0.50454 | Train Accs : 0.84863 | Valid Accs : 0.85378 | Time: 0.42 seconds\n",
            "Epoch: 437 | Train Loss: 0.50615 | Valid Loss: 0.50447 | Train Accs : 0.84869 | Valid Accs : 0.85457 | Time: 0.36 seconds\n",
            "Epoch: 438 | Train Loss: 0.50536 | Valid Loss: 0.50470 | Train Accs : 0.84863 | Valid Accs : 0.85301 | Time: 0.38 seconds\n",
            "Epoch: 439 | Train Loss: 0.50529 | Valid Loss: 0.50576 | Train Accs : 0.85046 | Valid Accs : 0.85269 | Time: 0.36 seconds\n",
            "Epoch: 440 | Train Loss: 0.50490 | Valid Loss: 0.50395 | Train Accs : 0.84735 | Valid Accs : 0.85853 | Time: 0.36 seconds\n",
            "Epoch: 441 | Train Loss: 0.50494 | Valid Loss: 0.50385 | Train Accs : 0.84802 | Valid Accs : 0.85492 | Time: 0.43 seconds\n",
            "Epoch: 442 | Train Loss: 0.50539 | Valid Loss: 0.50375 | Train Accs : 0.85040 | Valid Accs : 0.85537 | Time: 0.35 seconds\n",
            "Epoch: 443 | Train Loss: 0.50607 | Valid Loss: 0.50407 | Train Accs : 0.85028 | Valid Accs : 0.85415 | Time: 0.36 seconds\n",
            "Epoch: 444 | Train Loss: 0.50447 | Valid Loss: 0.50571 | Train Accs : 0.85101 | Valid Accs : 0.85421 | Time: 0.35 seconds\n",
            "Epoch: 445 | Train Loss: 0.50530 | Valid Loss: 0.50572 | Train Accs : 0.85052 | Valid Accs : 0.85676 | Time: 0.35 seconds\n",
            "Epoch: 446 | Train Loss: 0.50532 | Valid Loss: 0.50409 | Train Accs : 0.85016 | Valid Accs : 0.85628 | Time: 0.42 seconds\n",
            "Epoch: 447 | Train Loss: 0.50636 | Valid Loss: 0.50560 | Train Accs : 0.85059 | Valid Accs : 0.85569 | Time: 0.35 seconds\n",
            "Epoch: 448 | Train Loss: 0.50484 | Valid Loss: 0.50502 | Train Accs : 0.85004 | Valid Accs : 0.85305 | Time: 0.35 seconds\n",
            "Epoch: 449 | Train Loss: 0.50583 | Valid Loss: 0.50452 | Train Accs : 0.84967 | Valid Accs : 0.85402 | Time: 0.36 seconds\n",
            "Epoch: 450 | Train Loss: 0.50686 | Valid Loss: 0.50418 | Train Accs : 0.84930 | Valid Accs : 0.85464 | Time: 0.36 seconds\n",
            "Epoch: 451 | Train Loss: 0.50485 | Valid Loss: 0.50496 | Train Accs : 0.84851 | Valid Accs : 0.85723 | Time: 0.42 seconds\n",
            "Epoch: 452 | Train Loss: 0.50485 | Valid Loss: 0.50417 | Train Accs : 0.85016 | Valid Accs : 0.85646 | Time: 0.36 seconds\n",
            "Epoch: 453 | Train Loss: 0.50576 | Valid Loss: 0.50362 | Train Accs : 0.84985 | Valid Accs : 0.85926 | Time: 0.35 seconds\n",
            "Epoch: 454 | Train Loss: 0.50542 | Valid Loss: 0.50569 | Train Accs : 0.84991 | Valid Accs : 0.85318 | Time: 0.37 seconds\n",
            "Epoch: 455 | Train Loss: 0.50328 | Valid Loss: 0.50389 | Train Accs : 0.85181 | Valid Accs : 0.85752 | Time: 0.36 seconds\n",
            "Epoch: 456 | Train Loss: 0.50745 | Valid Loss: 0.50452 | Train Accs : 0.84564 | Valid Accs : 0.85859 | Time: 0.42 seconds\n",
            "Epoch: 457 | Train Loss: 0.50680 | Valid Loss: 0.50573 | Train Accs : 0.84601 | Valid Accs : 0.85389 | Time: 0.35 seconds\n",
            "Epoch: 458 | Train Loss: 0.50510 | Valid Loss: 0.50543 | Train Accs : 0.84851 | Valid Accs : 0.85389 | Time: 0.35 seconds\n",
            "Epoch: 459 | Train Loss: 0.50604 | Valid Loss: 0.50351 | Train Accs : 0.84753 | Valid Accs : 0.85853 | Time: 0.35 seconds\n",
            "Epoch: 460 | Train Loss: 0.50443 | Valid Loss: 0.50434 | Train Accs : 0.85004 | Valid Accs : 0.85652 | Time: 0.37 seconds\n",
            "Epoch: 461 | Train Loss: 0.50528 | Valid Loss: 0.50389 | Train Accs : 0.85016 | Valid Accs : 0.85633 | Time: 0.42 seconds\n",
            "Epoch: 462 | Train Loss: 0.50534 | Valid Loss: 0.50403 | Train Accs : 0.85040 | Valid Accs : 0.85556 | Time: 0.36 seconds\n",
            "Epoch: 463 | Train Loss: 0.50771 | Valid Loss: 0.50539 | Train Accs : 0.84796 | Valid Accs : 0.85701 | Time: 0.36 seconds\n",
            "Epoch: 464 | Train Loss: 0.50389 | Valid Loss: 0.50393 | Train Accs : 0.85046 | Valid Accs : 0.85810 | Time: 0.36 seconds\n",
            "Epoch: 465 | Train Loss: 0.50513 | Valid Loss: 0.50555 | Train Accs : 0.85034 | Valid Accs : 0.85476 | Time: 0.36 seconds\n",
            "Epoch: 466 | Train Loss: 0.50443 | Valid Loss: 0.50439 | Train Accs : 0.85059 | Valid Accs : 0.85603 | Time: 0.42 seconds\n",
            "Epoch: 467 | Train Loss: 0.50471 | Valid Loss: 0.50462 | Train Accs : 0.85040 | Valid Accs : 0.85536 | Time: 0.36 seconds\n",
            "Epoch: 468 | Train Loss: 0.50402 | Valid Loss: 0.50349 | Train Accs : 0.85046 | Valid Accs : 0.85614 | Time: 0.36 seconds\n",
            "Epoch: 469 | Train Loss: 0.50359 | Valid Loss: 0.50457 | Train Accs : 0.85028 | Valid Accs : 0.85432 | Time: 0.36 seconds\n",
            "Epoch: 470 | Train Loss: 0.50553 | Valid Loss: 0.50535 | Train Accs : 0.84747 | Valid Accs : 0.85707 | Time: 0.36 seconds\n",
            "Epoch: 471 | Train Loss: 0.50657 | Valid Loss: 0.50570 | Train Accs : 0.85052 | Valid Accs : 0.85599 | Time: 0.42 seconds\n",
            "Epoch: 472 | Train Loss: 0.50512 | Valid Loss: 0.50453 | Train Accs : 0.84979 | Valid Accs : 0.85483 | Time: 0.36 seconds\n",
            "Epoch: 473 | Train Loss: 0.50443 | Valid Loss: 0.50474 | Train Accs : 0.85175 | Valid Accs : 0.85707 | Time: 0.36 seconds\n",
            "Epoch: 474 | Train Loss: 0.50464 | Valid Loss: 0.50523 | Train Accs : 0.85089 | Valid Accs : 0.85462 | Time: 0.36 seconds\n",
            "Epoch: 475 | Train Loss: 0.50420 | Valid Loss: 0.50486 | Train Accs : 0.85223 | Valid Accs : 0.85462 | Time: 0.36 seconds\n",
            "Epoch: 476 | Train Loss: 0.50430 | Valid Loss: 0.50494 | Train Accs : 0.85028 | Valid Accs : 0.85676 | Time: 0.43 seconds\n",
            "Epoch: 477 | Train Loss: 0.50469 | Valid Loss: 0.50455 | Train Accs : 0.84772 | Valid Accs : 0.85834 | Time: 0.36 seconds\n",
            "Epoch: 478 | Train Loss: 0.50442 | Valid Loss: 0.50401 | Train Accs : 0.84918 | Valid Accs : 0.85701 | Time: 0.36 seconds\n",
            "Epoch: 479 | Train Loss: 0.50480 | Valid Loss: 0.50299 | Train Accs : 0.85071 | Valid Accs : 0.85626 | Time: 0.37 seconds\n",
            "Epoch: 480 | Train Loss: 0.50555 | Valid Loss: 0.50498 | Train Accs : 0.84882 | Valid Accs : 0.85506 | Time: 0.38 seconds\n",
            "Epoch: 481 | Train Loss: 0.50686 | Valid Loss: 0.50395 | Train Accs : 0.84796 | Valid Accs : 0.85817 | Time: 0.42 seconds\n",
            "Epoch: 482 | Train Loss: 0.50370 | Valid Loss: 0.50349 | Train Accs : 0.85065 | Valid Accs : 0.85708 | Time: 0.36 seconds\n",
            "Epoch: 483 | Train Loss: 0.50603 | Valid Loss: 0.50450 | Train Accs : 0.84918 | Valid Accs : 0.85622 | Time: 0.36 seconds\n",
            "Epoch: 484 | Train Loss: 0.50389 | Valid Loss: 0.50488 | Train Accs : 0.84998 | Valid Accs : 0.85476 | Time: 0.36 seconds\n",
            "Epoch: 485 | Train Loss: 0.50395 | Valid Loss: 0.50432 | Train Accs : 0.85059 | Valid Accs : 0.85635 | Time: 0.37 seconds\n",
            "Epoch: 486 | Train Loss: 0.50538 | Valid Loss: 0.50415 | Train Accs : 0.84851 | Valid Accs : 0.85737 | Time: 0.42 seconds\n",
            "Epoch: 487 | Train Loss: 0.50580 | Valid Loss: 0.50536 | Train Accs : 0.85101 | Valid Accs : 0.85549 | Time: 0.37 seconds\n",
            "Epoch: 488 | Train Loss: 0.50721 | Valid Loss: 0.50256 | Train Accs : 0.84528 | Valid Accs : 0.85797 | Time: 0.36 seconds\n",
            "Epoch: 489 | Train Loss: 0.50514 | Valid Loss: 0.50549 | Train Accs : 0.84973 | Valid Accs : 0.85519 | Time: 0.35 seconds\n",
            "Epoch: 490 | Train Loss: 0.50513 | Valid Loss: 0.50531 | Train Accs : 0.85242 | Valid Accs : 0.85318 | Time: 0.36 seconds\n",
            "Epoch: 491 | Train Loss: 0.50560 | Valid Loss: 0.50512 | Train Accs : 0.85010 | Valid Accs : 0.85707 | Time: 0.43 seconds\n",
            "Epoch: 492 | Train Loss: 0.50579 | Valid Loss: 0.50501 | Train Accs : 0.84973 | Valid Accs : 0.85293 | Time: 0.37 seconds\n",
            "Epoch: 493 | Train Loss: 0.50632 | Valid Loss: 0.50559 | Train Accs : 0.84961 | Valid Accs : 0.85385 | Time: 0.35 seconds\n",
            "Epoch: 494 | Train Loss: 0.50437 | Valid Loss: 0.50465 | Train Accs : 0.84943 | Valid Accs : 0.85712 | Time: 0.35 seconds\n",
            "Epoch: 495 | Train Loss: 0.50635 | Valid Loss: 0.50511 | Train Accs : 0.85095 | Valid Accs : 0.85399 | Time: 0.36 seconds\n",
            "Epoch: 496 | Train Loss: 0.50546 | Valid Loss: 0.50361 | Train Accs : 0.84955 | Valid Accs : 0.85568 | Time: 0.42 seconds\n",
            "Epoch: 497 | Train Loss: 0.50611 | Valid Loss: 0.50367 | Train Accs : 0.84888 | Valid Accs : 0.85532 | Time: 0.36 seconds\n",
            "Epoch: 498 | Train Loss: 0.50305 | Valid Loss: 0.50489 | Train Accs : 0.84949 | Valid Accs : 0.85620 | Time: 0.36 seconds\n",
            "Epoch: 499 | Train Loss: 0.50453 | Valid Loss: 0.50379 | Train Accs : 0.84961 | Valid Accs : 0.85725 | Time: 0.35 seconds\n",
            "Epoch: 500 | Train Loss: 0.50338 | Valid Loss: 0.50331 | Train Accs : 0.85059 | Valid Accs : 0.85688 | Time: 0.35 seconds\n",
            "Epoch: 501 | Train Loss: 0.50501 | Valid Loss: 0.50338 | Train Accs : 0.85034 | Valid Accs : 0.85939 | Time: 0.42 seconds\n",
            "Epoch: 502 | Train Loss: 0.50471 | Valid Loss: 0.50407 | Train Accs : 0.85040 | Valid Accs : 0.85549 | Time: 0.35 seconds\n",
            "Epoch: 503 | Train Loss: 0.50638 | Valid Loss: 0.50365 | Train Accs : 0.84650 | Valid Accs : 0.85767 | Time: 0.36 seconds\n",
            "Epoch: 504 | Train Loss: 0.50540 | Valid Loss: 0.50406 | Train Accs : 0.84790 | Valid Accs : 0.85566 | Time: 0.36 seconds\n",
            "Epoch: 505 | Train Loss: 0.50514 | Valid Loss: 0.50414 | Train Accs : 0.85022 | Valid Accs : 0.85492 | Time: 0.35 seconds\n",
            "Epoch: 506 | Train Loss: 0.50665 | Valid Loss: 0.50417 | Train Accs : 0.84869 | Valid Accs : 0.85626 | Time: 0.44 seconds\n",
            "Epoch: 507 | Train Loss: 0.50501 | Valid Loss: 0.50428 | Train Accs : 0.85010 | Valid Accs : 0.85545 | Time: 0.39 seconds\n",
            "Epoch: 508 | Train Loss: 0.50375 | Valid Loss: 0.50400 | Train Accs : 0.84772 | Valid Accs : 0.85693 | Time: 0.36 seconds\n",
            "Epoch: 509 | Train Loss: 0.50531 | Valid Loss: 0.50362 | Train Accs : 0.84906 | Valid Accs : 0.85815 | Time: 0.36 seconds\n",
            "Epoch: 510 | Train Loss: 0.50525 | Valid Loss: 0.50475 | Train Accs : 0.84906 | Valid Accs : 0.85451 | Time: 0.36 seconds\n",
            "Epoch: 511 | Train Loss: 0.50376 | Valid Loss: 0.50389 | Train Accs : 0.84955 | Valid Accs : 0.85682 | Time: 0.42 seconds\n",
            "Epoch: 512 | Train Loss: 0.50529 | Valid Loss: 0.50437 | Train Accs : 0.84924 | Valid Accs : 0.85675 | Time: 0.36 seconds\n",
            "Epoch: 513 | Train Loss: 0.50443 | Valid Loss: 0.50497 | Train Accs : 0.85236 | Valid Accs : 0.85459 | Time: 0.36 seconds\n",
            "Epoch: 514 | Train Loss: 0.50494 | Valid Loss: 0.50373 | Train Accs : 0.85193 | Valid Accs : 0.85676 | Time: 0.36 seconds\n",
            "Epoch: 515 | Train Loss: 0.50399 | Valid Loss: 0.50446 | Train Accs : 0.84937 | Valid Accs : 0.85753 | Time: 0.36 seconds\n",
            "Epoch: 516 | Train Loss: 0.50538 | Valid Loss: 0.50305 | Train Accs : 0.84900 | Valid Accs : 0.85622 | Time: 0.42 seconds\n",
            "Epoch: 517 | Train Loss: 0.50408 | Valid Loss: 0.50526 | Train Accs : 0.85114 | Valid Accs : 0.85457 | Time: 0.36 seconds\n",
            "Epoch: 518 | Train Loss: 0.50526 | Valid Loss: 0.50380 | Train Accs : 0.84814 | Valid Accs : 0.85639 | Time: 0.35 seconds\n",
            "Epoch: 519 | Train Loss: 0.50267 | Valid Loss: 0.50369 | Train Accs : 0.85236 | Valid Accs : 0.85840 | Time: 0.36 seconds\n",
            "Epoch: 520 | Train Loss: 0.50474 | Valid Loss: 0.50483 | Train Accs : 0.84979 | Valid Accs : 0.85470 | Time: 0.36 seconds\n",
            "Epoch: 521 | Train Loss: 0.50515 | Valid Loss: 0.50328 | Train Accs : 0.85162 | Valid Accs : 0.85774 | Time: 0.43 seconds\n",
            "Epoch: 522 | Train Loss: 0.50538 | Valid Loss: 0.50423 | Train Accs : 0.85052 | Valid Accs : 0.85476 | Time: 0.37 seconds\n",
            "Epoch: 523 | Train Loss: 0.50646 | Valid Loss: 0.50419 | Train Accs : 0.84875 | Valid Accs : 0.85530 | Time: 0.36 seconds\n",
            "Epoch: 524 | Train Loss: 0.50363 | Valid Loss: 0.50426 | Train Accs : 0.85034 | Valid Accs : 0.85768 | Time: 0.35 seconds\n",
            "Epoch: 525 | Train Loss: 0.50533 | Valid Loss: 0.50519 | Train Accs : 0.84991 | Valid Accs : 0.85549 | Time: 0.36 seconds\n",
            "Epoch: 526 | Train Loss: 0.50369 | Valid Loss: 0.50393 | Train Accs : 0.84875 | Valid Accs : 0.85755 | Time: 0.43 seconds\n",
            "Epoch: 527 | Train Loss: 0.50528 | Valid Loss: 0.50268 | Train Accs : 0.84827 | Valid Accs : 0.86048 | Time: 0.36 seconds\n",
            "Epoch: 528 | Train Loss: 0.50756 | Valid Loss: 0.50315 | Train Accs : 0.84821 | Valid Accs : 0.85750 | Time: 0.36 seconds\n",
            "Epoch: 529 | Train Loss: 0.50331 | Valid Loss: 0.50535 | Train Accs : 0.84985 | Valid Accs : 0.85517 | Time: 0.35 seconds\n",
            "Epoch: 530 | Train Loss: 0.50596 | Valid Loss: 0.50470 | Train Accs : 0.84930 | Valid Accs : 0.85707 | Time: 0.36 seconds\n",
            "Epoch: 531 | Train Loss: 0.50500 | Valid Loss: 0.50384 | Train Accs : 0.85089 | Valid Accs : 0.85532 | Time: 0.42 seconds\n",
            "Epoch: 532 | Train Loss: 0.50286 | Valid Loss: 0.50456 | Train Accs : 0.85059 | Valid Accs : 0.85620 | Time: 0.36 seconds\n",
            "Epoch: 533 | Train Loss: 0.50545 | Valid Loss: 0.50539 | Train Accs : 0.85052 | Valid Accs : 0.85481 | Time: 0.35 seconds\n",
            "Epoch: 534 | Train Loss: 0.50551 | Valid Loss: 0.50618 | Train Accs : 0.84790 | Valid Accs : 0.85511 | Time: 0.35 seconds\n",
            "Epoch: 535 | Train Loss: 0.50483 | Valid Loss: 0.50440 | Train Accs : 0.85034 | Valid Accs : 0.85671 | Time: 0.35 seconds\n",
            "Epoch: 536 | Train Loss: 0.50449 | Valid Loss: 0.50450 | Train Accs : 0.84949 | Valid Accs : 0.85628 | Time: 0.43 seconds\n",
            "Epoch: 537 | Train Loss: 0.50531 | Valid Loss: 0.50423 | Train Accs : 0.84882 | Valid Accs : 0.85646 | Time: 0.36 seconds\n",
            "Epoch: 538 | Train Loss: 0.50709 | Valid Loss: 0.50515 | Train Accs : 0.84686 | Valid Accs : 0.85530 | Time: 0.36 seconds\n",
            "Epoch: 539 | Train Loss: 0.50499 | Valid Loss: 0.50480 | Train Accs : 0.85229 | Valid Accs : 0.85378 | Time: 0.35 seconds\n",
            "Epoch: 540 | Train Loss: 0.50448 | Valid Loss: 0.50397 | Train Accs : 0.84930 | Valid Accs : 0.85532 | Time: 0.35 seconds\n",
            "Epoch: 541 | Train Loss: 0.50597 | Valid Loss: 0.50498 | Train Accs : 0.84882 | Valid Accs : 0.85415 | Time: 0.44 seconds\n",
            "Epoch: 542 | Train Loss: 0.50665 | Valid Loss: 0.50467 | Train Accs : 0.84857 | Valid Accs : 0.85611 | Time: 0.37 seconds\n",
            "Epoch: 543 | Train Loss: 0.50959 | Valid Loss: 0.50339 | Train Accs : 0.85095 | Valid Accs : 0.85598 | Time: 0.35 seconds\n",
            "Epoch: 544 | Train Loss: 0.50567 | Valid Loss: 0.50488 | Train Accs : 0.84937 | Valid Accs : 0.85372 | Time: 0.36 seconds\n",
            "Epoch: 545 | Train Loss: 0.50611 | Valid Loss: 0.50543 | Train Accs : 0.85052 | Valid Accs : 0.85220 | Time: 0.35 seconds\n",
            "Epoch: 546 | Train Loss: 0.50393 | Valid Loss: 0.50619 | Train Accs : 0.85101 | Valid Accs : 0.85414 | Time: 0.42 seconds\n",
            "Epoch: 547 | Train Loss: 0.50266 | Valid Loss: 0.50399 | Train Accs : 0.85126 | Valid Accs : 0.85419 | Time: 0.37 seconds\n",
            "Epoch: 548 | Train Loss: 0.50606 | Valid Loss: 0.50310 | Train Accs : 0.85028 | Valid Accs : 0.85712 | Time: 0.36 seconds\n",
            "Epoch: 549 | Train Loss: 0.50379 | Valid Loss: 0.50495 | Train Accs : 0.85138 | Valid Accs : 0.85693 | Time: 0.36 seconds\n",
            "Epoch: 550 | Train Loss: 0.50718 | Valid Loss: 0.50556 | Train Accs : 0.84888 | Valid Accs : 0.85269 | Time: 0.35 seconds\n",
            "Epoch: 551 | Train Loss: 0.50450 | Valid Loss: 0.50507 | Train Accs : 0.85144 | Valid Accs : 0.85511 | Time: 0.42 seconds\n",
            "Epoch: 552 | Train Loss: 0.50547 | Valid Loss: 0.50437 | Train Accs : 0.84894 | Valid Accs : 0.85445 | Time: 0.36 seconds\n",
            "Epoch: 553 | Train Loss: 0.50543 | Valid Loss: 0.50367 | Train Accs : 0.84857 | Valid Accs : 0.85731 | Time: 0.35 seconds\n",
            "Epoch: 554 | Train Loss: 0.50526 | Valid Loss: 0.50392 | Train Accs : 0.85071 | Valid Accs : 0.85590 | Time: 0.36 seconds\n",
            "Epoch: 555 | Train Loss: 0.50585 | Valid Loss: 0.50417 | Train Accs : 0.84912 | Valid Accs : 0.85622 | Time: 0.35 seconds\n",
            "Epoch: 556 | Train Loss: 0.50441 | Valid Loss: 0.50476 | Train Accs : 0.84967 | Valid Accs : 0.85859 | Time: 0.42 seconds\n",
            "Epoch: 557 | Train Loss: 0.50532 | Valid Loss: 0.50426 | Train Accs : 0.84869 | Valid Accs : 0.85590 | Time: 0.36 seconds\n",
            "Epoch: 558 | Train Loss: 0.50643 | Valid Loss: 0.50456 | Train Accs : 0.84827 | Valid Accs : 0.85432 | Time: 0.37 seconds\n",
            "Epoch: 559 | Train Loss: 0.50397 | Valid Loss: 0.50449 | Train Accs : 0.85040 | Valid Accs : 0.85432 | Time: 0.36 seconds\n",
            "Epoch: 560 | Train Loss: 0.50431 | Valid Loss: 0.50406 | Train Accs : 0.85095 | Valid Accs : 0.85549 | Time: 0.36 seconds\n",
            "Epoch: 561 | Train Loss: 0.50449 | Valid Loss: 0.50539 | Train Accs : 0.85126 | Valid Accs : 0.85616 | Time: 0.42 seconds\n",
            "Epoch: 562 | Train Loss: 0.50479 | Valid Loss: 0.50447 | Train Accs : 0.85175 | Valid Accs : 0.85714 | Time: 0.36 seconds\n",
            "Epoch: 563 | Train Loss: 0.50537 | Valid Loss: 0.50449 | Train Accs : 0.85028 | Valid Accs : 0.85707 | Time: 0.36 seconds\n",
            "Epoch: 564 | Train Loss: 0.50575 | Valid Loss: 0.50439 | Train Accs : 0.85217 | Valid Accs : 0.85459 | Time: 0.37 seconds\n",
            "Epoch: 565 | Train Loss: 0.50451 | Valid Loss: 0.50321 | Train Accs : 0.84857 | Valid Accs : 0.85761 | Time: 0.36 seconds\n",
            "Epoch: 566 | Train Loss: 0.50398 | Valid Loss: 0.50397 | Train Accs : 0.84912 | Valid Accs : 0.85755 | Time: 0.42 seconds\n",
            "Epoch: 567 | Train Loss: 0.50472 | Valid Loss: 0.50420 | Train Accs : 0.84875 | Valid Accs : 0.85577 | Time: 0.36 seconds\n",
            "Epoch: 568 | Train Loss: 0.50340 | Valid Loss: 0.50395 | Train Accs : 0.85016 | Valid Accs : 0.85506 | Time: 0.37 seconds\n",
            "Epoch: 569 | Train Loss: 0.50522 | Valid Loss: 0.50325 | Train Accs : 0.84967 | Valid Accs : 0.85682 | Time: 0.36 seconds\n",
            "Epoch: 570 | Train Loss: 0.50613 | Valid Loss: 0.50413 | Train Accs : 0.85040 | Valid Accs : 0.85530 | Time: 0.36 seconds\n",
            "Epoch: 571 | Train Loss: 0.50526 | Valid Loss: 0.50425 | Train Accs : 0.85040 | Valid Accs : 0.85663 | Time: 0.43 seconds\n",
            "Epoch: 572 | Train Loss: 0.50349 | Valid Loss: 0.50473 | Train Accs : 0.85260 | Valid Accs : 0.85530 | Time: 0.36 seconds\n",
            "Epoch: 573 | Train Loss: 0.50558 | Valid Loss: 0.50419 | Train Accs : 0.85004 | Valid Accs : 0.85676 | Time: 0.35 seconds\n",
            "Epoch: 574 | Train Loss: 0.50531 | Valid Loss: 0.50454 | Train Accs : 0.85095 | Valid Accs : 0.85622 | Time: 0.36 seconds\n",
            "Epoch: 575 | Train Loss: 0.50614 | Valid Loss: 0.50402 | Train Accs : 0.84534 | Valid Accs : 0.85688 | Time: 0.36 seconds\n",
            "Epoch: 576 | Train Loss: 0.50425 | Valid Loss: 0.50481 | Train Accs : 0.84998 | Valid Accs : 0.85645 | Time: 0.42 seconds\n",
            "Epoch: 577 | Train Loss: 0.50427 | Valid Loss: 0.50495 | Train Accs : 0.85034 | Valid Accs : 0.85622 | Time: 0.37 seconds\n",
            "Epoch: 578 | Train Loss: 0.50527 | Valid Loss: 0.50441 | Train Accs : 0.84961 | Valid Accs : 0.85755 | Time: 0.35 seconds\n",
            "Epoch: 579 | Train Loss: 0.50487 | Valid Loss: 0.50387 | Train Accs : 0.84955 | Valid Accs : 0.85750 | Time: 0.36 seconds\n",
            "Epoch: 580 | Train Loss: 0.50664 | Valid Loss: 0.50427 | Train Accs : 0.84674 | Valid Accs : 0.85707 | Time: 0.35 seconds\n",
            "Epoch: 581 | Train Loss: 0.50502 | Valid Loss: 0.50437 | Train Accs : 0.85028 | Valid Accs : 0.85506 | Time: 0.42 seconds\n",
            "Epoch: 582 | Train Loss: 0.50469 | Valid Loss: 0.50361 | Train Accs : 0.85083 | Valid Accs : 0.85601 | Time: 0.37 seconds\n",
            "Epoch: 583 | Train Loss: 0.50290 | Valid Loss: 0.50479 | Train Accs : 0.85278 | Valid Accs : 0.85622 | Time: 0.35 seconds\n",
            "Epoch: 584 | Train Loss: 0.50683 | Valid Loss: 0.50319 | Train Accs : 0.85004 | Valid Accs : 0.85859 | Time: 0.36 seconds\n",
            "Epoch: 585 | Train Loss: 0.50303 | Valid Loss: 0.50407 | Train Accs : 0.85303 | Valid Accs : 0.85476 | Time: 0.36 seconds\n",
            "Epoch: 586 | Train Loss: 0.50665 | Valid Loss: 0.50453 | Train Accs : 0.84802 | Valid Accs : 0.85554 | Time: 0.42 seconds\n",
            "Epoch: 587 | Train Loss: 0.50717 | Valid Loss: 0.50271 | Train Accs : 0.84790 | Valid Accs : 0.85633 | Time: 0.35 seconds\n",
            "Epoch: 588 | Train Loss: 0.50530 | Valid Loss: 0.50417 | Train Accs : 0.84912 | Valid Accs : 0.85633 | Time: 0.36 seconds\n",
            "Epoch: 589 | Train Loss: 0.50470 | Valid Loss: 0.50507 | Train Accs : 0.85120 | Valid Accs : 0.85500 | Time: 0.36 seconds\n",
            "Epoch: 590 | Train Loss: 0.50468 | Valid Loss: 0.50478 | Train Accs : 0.85229 | Valid Accs : 0.85372 | Time: 0.36 seconds\n",
            "Epoch: 591 | Train Loss: 0.50556 | Valid Loss: 0.50420 | Train Accs : 0.85150 | Valid Accs : 0.85372 | Time: 0.43 seconds\n",
            "Epoch: 592 | Train Loss: 0.50832 | Valid Loss: 0.50410 | Train Accs : 0.84839 | Valid Accs : 0.85793 | Time: 0.36 seconds\n",
            "Epoch: 593 | Train Loss: 0.50467 | Valid Loss: 0.50344 | Train Accs : 0.85010 | Valid Accs : 0.85737 | Time: 0.36 seconds\n",
            "Epoch: 594 | Train Loss: 0.50401 | Valid Loss: 0.50596 | Train Accs : 0.85022 | Valid Accs : 0.85408 | Time: 0.35 seconds\n",
            "Epoch: 595 | Train Loss: 0.50460 | Valid Loss: 0.50390 | Train Accs : 0.84961 | Valid Accs : 0.85590 | Time: 0.36 seconds\n",
            "Epoch: 596 | Train Loss: 0.50458 | Valid Loss: 0.50453 | Train Accs : 0.85040 | Valid Accs : 0.85122 | Time: 0.43 seconds\n",
            "Epoch: 597 | Train Loss: 0.50529 | Valid Loss: 0.50466 | Train Accs : 0.84888 | Valid Accs : 0.85675 | Time: 0.36 seconds\n",
            "Epoch: 598 | Train Loss: 0.50546 | Valid Loss: 0.50544 | Train Accs : 0.84943 | Valid Accs : 0.85353 | Time: 0.36 seconds\n",
            "Epoch: 599 | Train Loss: 0.50505 | Valid Loss: 0.50548 | Train Accs : 0.85077 | Valid Accs : 0.85111 | Time: 0.35 seconds\n",
            "Epoch: 600 | Train Loss: 0.50545 | Valid Loss: 0.50398 | Train Accs : 0.84753 | Valid Accs : 0.85628 | Time: 0.36 seconds\n",
            "Epoch: 601 | Train Loss: 0.50582 | Valid Loss: 0.50411 | Train Accs : 0.84949 | Valid Accs : 0.85581 | Time: 0.42 seconds\n",
            "Epoch: 602 | Train Loss: 0.50572 | Valid Loss: 0.50494 | Train Accs : 0.85010 | Valid Accs : 0.85633 | Time: 0.36 seconds\n",
            "Epoch: 603 | Train Loss: 0.50510 | Valid Loss: 0.50451 | Train Accs : 0.85272 | Valid Accs : 0.85329 | Time: 0.35 seconds\n",
            "Epoch: 604 | Train Loss: 0.50522 | Valid Loss: 0.50425 | Train Accs : 0.84778 | Valid Accs : 0.85554 | Time: 0.36 seconds\n",
            "Epoch: 605 | Train Loss: 0.50489 | Valid Loss: 0.50482 | Train Accs : 0.85004 | Valid Accs : 0.85676 | Time: 0.35 seconds\n",
            "Epoch: 606 | Train Loss: 0.50552 | Valid Loss: 0.50459 | Train Accs : 0.85004 | Valid Accs : 0.85720 | Time: 0.42 seconds\n",
            "Epoch: 607 | Train Loss: 0.50579 | Valid Loss: 0.50565 | Train Accs : 0.84668 | Valid Accs : 0.85220 | Time: 0.37 seconds\n",
            "Epoch: 608 | Train Loss: 0.50525 | Valid Loss: 0.50577 | Train Accs : 0.85175 | Valid Accs : 0.85263 | Time: 0.36 seconds\n",
            "Epoch: 609 | Train Loss: 0.50465 | Valid Loss: 0.50419 | Train Accs : 0.85284 | Valid Accs : 0.85434 | Time: 0.36 seconds\n",
            "Epoch: 610 | Train Loss: 0.50474 | Valid Loss: 0.50437 | Train Accs : 0.84955 | Valid Accs : 0.85750 | Time: 0.36 seconds\n",
            "Epoch: 611 | Train Loss: 0.50340 | Valid Loss: 0.50424 | Train Accs : 0.85126 | Valid Accs : 0.85628 | Time: 0.42 seconds\n",
            "Epoch: 612 | Train Loss: 0.50427 | Valid Loss: 0.50509 | Train Accs : 0.84912 | Valid Accs : 0.85598 | Time: 0.38 seconds\n",
            "Epoch: 613 | Train Loss: 0.50444 | Valid Loss: 0.50433 | Train Accs : 0.85187 | Valid Accs : 0.85492 | Time: 0.36 seconds\n",
            "Epoch: 614 | Train Loss: 0.50564 | Valid Loss: 0.50525 | Train Accs : 0.85211 | Valid Accs : 0.85239 | Time: 0.35 seconds\n",
            "Epoch: 615 | Train Loss: 0.50635 | Valid Loss: 0.50387 | Train Accs : 0.85223 | Valid Accs : 0.85603 | Time: 0.36 seconds\n",
            "Epoch: 616 | Train Loss: 0.50530 | Valid Loss: 0.50460 | Train Accs : 0.85107 | Valid Accs : 0.85445 | Time: 0.42 seconds\n",
            "Epoch: 617 | Train Loss: 0.50464 | Valid Loss: 0.50271 | Train Accs : 0.84833 | Valid Accs : 0.85951 | Time: 0.36 seconds\n",
            "Epoch: 618 | Train Loss: 0.50632 | Valid Loss: 0.50387 | Train Accs : 0.85083 | Valid Accs : 0.85768 | Time: 0.35 seconds\n",
            "Epoch: 619 | Train Loss: 0.50711 | Valid Loss: 0.50460 | Train Accs : 0.84967 | Valid Accs : 0.85554 | Time: 0.36 seconds\n",
            "Epoch: 620 | Train Loss: 0.50716 | Valid Loss: 0.50565 | Train Accs : 0.84985 | Valid Accs : 0.85190 | Time: 0.36 seconds\n",
            "Epoch: 621 | Train Loss: 0.50482 | Valid Loss: 0.50466 | Train Accs : 0.84955 | Valid Accs : 0.85579 | Time: 0.42 seconds\n",
            "Epoch: 622 | Train Loss: 0.50590 | Valid Loss: 0.50496 | Train Accs : 0.84851 | Valid Accs : 0.85554 | Time: 0.36 seconds\n",
            "Epoch: 623 | Train Loss: 0.50481 | Valid Loss: 0.50392 | Train Accs : 0.85034 | Valid Accs : 0.85902 | Time: 0.36 seconds\n",
            "Epoch: 624 | Train Loss: 0.50341 | Valid Loss: 0.50525 | Train Accs : 0.85205 | Valid Accs : 0.85641 | Time: 0.36 seconds\n",
            "Epoch: 625 | Train Loss: 0.50669 | Valid Loss: 0.50439 | Train Accs : 0.85144 | Valid Accs : 0.85630 | Time: 0.36 seconds\n",
            "Epoch: 626 | Train Loss: 0.50459 | Valid Loss: 0.50483 | Train Accs : 0.85394 | Valid Accs : 0.85573 | Time: 0.42 seconds\n",
            "Epoch: 627 | Train Loss: 0.50498 | Valid Loss: 0.50519 | Train Accs : 0.84973 | Valid Accs : 0.85489 | Time: 0.36 seconds\n",
            "Epoch: 628 | Train Loss: 0.50566 | Valid Loss: 0.50613 | Train Accs : 0.84808 | Valid Accs : 0.85380 | Time: 0.36 seconds\n",
            "Epoch: 629 | Train Loss: 0.50537 | Valid Loss: 0.50509 | Train Accs : 0.85071 | Valid Accs : 0.85641 | Time: 0.36 seconds\n",
            "Epoch: 630 | Train Loss: 0.50512 | Valid Loss: 0.50467 | Train Accs : 0.84900 | Valid Accs : 0.85641 | Time: 0.35 seconds\n",
            "Epoch: 631 | Train Loss: 0.50651 | Valid Loss: 0.50429 | Train Accs : 0.85034 | Valid Accs : 0.85568 | Time: 0.42 seconds\n",
            "Epoch: 632 | Train Loss: 0.50480 | Valid Loss: 0.50623 | Train Accs : 0.85022 | Valid Accs : 0.85269 | Time: 0.35 seconds\n",
            "Epoch: 633 | Train Loss: 0.50337 | Valid Loss: 0.50313 | Train Accs : 0.85083 | Valid Accs : 0.85847 | Time: 0.36 seconds\n",
            "Epoch: 634 | Train Loss: 0.50529 | Valid Loss: 0.50408 | Train Accs : 0.85168 | Valid Accs : 0.85695 | Time: 0.37 seconds\n",
            "Epoch: 635 | Train Loss: 0.50675 | Valid Loss: 0.50301 | Train Accs : 0.84973 | Valid Accs : 0.85896 | Time: 0.36 seconds\n",
            "Epoch: 636 | Train Loss: 0.50635 | Valid Loss: 0.50523 | Train Accs : 0.85089 | Valid Accs : 0.85361 | Time: 0.42 seconds\n",
            "Epoch: 637 | Train Loss: 0.50706 | Valid Loss: 0.50505 | Train Accs : 0.84875 | Valid Accs : 0.85457 | Time: 0.36 seconds\n",
            "Epoch: 638 | Train Loss: 0.50535 | Valid Loss: 0.50221 | Train Accs : 0.84698 | Valid Accs : 0.85902 | Time: 0.36 seconds\n",
            "Epoch: 639 | Train Loss: 0.50373 | Valid Loss: 0.50548 | Train Accs : 0.85168 | Valid Accs : 0.85312 | Time: 0.36 seconds\n",
            "Epoch: 640 | Train Loss: 0.50610 | Valid Loss: 0.50325 | Train Accs : 0.84949 | Valid Accs : 0.86095 | Time: 0.36 seconds\n",
            "Epoch: 641 | Train Loss: 0.50598 | Valid Loss: 0.50440 | Train Accs : 0.85040 | Valid Accs : 0.85605 | Time: 0.42 seconds\n",
            "Epoch: 642 | Train Loss: 0.50442 | Valid Loss: 0.50486 | Train Accs : 0.85126 | Valid Accs : 0.85507 | Time: 0.36 seconds\n",
            "Epoch: 643 | Train Loss: 0.50575 | Valid Loss: 0.50456 | Train Accs : 0.84827 | Valid Accs : 0.85451 | Time: 0.36 seconds\n",
            "Epoch: 644 | Train Loss: 0.50349 | Valid Loss: 0.50563 | Train Accs : 0.85071 | Valid Accs : 0.85530 | Time: 0.35 seconds\n",
            "Epoch: 645 | Train Loss: 0.50512 | Valid Loss: 0.50511 | Train Accs : 0.85144 | Valid Accs : 0.85586 | Time: 0.36 seconds\n",
            "Epoch: 646 | Train Loss: 0.50641 | Valid Loss: 0.50491 | Train Accs : 0.84888 | Valid Accs : 0.85688 | Time: 0.43 seconds\n",
            "Epoch: 647 | Train Loss: 0.50621 | Valid Loss: 0.50423 | Train Accs : 0.85004 | Valid Accs : 0.85513 | Time: 0.36 seconds\n",
            "Epoch: 648 | Train Loss: 0.50411 | Valid Loss: 0.50393 | Train Accs : 0.84955 | Valid Accs : 0.85742 | Time: 0.36 seconds\n",
            "Epoch: 649 | Train Loss: 0.50617 | Valid Loss: 0.50457 | Train Accs : 0.84906 | Valid Accs : 0.85581 | Time: 0.37 seconds\n",
            "Epoch: 650 | Train Loss: 0.50549 | Valid Loss: 0.50478 | Train Accs : 0.84814 | Valid Accs : 0.85646 | Time: 0.37 seconds\n",
            "Epoch: 651 | Train Loss: 0.50533 | Valid Loss: 0.50483 | Train Accs : 0.84717 | Valid Accs : 0.85536 | Time: 0.42 seconds\n",
            "Epoch: 652 | Train Loss: 0.50438 | Valid Loss: 0.50491 | Train Accs : 0.84930 | Valid Accs : 0.85603 | Time: 0.36 seconds\n",
            "Epoch: 653 | Train Loss: 0.50527 | Valid Loss: 0.50336 | Train Accs : 0.85162 | Valid Accs : 0.85861 | Time: 0.35 seconds\n",
            "Epoch: 654 | Train Loss: 0.50415 | Valid Loss: 0.50328 | Train Accs : 0.84698 | Valid Accs : 0.85877 | Time: 0.35 seconds\n",
            "Epoch: 655 | Train Loss: 0.50487 | Valid Loss: 0.50444 | Train Accs : 0.84998 | Valid Accs : 0.85367 | Time: 0.35 seconds\n",
            "Epoch: 656 | Train Loss: 0.50619 | Valid Loss: 0.50471 | Train Accs : 0.84827 | Valid Accs : 0.85628 | Time: 0.43 seconds\n",
            "Epoch: 657 | Train Loss: 0.50514 | Valid Loss: 0.50377 | Train Accs : 0.85010 | Valid Accs : 0.85823 | Time: 0.36 seconds\n",
            "Epoch: 658 | Train Loss: 0.50437 | Valid Loss: 0.50376 | Train Accs : 0.84833 | Valid Accs : 0.85725 | Time: 0.36 seconds\n",
            "Epoch: 659 | Train Loss: 0.50514 | Valid Loss: 0.50503 | Train Accs : 0.85211 | Valid Accs : 0.85489 | Time: 0.36 seconds\n",
            "Epoch: 660 | Train Loss: 0.50506 | Valid Loss: 0.50478 | Train Accs : 0.84998 | Valid Accs : 0.85584 | Time: 0.35 seconds\n",
            "Epoch: 661 | Train Loss: 0.50493 | Valid Loss: 0.50487 | Train Accs : 0.85004 | Valid Accs : 0.85665 | Time: 0.42 seconds\n",
            "Epoch: 662 | Train Loss: 0.50456 | Valid Loss: 0.50356 | Train Accs : 0.85168 | Valid Accs : 0.85799 | Time: 0.35 seconds\n",
            "Epoch: 663 | Train Loss: 0.50496 | Valid Loss: 0.50368 | Train Accs : 0.85107 | Valid Accs : 0.85440 | Time: 0.35 seconds\n",
            "Epoch: 664 | Train Loss: 0.50491 | Valid Loss: 0.50399 | Train Accs : 0.84967 | Valid Accs : 0.85744 | Time: 0.36 seconds\n",
            "Epoch: 665 | Train Loss: 0.50479 | Valid Loss: 0.50614 | Train Accs : 0.85114 | Valid Accs : 0.85380 | Time: 0.36 seconds\n",
            "Epoch: 666 | Train Loss: 0.50719 | Valid Loss: 0.50479 | Train Accs : 0.84772 | Valid Accs : 0.85434 | Time: 0.42 seconds\n",
            "Epoch: 667 | Train Loss: 0.50562 | Valid Loss: 0.50505 | Train Accs : 0.85126 | Valid Accs : 0.85519 | Time: 0.36 seconds\n",
            "Epoch: 668 | Train Loss: 0.50470 | Valid Loss: 0.50486 | Train Accs : 0.85052 | Valid Accs : 0.85549 | Time: 0.36 seconds\n",
            "Epoch: 669 | Train Loss: 0.50380 | Valid Loss: 0.50451 | Train Accs : 0.85059 | Valid Accs : 0.85532 | Time: 0.36 seconds\n",
            "Epoch: 670 | Train Loss: 0.50423 | Valid Loss: 0.50358 | Train Accs : 0.85065 | Valid Accs : 0.85671 | Time: 0.36 seconds\n",
            "Epoch: 671 | Train Loss: 0.50504 | Valid Loss: 0.50476 | Train Accs : 0.84912 | Valid Accs : 0.85676 | Time: 0.41 seconds\n",
            "Epoch: 672 | Train Loss: 0.50702 | Valid Loss: 0.50417 | Train Accs : 0.85150 | Valid Accs : 0.85738 | Time: 0.36 seconds\n",
            "Epoch: 673 | Train Loss: 0.50638 | Valid Loss: 0.50267 | Train Accs : 0.84924 | Valid Accs : 0.85956 | Time: 0.35 seconds\n",
            "Epoch: 674 | Train Loss: 0.50511 | Valid Loss: 0.50375 | Train Accs : 0.85034 | Valid Accs : 0.85870 | Time: 0.36 seconds\n",
            "Epoch: 675 | Train Loss: 0.50765 | Valid Loss: 0.50456 | Train Accs : 0.84888 | Valid Accs : 0.85489 | Time: 0.36 seconds\n",
            "Epoch: 676 | Train Loss: 0.50590 | Valid Loss: 0.50348 | Train Accs : 0.84857 | Valid Accs : 0.85768 | Time: 0.42 seconds\n",
            "Epoch: 677 | Train Loss: 0.50660 | Valid Loss: 0.50378 | Train Accs : 0.84668 | Valid Accs : 0.85573 | Time: 0.36 seconds\n",
            "Epoch: 678 | Train Loss: 0.50562 | Valid Loss: 0.50451 | Train Accs : 0.84937 | Valid Accs : 0.85562 | Time: 0.36 seconds\n",
            "Epoch: 679 | Train Loss: 0.50488 | Valid Loss: 0.50545 | Train Accs : 0.85126 | Valid Accs : 0.85483 | Time: 0.35 seconds\n",
            "Epoch: 680 | Train Loss: 0.50453 | Valid Loss: 0.50620 | Train Accs : 0.85205 | Valid Accs : 0.85440 | Time: 0.36 seconds\n",
            "Epoch: 681 | Train Loss: 0.50377 | Valid Loss: 0.50379 | Train Accs : 0.84979 | Valid Accs : 0.85799 | Time: 0.43 seconds\n",
            "Epoch: 682 | Train Loss: 0.50668 | Valid Loss: 0.50440 | Train Accs : 0.84827 | Valid Accs : 0.85491 | Time: 0.36 seconds\n",
            "Epoch: 683 | Train Loss: 0.50516 | Valid Loss: 0.50356 | Train Accs : 0.85333 | Valid Accs : 0.85641 | Time: 0.36 seconds\n",
            "Epoch: 684 | Train Loss: 0.50561 | Valid Loss: 0.50485 | Train Accs : 0.85187 | Valid Accs : 0.85385 | Time: 0.39 seconds\n",
            "Epoch: 685 | Train Loss: 0.50655 | Valid Loss: 0.50431 | Train Accs : 0.85022 | Valid Accs : 0.85641 | Time: 0.38 seconds\n",
            "Epoch: 686 | Train Loss: 0.50515 | Valid Loss: 0.50303 | Train Accs : 0.84784 | Valid Accs : 0.85829 | Time: 0.44 seconds\n",
            "Epoch: 687 | Train Loss: 0.50514 | Valid Loss: 0.50370 | Train Accs : 0.84808 | Valid Accs : 0.85750 | Time: 0.37 seconds\n",
            "Epoch: 688 | Train Loss: 0.50458 | Valid Loss: 0.50519 | Train Accs : 0.84967 | Valid Accs : 0.85367 | Time: 0.36 seconds\n",
            "Epoch: 689 | Train Loss: 0.50584 | Valid Loss: 0.50518 | Train Accs : 0.84930 | Valid Accs : 0.85603 | Time: 0.37 seconds\n",
            "Epoch: 690 | Train Loss: 0.50359 | Valid Loss: 0.50529 | Train Accs : 0.84900 | Valid Accs : 0.85481 | Time: 0.36 seconds\n",
            "Epoch: 691 | Train Loss: 0.50605 | Valid Loss: 0.50400 | Train Accs : 0.84845 | Valid Accs : 0.85682 | Time: 0.43 seconds\n",
            "Epoch: 692 | Train Loss: 0.50345 | Valid Loss: 0.50519 | Train Accs : 0.85175 | Valid Accs : 0.85355 | Time: 0.36 seconds\n",
            "Epoch: 693 | Train Loss: 0.50491 | Valid Loss: 0.50490 | Train Accs : 0.85126 | Valid Accs : 0.85361 | Time: 0.36 seconds\n",
            "Epoch: 694 | Train Loss: 0.50485 | Valid Loss: 0.50448 | Train Accs : 0.84796 | Valid Accs : 0.85785 | Time: 0.37 seconds\n",
            "Epoch: 695 | Train Loss: 0.50318 | Valid Loss: 0.50373 | Train Accs : 0.85101 | Valid Accs : 0.85688 | Time: 0.37 seconds\n",
            "Epoch: 696 | Train Loss: 0.50396 | Valid Loss: 0.50481 | Train Accs : 0.85065 | Valid Accs : 0.85800 | Time: 0.42 seconds\n",
            "Epoch: 697 | Train Loss: 0.50451 | Valid Loss: 0.50488 | Train Accs : 0.84973 | Valid Accs : 0.85579 | Time: 0.36 seconds\n",
            "Epoch: 698 | Train Loss: 0.50484 | Valid Loss: 0.50449 | Train Accs : 0.85199 | Valid Accs : 0.85622 | Time: 0.36 seconds\n",
            "Epoch: 699 | Train Loss: 0.50438 | Valid Loss: 0.50445 | Train Accs : 0.84918 | Valid Accs : 0.85994 | Time: 0.36 seconds\n",
            "Epoch: 700 | Train Loss: 0.50474 | Valid Loss: 0.50372 | Train Accs : 0.85040 | Valid Accs : 0.85859 | Time: 0.36 seconds\n",
            "Epoch: 701 | Train Loss: 0.50592 | Valid Loss: 0.50407 | Train Accs : 0.85101 | Valid Accs : 0.85241 | Time: 0.43 seconds\n",
            "Epoch: 702 | Train Loss: 0.50369 | Valid Loss: 0.50609 | Train Accs : 0.85162 | Valid Accs : 0.85209 | Time: 0.37 seconds\n",
            "Epoch: 703 | Train Loss: 0.50431 | Valid Loss: 0.50369 | Train Accs : 0.85278 | Valid Accs : 0.85494 | Time: 0.36 seconds\n",
            "Epoch: 704 | Train Loss: 0.50519 | Valid Loss: 0.50592 | Train Accs : 0.84644 | Valid Accs : 0.85791 | Time: 0.36 seconds\n",
            "Epoch: 705 | Train Loss: 0.50406 | Valid Loss: 0.50363 | Train Accs : 0.85077 | Valid Accs : 0.85810 | Time: 0.36 seconds\n",
            "Epoch: 706 | Train Loss: 0.50461 | Valid Loss: 0.50578 | Train Accs : 0.84937 | Valid Accs : 0.85464 | Time: 0.43 seconds\n",
            "Epoch: 707 | Train Loss: 0.50545 | Valid Loss: 0.50424 | Train Accs : 0.84827 | Valid Accs : 0.85804 | Time: 0.37 seconds\n",
            "Epoch: 708 | Train Loss: 0.50576 | Valid Loss: 0.50474 | Train Accs : 0.84949 | Valid Accs : 0.85744 | Time: 0.36 seconds\n",
            "Epoch: 709 | Train Loss: 0.50422 | Valid Loss: 0.50444 | Train Accs : 0.85046 | Valid Accs : 0.85586 | Time: 0.36 seconds\n",
            "Epoch: 710 | Train Loss: 0.50490 | Valid Loss: 0.50342 | Train Accs : 0.84924 | Valid Accs : 0.85676 | Time: 0.37 seconds\n",
            "Epoch: 711 | Train Loss: 0.50580 | Valid Loss: 0.50427 | Train Accs : 0.85040 | Valid Accs : 0.85646 | Time: 0.43 seconds\n",
            "Epoch: 712 | Train Loss: 0.50562 | Valid Loss: 0.50370 | Train Accs : 0.84943 | Valid Accs : 0.85723 | Time: 0.37 seconds\n",
            "Epoch: 713 | Train Loss: 0.50650 | Valid Loss: 0.50457 | Train Accs : 0.84900 | Valid Accs : 0.85372 | Time: 0.37 seconds\n",
            "Epoch: 714 | Train Loss: 0.50571 | Valid Loss: 0.50439 | Train Accs : 0.84973 | Valid Accs : 0.85489 | Time: 0.35 seconds\n",
            "Epoch: 715 | Train Loss: 0.50365 | Valid Loss: 0.50382 | Train Accs : 0.85242 | Valid Accs : 0.85630 | Time: 0.36 seconds\n",
            "Epoch: 716 | Train Loss: 0.50618 | Valid Loss: 0.50472 | Train Accs : 0.85138 | Valid Accs : 0.85641 | Time: 0.42 seconds\n",
            "Epoch: 717 | Train Loss: 0.50424 | Valid Loss: 0.50313 | Train Accs : 0.84991 | Valid Accs : 0.85603 | Time: 0.36 seconds\n",
            "Epoch: 718 | Train Loss: 0.50533 | Valid Loss: 0.50405 | Train Accs : 0.84900 | Valid Accs : 0.85487 | Time: 0.36 seconds\n",
            "Epoch: 719 | Train Loss: 0.50402 | Valid Loss: 0.50363 | Train Accs : 0.84912 | Valid Accs : 0.85603 | Time: 0.35 seconds\n",
            "Epoch: 720 | Train Loss: 0.50487 | Valid Loss: 0.50489 | Train Accs : 0.85040 | Valid Accs : 0.85543 | Time: 0.36 seconds\n",
            "Epoch: 721 | Train Loss: 0.50658 | Valid Loss: 0.50475 | Train Accs : 0.85156 | Valid Accs : 0.85361 | Time: 0.42 seconds\n",
            "Epoch: 722 | Train Loss: 0.50493 | Valid Loss: 0.50403 | Train Accs : 0.85175 | Valid Accs : 0.85633 | Time: 0.35 seconds\n",
            "Epoch: 723 | Train Loss: 0.50479 | Valid Loss: 0.50360 | Train Accs : 0.84833 | Valid Accs : 0.85592 | Time: 0.37 seconds\n",
            "Epoch: 724 | Train Loss: 0.50622 | Valid Loss: 0.50480 | Train Accs : 0.84918 | Valid Accs : 0.85532 | Time: 0.35 seconds\n",
            "Epoch: 725 | Train Loss: 0.50620 | Valid Loss: 0.50451 | Train Accs : 0.84796 | Valid Accs : 0.85524 | Time: 0.35 seconds\n",
            "Epoch: 726 | Train Loss: 0.50410 | Valid Loss: 0.50424 | Train Accs : 0.85101 | Valid Accs : 0.85421 | Time: 0.43 seconds\n",
            "Epoch: 727 | Train Loss: 0.50621 | Valid Loss: 0.50369 | Train Accs : 0.84943 | Valid Accs : 0.85731 | Time: 0.36 seconds\n",
            "Epoch: 728 | Train Loss: 0.50364 | Valid Loss: 0.50478 | Train Accs : 0.85114 | Valid Accs : 0.85536 | Time: 0.36 seconds\n",
            "Epoch: 729 | Train Loss: 0.50306 | Valid Loss: 0.50584 | Train Accs : 0.85065 | Valid Accs : 0.85500 | Time: 0.37 seconds\n",
            "Epoch: 730 | Train Loss: 0.50634 | Valid Loss: 0.50352 | Train Accs : 0.84991 | Valid Accs : 0.85573 | Time: 0.35 seconds\n",
            "Epoch: 731 | Train Loss: 0.50629 | Valid Loss: 0.50441 | Train Accs : 0.84937 | Valid Accs : 0.85639 | Time: 0.42 seconds\n",
            "Epoch: 732 | Train Loss: 0.50580 | Valid Loss: 0.50388 | Train Accs : 0.84680 | Valid Accs : 0.85652 | Time: 0.37 seconds\n",
            "Epoch: 733 | Train Loss: 0.50433 | Valid Loss: 0.50540 | Train Accs : 0.85150 | Valid Accs : 0.85459 | Time: 0.35 seconds\n",
            "Epoch: 734 | Train Loss: 0.50458 | Valid Loss: 0.50510 | Train Accs : 0.84973 | Valid Accs : 0.85348 | Time: 0.36 seconds\n",
            "Epoch: 735 | Train Loss: 0.50664 | Valid Loss: 0.50493 | Train Accs : 0.84961 | Valid Accs : 0.85628 | Time: 0.35 seconds\n",
            "Epoch: 736 | Train Loss: 0.50583 | Valid Loss: 0.50460 | Train Accs : 0.84985 | Valid Accs : 0.85492 | Time: 0.43 seconds\n",
            "Epoch: 737 | Train Loss: 0.50604 | Valid Loss: 0.50419 | Train Accs : 0.84900 | Valid Accs : 0.85688 | Time: 0.36 seconds\n",
            "Epoch: 738 | Train Loss: 0.50433 | Valid Loss: 0.50600 | Train Accs : 0.84930 | Valid Accs : 0.85517 | Time: 0.35 seconds\n",
            "Epoch: 739 | Train Loss: 0.50412 | Valid Loss: 0.50511 | Train Accs : 0.84937 | Valid Accs : 0.85579 | Time: 0.35 seconds\n",
            "Epoch: 740 | Train Loss: 0.50802 | Valid Loss: 0.50484 | Train Accs : 0.84564 | Valid Accs : 0.85690 | Time: 0.37 seconds\n",
            "Epoch: 741 | Train Loss: 0.50523 | Valid Loss: 0.50409 | Train Accs : 0.85107 | Valid Accs : 0.85305 | Time: 0.42 seconds\n",
            "Epoch: 742 | Train Loss: 0.50358 | Valid Loss: 0.50436 | Train Accs : 0.84998 | Valid Accs : 0.85633 | Time: 0.35 seconds\n",
            "Epoch: 743 | Train Loss: 0.50355 | Valid Loss: 0.50548 | Train Accs : 0.85120 | Valid Accs : 0.85628 | Time: 0.36 seconds\n",
            "Epoch: 744 | Train Loss: 0.50427 | Valid Loss: 0.50497 | Train Accs : 0.85028 | Valid Accs : 0.85633 | Time: 0.35 seconds\n",
            "Epoch: 745 | Train Loss: 0.50399 | Valid Loss: 0.50337 | Train Accs : 0.85095 | Valid Accs : 0.85592 | Time: 0.36 seconds\n",
            "Epoch: 746 | Train Loss: 0.50521 | Valid Loss: 0.50516 | Train Accs : 0.84912 | Valid Accs : 0.85658 | Time: 0.42 seconds\n",
            "Epoch: 747 | Train Loss: 0.50451 | Valid Loss: 0.50405 | Train Accs : 0.85303 | Valid Accs : 0.85609 | Time: 0.36 seconds\n",
            "Epoch: 748 | Train Loss: 0.50497 | Valid Loss: 0.50478 | Train Accs : 0.85168 | Valid Accs : 0.85494 | Time: 0.35 seconds\n",
            "Epoch: 749 | Train Loss: 0.50539 | Valid Loss: 0.50441 | Train Accs : 0.84906 | Valid Accs : 0.85785 | Time: 0.35 seconds\n",
            "Epoch: 750 | Train Loss: 0.50370 | Valid Loss: 0.50433 | Train Accs : 0.84912 | Valid Accs : 0.85592 | Time: 0.35 seconds\n",
            "Epoch: 751 | Train Loss: 0.50495 | Valid Loss: 0.50422 | Train Accs : 0.84698 | Valid Accs : 0.85543 | Time: 0.45 seconds\n",
            "Epoch: 752 | Train Loss: 0.50557 | Valid Loss: 0.50502 | Train Accs : 0.85004 | Valid Accs : 0.85459 | Time: 0.36 seconds\n",
            "Epoch: 753 | Train Loss: 0.50702 | Valid Loss: 0.50502 | Train Accs : 0.85126 | Valid Accs : 0.85372 | Time: 0.35 seconds\n",
            "Epoch: 754 | Train Loss: 0.50518 | Valid Loss: 0.50425 | Train Accs : 0.84967 | Valid Accs : 0.85575 | Time: 0.36 seconds\n",
            "Epoch: 755 | Train Loss: 0.50413 | Valid Loss: 0.50441 | Train Accs : 0.85040 | Valid Accs : 0.85513 | Time: 0.35 seconds\n",
            "Epoch: 756 | Train Loss: 0.50477 | Valid Loss: 0.50525 | Train Accs : 0.85083 | Valid Accs : 0.85543 | Time: 0.42 seconds\n",
            "Epoch: 757 | Train Loss: 0.50781 | Valid Loss: 0.50441 | Train Accs : 0.84912 | Valid Accs : 0.85701 | Time: 0.36 seconds\n",
            "Epoch: 758 | Train Loss: 0.50317 | Valid Loss: 0.50452 | Train Accs : 0.85010 | Valid Accs : 0.85389 | Time: 0.35 seconds\n",
            "Epoch: 759 | Train Loss: 0.50465 | Valid Loss: 0.50503 | Train Accs : 0.85120 | Valid Accs : 0.85310 | Time: 0.35 seconds\n",
            "Epoch: 760 | Train Loss: 0.50713 | Valid Loss: 0.50365 | Train Accs : 0.84979 | Valid Accs : 0.85554 | Time: 0.36 seconds\n",
            "Epoch: 761 | Train Loss: 0.50643 | Valid Loss: 0.50404 | Train Accs : 0.85040 | Valid Accs : 0.85391 | Time: 0.41 seconds\n",
            "Epoch: 762 | Train Loss: 0.50508 | Valid Loss: 0.50436 | Train Accs : 0.85028 | Valid Accs : 0.85671 | Time: 0.36 seconds\n",
            "Epoch: 763 | Train Loss: 0.50473 | Valid Loss: 0.50408 | Train Accs : 0.85028 | Valid Accs : 0.85714 | Time: 0.35 seconds\n",
            "Epoch: 764 | Train Loss: 0.50541 | Valid Loss: 0.50545 | Train Accs : 0.84869 | Valid Accs : 0.85603 | Time: 0.35 seconds\n",
            "Epoch: 765 | Train Loss: 0.50441 | Valid Loss: 0.50498 | Train Accs : 0.85077 | Valid Accs : 0.85378 | Time: 0.36 seconds\n",
            "Epoch: 766 | Train Loss: 0.50576 | Valid Loss: 0.50703 | Train Accs : 0.84814 | Valid Accs : 0.85239 | Time: 0.42 seconds\n",
            "Epoch: 767 | Train Loss: 0.50522 | Valid Loss: 0.50366 | Train Accs : 0.84729 | Valid Accs : 0.85877 | Time: 0.37 seconds\n",
            "Epoch: 768 | Train Loss: 0.50413 | Valid Loss: 0.50415 | Train Accs : 0.84906 | Valid Accs : 0.85767 | Time: 0.36 seconds\n",
            "Epoch: 769 | Train Loss: 0.50363 | Valid Loss: 0.50502 | Train Accs : 0.84930 | Valid Accs : 0.85481 | Time: 0.36 seconds\n",
            "Epoch: 770 | Train Loss: 0.50418 | Valid Loss: 0.50472 | Train Accs : 0.84967 | Valid Accs : 0.85299 | Time: 0.36 seconds\n",
            "Epoch: 771 | Train Loss: 0.50565 | Valid Loss: 0.50512 | Train Accs : 0.84821 | Valid Accs : 0.85438 | Time: 0.42 seconds\n",
            "Epoch: 772 | Train Loss: 0.50294 | Valid Loss: 0.50508 | Train Accs : 0.85156 | Valid Accs : 0.85361 | Time: 0.36 seconds\n",
            "Epoch: 773 | Train Loss: 0.50568 | Valid Loss: 0.50367 | Train Accs : 0.85065 | Valid Accs : 0.85755 | Time: 0.37 seconds\n",
            "Epoch: 774 | Train Loss: 0.50522 | Valid Loss: 0.50518 | Train Accs : 0.85083 | Valid Accs : 0.85209 | Time: 0.35 seconds\n",
            "Epoch: 775 | Train Loss: 0.50526 | Valid Loss: 0.50415 | Train Accs : 0.84845 | Valid Accs : 0.85742 | Time: 0.35 seconds\n",
            "Epoch: 776 | Train Loss: 0.50361 | Valid Loss: 0.50446 | Train Accs : 0.84900 | Valid Accs : 0.85543 | Time: 0.42 seconds\n",
            "Epoch: 777 | Train Loss: 0.50761 | Valid Loss: 0.50384 | Train Accs : 0.84991 | Valid Accs : 0.85609 | Time: 0.36 seconds\n",
            "Epoch: 778 | Train Loss: 0.50695 | Valid Loss: 0.50376 | Train Accs : 0.84753 | Valid Accs : 0.85549 | Time: 0.36 seconds\n",
            "Epoch: 779 | Train Loss: 0.50577 | Valid Loss: 0.50512 | Train Accs : 0.84753 | Valid Accs : 0.85823 | Time: 0.35 seconds\n",
            "Epoch: 780 | Train Loss: 0.50450 | Valid Loss: 0.50543 | Train Accs : 0.85168 | Valid Accs : 0.85233 | Time: 0.35 seconds\n",
            "Epoch: 781 | Train Loss: 0.50567 | Valid Loss: 0.50520 | Train Accs : 0.84808 | Valid Accs : 0.85438 | Time: 0.43 seconds\n",
            "Epoch: 782 | Train Loss: 0.50517 | Valid Loss: 0.50424 | Train Accs : 0.85089 | Valid Accs : 0.85737 | Time: 0.35 seconds\n",
            "Epoch: 783 | Train Loss: 0.50498 | Valid Loss: 0.50476 | Train Accs : 0.84668 | Valid Accs : 0.85767 | Time: 0.36 seconds\n",
            "Epoch: 784 | Train Loss: 0.50466 | Valid Loss: 0.50435 | Train Accs : 0.84875 | Valid Accs : 0.85415 | Time: 0.36 seconds\n",
            "Epoch: 785 | Train Loss: 0.50673 | Valid Loss: 0.50387 | Train Accs : 0.84900 | Valid Accs : 0.85676 | Time: 0.36 seconds\n",
            "Epoch: 786 | Train Loss: 0.50466 | Valid Loss: 0.50406 | Train Accs : 0.84839 | Valid Accs : 0.85725 | Time: 0.43 seconds\n",
            "Epoch: 787 | Train Loss: 0.50433 | Valid Loss: 0.50419 | Train Accs : 0.84961 | Valid Accs : 0.85669 | Time: 0.35 seconds\n",
            "Epoch: 788 | Train Loss: 0.50421 | Valid Loss: 0.50395 | Train Accs : 0.84930 | Valid Accs : 0.85938 | Time: 0.37 seconds\n",
            "Epoch: 789 | Train Loss: 0.50606 | Valid Loss: 0.50402 | Train Accs : 0.84790 | Valid Accs : 0.85530 | Time: 0.37 seconds\n",
            "Epoch: 790 | Train Loss: 0.50454 | Valid Loss: 0.50325 | Train Accs : 0.85052 | Valid Accs : 0.85834 | Time: 0.36 seconds\n",
            "Epoch: 791 | Train Loss: 0.50430 | Valid Loss: 0.50453 | Train Accs : 0.84882 | Valid Accs : 0.85502 | Time: 0.42 seconds\n",
            "Epoch: 792 | Train Loss: 0.50508 | Valid Loss: 0.50627 | Train Accs : 0.84778 | Valid Accs : 0.85275 | Time: 0.37 seconds\n",
            "Epoch: 793 | Train Loss: 0.50477 | Valid Loss: 0.50337 | Train Accs : 0.84772 | Valid Accs : 0.85712 | Time: 0.36 seconds\n",
            "Epoch: 794 | Train Loss: 0.50464 | Valid Loss: 0.50446 | Train Accs : 0.85052 | Valid Accs : 0.85573 | Time: 0.36 seconds\n",
            "Epoch: 795 | Train Loss: 0.50381 | Valid Loss: 0.50434 | Train Accs : 0.84821 | Valid Accs : 0.85622 | Time: 0.36 seconds\n",
            "Epoch: 796 | Train Loss: 0.50516 | Valid Loss: 0.50472 | Train Accs : 0.84991 | Valid Accs : 0.85712 | Time: 0.42 seconds\n",
            "Epoch: 797 | Train Loss: 0.50491 | Valid Loss: 0.50495 | Train Accs : 0.84717 | Valid Accs : 0.85701 | Time: 0.36 seconds\n",
            "Epoch: 798 | Train Loss: 0.50396 | Valid Loss: 0.50468 | Train Accs : 0.85059 | Valid Accs : 0.85395 | Time: 0.35 seconds\n",
            "Epoch: 799 | Train Loss: 0.50856 | Valid Loss: 0.50488 | Train Accs : 0.84686 | Valid Accs : 0.85263 | Time: 0.36 seconds\n",
            "Epoch: 800 | Train Loss: 0.50453 | Valid Loss: 0.50399 | Train Accs : 0.84979 | Valid Accs : 0.85560 | Time: 0.37 seconds\n",
            "Epoch: 801 | Train Loss: 0.50572 | Valid Loss: 0.50446 | Train Accs : 0.84875 | Valid Accs : 0.85806 | Time: 0.42 seconds\n",
            "Epoch: 802 | Train Loss: 0.50472 | Valid Loss: 0.50352 | Train Accs : 0.84918 | Valid Accs : 0.85690 | Time: 0.36 seconds\n",
            "Epoch: 803 | Train Loss: 0.50396 | Valid Loss: 0.50428 | Train Accs : 0.85126 | Valid Accs : 0.85676 | Time: 0.36 seconds\n",
            "Epoch: 804 | Train Loss: 0.50498 | Valid Loss: 0.50464 | Train Accs : 0.84869 | Valid Accs : 0.85682 | Time: 0.36 seconds\n",
            "Epoch: 805 | Train Loss: 0.50606 | Valid Loss: 0.50582 | Train Accs : 0.84906 | Valid Accs : 0.85331 | Time: 0.37 seconds\n",
            "Epoch: 806 | Train Loss: 0.50437 | Valid Loss: 0.50440 | Train Accs : 0.84930 | Valid Accs : 0.85889 | Time: 0.42 seconds\n",
            "Epoch: 807 | Train Loss: 0.50564 | Valid Loss: 0.50555 | Train Accs : 0.85028 | Valid Accs : 0.85271 | Time: 0.35 seconds\n",
            "Epoch: 808 | Train Loss: 0.50394 | Valid Loss: 0.50458 | Train Accs : 0.85089 | Valid Accs : 0.85513 | Time: 0.36 seconds\n",
            "Epoch: 809 | Train Loss: 0.50519 | Valid Loss: 0.50461 | Train Accs : 0.84949 | Valid Accs : 0.85676 | Time: 0.35 seconds\n",
            "Epoch: 810 | Train Loss: 0.50515 | Valid Loss: 0.50387 | Train Accs : 0.84827 | Valid Accs : 0.85676 | Time: 0.35 seconds\n",
            "Epoch: 811 | Train Loss: 0.50555 | Valid Loss: 0.50528 | Train Accs : 0.85052 | Valid Accs : 0.85476 | Time: 0.43 seconds\n",
            "Epoch: 812 | Train Loss: 0.50451 | Valid Loss: 0.50394 | Train Accs : 0.84894 | Valid Accs : 0.85652 | Time: 0.36 seconds\n",
            "Epoch: 813 | Train Loss: 0.50361 | Valid Loss: 0.50578 | Train Accs : 0.85059 | Valid Accs : 0.85639 | Time: 0.35 seconds\n",
            "Epoch: 814 | Train Loss: 0.50402 | Valid Loss: 0.50421 | Train Accs : 0.85089 | Valid Accs : 0.85500 | Time: 0.36 seconds\n",
            "Epoch: 815 | Train Loss: 0.50525 | Valid Loss: 0.50439 | Train Accs : 0.84943 | Valid Accs : 0.85658 | Time: 0.36 seconds\n",
            "Epoch: 816 | Train Loss: 0.50485 | Valid Loss: 0.50412 | Train Accs : 0.85095 | Valid Accs : 0.85641 | Time: 0.44 seconds\n",
            "Epoch: 817 | Train Loss: 0.50417 | Valid Loss: 0.50437 | Train Accs : 0.85077 | Valid Accs : 0.85598 | Time: 0.36 seconds\n",
            "Epoch: 818 | Train Loss: 0.50554 | Valid Loss: 0.50272 | Train Accs : 0.85034 | Valid Accs : 0.85791 | Time: 0.36 seconds\n",
            "Epoch: 819 | Train Loss: 0.50439 | Valid Loss: 0.50271 | Train Accs : 0.84821 | Valid Accs : 0.85951 | Time: 0.36 seconds\n",
            "Epoch: 820 | Train Loss: 0.50776 | Valid Loss: 0.50302 | Train Accs : 0.84888 | Valid Accs : 0.85891 | Time: 0.35 seconds\n",
            "Epoch: 821 | Train Loss: 0.50508 | Valid Loss: 0.50502 | Train Accs : 0.85101 | Valid Accs : 0.85477 | Time: 0.42 seconds\n",
            "Epoch: 822 | Train Loss: 0.50733 | Valid Loss: 0.50490 | Train Accs : 0.84894 | Valid Accs : 0.85459 | Time: 0.36 seconds\n",
            "Epoch: 823 | Train Loss: 0.50565 | Valid Loss: 0.50440 | Train Accs : 0.84906 | Valid Accs : 0.85609 | Time: 0.35 seconds\n",
            "Epoch: 824 | Train Loss: 0.50471 | Valid Loss: 0.50404 | Train Accs : 0.84930 | Valid Accs : 0.85821 | Time: 0.36 seconds\n",
            "Epoch: 825 | Train Loss: 0.50427 | Valid Loss: 0.50445 | Train Accs : 0.85077 | Valid Accs : 0.85654 | Time: 0.36 seconds\n",
            "Epoch: 826 | Train Loss: 0.50448 | Valid Loss: 0.50421 | Train Accs : 0.84955 | Valid Accs : 0.85389 | Time: 0.43 seconds\n",
            "Epoch: 827 | Train Loss: 0.50486 | Valid Loss: 0.50488 | Train Accs : 0.85095 | Valid Accs : 0.85337 | Time: 0.36 seconds\n",
            "Epoch: 828 | Train Loss: 0.50526 | Valid Loss: 0.50495 | Train Accs : 0.85114 | Valid Accs : 0.85566 | Time: 0.36 seconds\n",
            "Epoch: 829 | Train Loss: 0.50386 | Valid Loss: 0.50345 | Train Accs : 0.84845 | Valid Accs : 0.85785 | Time: 0.35 seconds\n",
            "Epoch: 830 | Train Loss: 0.50411 | Valid Loss: 0.50502 | Train Accs : 0.84991 | Valid Accs : 0.85391 | Time: 0.36 seconds\n",
            "Epoch: 831 | Train Loss: 0.50837 | Valid Loss: 0.50457 | Train Accs : 0.84875 | Valid Accs : 0.85568 | Time: 0.42 seconds\n",
            "Epoch: 832 | Train Loss: 0.50580 | Valid Loss: 0.50478 | Train Accs : 0.84943 | Valid Accs : 0.85646 | Time: 0.36 seconds\n",
            "Epoch: 833 | Train Loss: 0.50594 | Valid Loss: 0.50505 | Train Accs : 0.84607 | Valid Accs : 0.85622 | Time: 0.36 seconds\n",
            "Epoch: 834 | Train Loss: 0.50623 | Valid Loss: 0.50348 | Train Accs : 0.84985 | Valid Accs : 0.85872 | Time: 0.36 seconds\n",
            "Epoch: 835 | Train Loss: 0.50467 | Valid Loss: 0.50502 | Train Accs : 0.84967 | Valid Accs : 0.85408 | Time: 0.36 seconds\n",
            "Epoch: 836 | Train Loss: 0.50609 | Valid Loss: 0.50635 | Train Accs : 0.84784 | Valid Accs : 0.85470 | Time: 0.42 seconds\n",
            "Epoch: 837 | Train Loss: 0.50630 | Valid Loss: 0.50450 | Train Accs : 0.85010 | Valid Accs : 0.85429 | Time: 0.36 seconds\n",
            "Epoch: 838 | Train Loss: 0.50469 | Valid Loss: 0.50487 | Train Accs : 0.84802 | Valid Accs : 0.85633 | Time: 0.37 seconds\n",
            "Epoch: 839 | Train Loss: 0.50551 | Valid Loss: 0.50542 | Train Accs : 0.84760 | Valid Accs : 0.85507 | Time: 0.37 seconds\n",
            "Epoch: 840 | Train Loss: 0.50687 | Valid Loss: 0.50602 | Train Accs : 0.85052 | Valid Accs : 0.85136 | Time: 0.36 seconds\n",
            "Epoch: 841 | Train Loss: 0.50364 | Valid Loss: 0.50461 | Train Accs : 0.85107 | Valid Accs : 0.85603 | Time: 0.43 seconds\n",
            "Epoch: 842 | Train Loss: 0.50430 | Valid Loss: 0.50469 | Train Accs : 0.85022 | Valid Accs : 0.85549 | Time: 0.36 seconds\n",
            "Epoch: 843 | Train Loss: 0.50599 | Valid Loss: 0.50376 | Train Accs : 0.84912 | Valid Accs : 0.85566 | Time: 0.36 seconds\n",
            "Epoch: 844 | Train Loss: 0.50452 | Valid Loss: 0.50443 | Train Accs : 0.84888 | Valid Accs : 0.85614 | Time: 0.36 seconds\n",
            "Epoch: 845 | Train Loss: 0.50610 | Valid Loss: 0.50451 | Train Accs : 0.84760 | Valid Accs : 0.85402 | Time: 0.37 seconds\n",
            "Epoch: 846 | Train Loss: 0.50587 | Valid Loss: 0.50557 | Train Accs : 0.84882 | Valid Accs : 0.85239 | Time: 0.42 seconds\n",
            "Epoch: 847 | Train Loss: 0.50457 | Valid Loss: 0.50402 | Train Accs : 0.84985 | Valid Accs : 0.85635 | Time: 0.36 seconds\n",
            "Epoch: 848 | Train Loss: 0.50520 | Valid Loss: 0.50538 | Train Accs : 0.84827 | Valid Accs : 0.85470 | Time: 0.36 seconds\n",
            "Epoch: 849 | Train Loss: 0.50658 | Valid Loss: 0.50295 | Train Accs : 0.85065 | Valid Accs : 0.85723 | Time: 0.36 seconds\n",
            "Epoch: 850 | Train Loss: 0.50493 | Valid Loss: 0.50456 | Train Accs : 0.85156 | Valid Accs : 0.85690 | Time: 0.36 seconds\n",
            "Epoch: 851 | Train Loss: 0.50678 | Valid Loss: 0.50423 | Train Accs : 0.85138 | Valid Accs : 0.85543 | Time: 0.42 seconds\n",
            "Epoch: 852 | Train Loss: 0.50604 | Valid Loss: 0.50438 | Train Accs : 0.84741 | Valid Accs : 0.85457 | Time: 0.37 seconds\n",
            "Epoch: 853 | Train Loss: 0.50493 | Valid Loss: 0.50435 | Train Accs : 0.84735 | Valid Accs : 0.85682 | Time: 0.37 seconds\n",
            "Epoch: 854 | Train Loss: 0.50560 | Valid Loss: 0.50456 | Train Accs : 0.84918 | Valid Accs : 0.85829 | Time: 0.36 seconds\n",
            "Epoch: 855 | Train Loss: 0.50485 | Valid Loss: 0.50369 | Train Accs : 0.84796 | Valid Accs : 0.85797 | Time: 0.36 seconds\n",
            "Epoch: 856 | Train Loss: 0.50432 | Valid Loss: 0.50349 | Train Accs : 0.85211 | Valid Accs : 0.85549 | Time: 0.42 seconds\n",
            "Epoch: 857 | Train Loss: 0.50574 | Valid Loss: 0.50610 | Train Accs : 0.84851 | Valid Accs : 0.85554 | Time: 0.36 seconds\n",
            "Epoch: 858 | Train Loss: 0.50493 | Valid Loss: 0.50461 | Train Accs : 0.85016 | Valid Accs : 0.85725 | Time: 0.36 seconds\n",
            "Epoch: 859 | Train Loss: 0.50592 | Valid Loss: 0.50542 | Train Accs : 0.84863 | Valid Accs : 0.85731 | Time: 0.36 seconds\n",
            "Epoch: 860 | Train Loss: 0.50498 | Valid Loss: 0.50496 | Train Accs : 0.85095 | Valid Accs : 0.85568 | Time: 0.36 seconds\n",
            "Epoch: 861 | Train Loss: 0.50505 | Valid Loss: 0.50475 | Train Accs : 0.84509 | Valid Accs : 0.85784 | Time: 0.44 seconds\n",
            "Epoch: 862 | Train Loss: 0.50713 | Valid Loss: 0.50577 | Train Accs : 0.84875 | Valid Accs : 0.85429 | Time: 0.38 seconds\n",
            "Epoch: 863 | Train Loss: 0.50530 | Valid Loss: 0.50534 | Train Accs : 0.84967 | Valid Accs : 0.85445 | Time: 0.36 seconds\n",
            "Epoch: 864 | Train Loss: 0.50473 | Valid Loss: 0.50577 | Train Accs : 0.85004 | Valid Accs : 0.85671 | Time: 0.37 seconds\n",
            "Epoch: 865 | Train Loss: 0.50562 | Valid Loss: 0.50518 | Train Accs : 0.84973 | Valid Accs : 0.85646 | Time: 0.38 seconds\n",
            "Epoch: 866 | Train Loss: 0.50574 | Valid Loss: 0.50540 | Train Accs : 0.84583 | Valid Accs : 0.85554 | Time: 0.42 seconds\n",
            "Epoch: 867 | Train Loss: 0.50574 | Valid Loss: 0.50481 | Train Accs : 0.84711 | Valid Accs : 0.85451 | Time: 0.36 seconds\n",
            "Epoch: 868 | Train Loss: 0.50476 | Valid Loss: 0.50538 | Train Accs : 0.85016 | Valid Accs : 0.85487 | Time: 0.36 seconds\n",
            "Epoch: 869 | Train Loss: 0.50460 | Valid Loss: 0.50414 | Train Accs : 0.84851 | Valid Accs : 0.85675 | Time: 0.36 seconds\n",
            "Epoch: 870 | Train Loss: 0.50492 | Valid Loss: 0.50329 | Train Accs : 0.84973 | Valid Accs : 0.85834 | Time: 0.36 seconds\n",
            "Epoch: 871 | Train Loss: 0.50466 | Valid Loss: 0.50370 | Train Accs : 0.84937 | Valid Accs : 0.85840 | Time: 0.43 seconds\n",
            "Epoch: 872 | Train Loss: 0.50437 | Valid Loss: 0.50417 | Train Accs : 0.84888 | Valid Accs : 0.85945 | Time: 0.36 seconds\n",
            "Epoch: 873 | Train Loss: 0.50649 | Valid Loss: 0.50404 | Train Accs : 0.84888 | Valid Accs : 0.85609 | Time: 0.36 seconds\n",
            "Epoch: 874 | Train Loss: 0.50596 | Valid Loss: 0.50393 | Train Accs : 0.84717 | Valid Accs : 0.85579 | Time: 0.36 seconds\n",
            "Epoch: 875 | Train Loss: 0.50620 | Valid Loss: 0.50480 | Train Accs : 0.84943 | Valid Accs : 0.85701 | Time: 0.35 seconds\n",
            "Epoch: 876 | Train Loss: 0.50566 | Valid Loss: 0.50526 | Train Accs : 0.85254 | Valid Accs : 0.85269 | Time: 0.44 seconds\n",
            "Epoch: 877 | Train Loss: 0.50741 | Valid Loss: 0.50370 | Train Accs : 0.84784 | Valid Accs : 0.85840 | Time: 0.36 seconds\n",
            "Epoch: 878 | Train Loss: 0.50548 | Valid Loss: 0.50311 | Train Accs : 0.84924 | Valid Accs : 0.85489 | Time: 0.35 seconds\n",
            "Epoch: 879 | Train Loss: 0.50409 | Valid Loss: 0.50554 | Train Accs : 0.85083 | Valid Accs : 0.85633 | Time: 0.37 seconds\n",
            "Epoch: 880 | Train Loss: 0.50539 | Valid Loss: 0.50526 | Train Accs : 0.85150 | Valid Accs : 0.85440 | Time: 0.36 seconds\n",
            "Epoch: 881 | Train Loss: 0.50468 | Valid Loss: 0.50421 | Train Accs : 0.85168 | Valid Accs : 0.85494 | Time: 0.42 seconds\n",
            "Epoch: 882 | Train Loss: 0.50370 | Valid Loss: 0.50407 | Train Accs : 0.85107 | Valid Accs : 0.85628 | Time: 0.36 seconds\n",
            "Epoch: 883 | Train Loss: 0.50413 | Valid Loss: 0.50475 | Train Accs : 0.85193 | Valid Accs : 0.85496 | Time: 0.36 seconds\n",
            "Epoch: 884 | Train Loss: 0.50535 | Valid Loss: 0.50430 | Train Accs : 0.84692 | Valid Accs : 0.85658 | Time: 0.36 seconds\n",
            "Epoch: 885 | Train Loss: 0.50530 | Valid Loss: 0.50498 | Train Accs : 0.84918 | Valid Accs : 0.85614 | Time: 0.36 seconds\n",
            "Epoch: 886 | Train Loss: 0.50577 | Valid Loss: 0.50484 | Train Accs : 0.84924 | Valid Accs : 0.85614 | Time: 0.41 seconds\n",
            "Epoch: 887 | Train Loss: 0.50831 | Valid Loss: 0.50426 | Train Accs : 0.84735 | Valid Accs : 0.85459 | Time: 0.36 seconds\n",
            "Epoch: 888 | Train Loss: 0.50434 | Valid Loss: 0.50335 | Train Accs : 0.85071 | Valid Accs : 0.85635 | Time: 0.35 seconds\n",
            "Epoch: 889 | Train Loss: 0.50562 | Valid Loss: 0.50401 | Train Accs : 0.84717 | Valid Accs : 0.85778 | Time: 0.36 seconds\n",
            "Epoch: 890 | Train Loss: 0.50658 | Valid Loss: 0.50351 | Train Accs : 0.85120 | Valid Accs : 0.85744 | Time: 0.36 seconds\n",
            "Epoch: 891 | Train Loss: 0.50517 | Valid Loss: 0.50478 | Train Accs : 0.85162 | Valid Accs : 0.85562 | Time: 0.42 seconds\n",
            "Epoch: 892 | Train Loss: 0.50509 | Valid Loss: 0.50401 | Train Accs : 0.85077 | Valid Accs : 0.85402 | Time: 0.37 seconds\n",
            "Epoch: 893 | Train Loss: 0.50759 | Valid Loss: 0.50448 | Train Accs : 0.84894 | Valid Accs : 0.85537 | Time: 0.35 seconds\n",
            "Epoch: 894 | Train Loss: 0.50687 | Valid Loss: 0.50430 | Train Accs : 0.85089 | Valid Accs : 0.85806 | Time: 0.35 seconds\n",
            "Epoch: 895 | Train Loss: 0.50417 | Valid Loss: 0.50374 | Train Accs : 0.85089 | Valid Accs : 0.85714 | Time: 0.37 seconds\n",
            "Epoch: 896 | Train Loss: 0.50639 | Valid Loss: 0.50522 | Train Accs : 0.84979 | Valid Accs : 0.85421 | Time: 0.43 seconds\n",
            "Epoch: 897 | Train Loss: 0.50432 | Valid Loss: 0.50572 | Train Accs : 0.85065 | Valid Accs : 0.85599 | Time: 0.36 seconds\n",
            "Epoch: 898 | Train Loss: 0.50441 | Valid Loss: 0.50434 | Train Accs : 0.85107 | Valid Accs : 0.85782 | Time: 0.36 seconds\n",
            "Epoch: 899 | Train Loss: 0.50370 | Valid Loss: 0.50363 | Train Accs : 0.84967 | Valid Accs : 0.85748 | Time: 0.35 seconds\n",
            "Epoch: 900 | Train Loss: 0.50434 | Valid Loss: 0.50535 | Train Accs : 0.85327 | Valid Accs : 0.85325 | Time: 0.36 seconds\n",
            "Epoch: 901 | Train Loss: 0.50578 | Valid Loss: 0.50342 | Train Accs : 0.84753 | Valid Accs : 0.85712 | Time: 0.42 seconds\n",
            "Epoch: 902 | Train Loss: 0.50587 | Valid Loss: 0.50422 | Train Accs : 0.84875 | Valid Accs : 0.85427 | Time: 0.37 seconds\n",
            "Epoch: 903 | Train Loss: 0.50609 | Valid Loss: 0.50425 | Train Accs : 0.84949 | Valid Accs : 0.85676 | Time: 0.36 seconds\n",
            "Epoch: 904 | Train Loss: 0.50398 | Valid Loss: 0.50477 | Train Accs : 0.85193 | Valid Accs : 0.85367 | Time: 0.37 seconds\n",
            "Epoch: 905 | Train Loss: 0.50494 | Valid Loss: 0.50382 | Train Accs : 0.85254 | Valid Accs : 0.85537 | Time: 0.35 seconds\n",
            "Epoch: 906 | Train Loss: 0.50509 | Valid Loss: 0.50325 | Train Accs : 0.84906 | Valid Accs : 0.85981 | Time: 0.43 seconds\n",
            "Epoch: 907 | Train Loss: 0.50713 | Valid Loss: 0.50442 | Train Accs : 0.84930 | Valid Accs : 0.85635 | Time: 0.37 seconds\n",
            "Epoch: 908 | Train Loss: 0.50436 | Valid Loss: 0.50348 | Train Accs : 0.85114 | Valid Accs : 0.85774 | Time: 0.36 seconds\n",
            "Epoch: 909 | Train Loss: 0.50594 | Valid Loss: 0.50373 | Train Accs : 0.84717 | Valid Accs : 0.85579 | Time: 0.37 seconds\n",
            "Epoch: 910 | Train Loss: 0.50625 | Valid Loss: 0.50280 | Train Accs : 0.84833 | Valid Accs : 0.85870 | Time: 0.36 seconds\n",
            "Epoch: 911 | Train Loss: 0.50423 | Valid Loss: 0.50342 | Train Accs : 0.85309 | Valid Accs : 0.85720 | Time: 0.44 seconds\n",
            "Epoch: 912 | Train Loss: 0.50675 | Valid Loss: 0.50377 | Train Accs : 0.84979 | Valid Accs : 0.85703 | Time: 0.37 seconds\n",
            "Epoch: 913 | Train Loss: 0.50628 | Valid Loss: 0.50458 | Train Accs : 0.84576 | Valid Accs : 0.85410 | Time: 0.36 seconds\n",
            "Epoch: 914 | Train Loss: 0.50566 | Valid Loss: 0.50364 | Train Accs : 0.84637 | Valid Accs : 0.85712 | Time: 0.36 seconds\n",
            "Epoch: 915 | Train Loss: 0.50457 | Valid Loss: 0.50324 | Train Accs : 0.84814 | Valid Accs : 0.85573 | Time: 0.36 seconds\n",
            "Epoch: 916 | Train Loss: 0.50304 | Valid Loss: 0.50512 | Train Accs : 0.85077 | Valid Accs : 0.85590 | Time: 0.42 seconds\n",
            "Epoch: 917 | Train Loss: 0.50504 | Valid Loss: 0.50489 | Train Accs : 0.84729 | Valid Accs : 0.85870 | Time: 0.36 seconds\n",
            "Epoch: 918 | Train Loss: 0.50532 | Valid Loss: 0.50458 | Train Accs : 0.84961 | Valid Accs : 0.85682 | Time: 0.36 seconds\n",
            "Epoch: 919 | Train Loss: 0.50443 | Valid Loss: 0.50423 | Train Accs : 0.84912 | Valid Accs : 0.85881 | Time: 0.36 seconds\n",
            "Epoch: 920 | Train Loss: 0.50415 | Valid Loss: 0.50442 | Train Accs : 0.85126 | Valid Accs : 0.85913 | Time: 0.37 seconds\n",
            "Epoch: 921 | Train Loss: 0.50465 | Valid Loss: 0.50273 | Train Accs : 0.85120 | Valid Accs : 0.85780 | Time: 0.42 seconds\n",
            "Epoch: 922 | Train Loss: 0.50613 | Valid Loss: 0.50431 | Train Accs : 0.84723 | Valid Accs : 0.85652 | Time: 0.37 seconds\n",
            "Epoch: 923 | Train Loss: 0.50610 | Valid Loss: 0.50430 | Train Accs : 0.84985 | Valid Accs : 0.85427 | Time: 0.37 seconds\n",
            "Epoch: 924 | Train Loss: 0.50603 | Valid Loss: 0.50430 | Train Accs : 0.84796 | Valid Accs : 0.85688 | Time: 0.35 seconds\n",
            "Epoch: 925 | Train Loss: 0.50521 | Valid Loss: 0.50337 | Train Accs : 0.84961 | Valid Accs : 0.85750 | Time: 0.36 seconds\n",
            "Epoch: 926 | Train Loss: 0.50574 | Valid Loss: 0.50463 | Train Accs : 0.84790 | Valid Accs : 0.85652 | Time: 0.43 seconds\n",
            "Epoch: 927 | Train Loss: 0.50468 | Valid Loss: 0.50514 | Train Accs : 0.84796 | Valid Accs : 0.85372 | Time: 0.36 seconds\n",
            "Epoch: 928 | Train Loss: 0.50729 | Valid Loss: 0.50504 | Train Accs : 0.85144 | Valid Accs : 0.85776 | Time: 0.37 seconds\n",
            "Epoch: 929 | Train Loss: 0.50430 | Valid Loss: 0.50390 | Train Accs : 0.84955 | Valid Accs : 0.85519 | Time: 0.36 seconds\n",
            "Epoch: 930 | Train Loss: 0.50538 | Valid Loss: 0.50496 | Train Accs : 0.84467 | Valid Accs : 0.85601 | Time: 0.37 seconds\n",
            "Epoch: 931 | Train Loss: 0.50369 | Valid Loss: 0.50358 | Train Accs : 0.85083 | Valid Accs : 0.85744 | Time: 0.42 seconds\n",
            "Epoch: 932 | Train Loss: 0.50619 | Valid Loss: 0.50467 | Train Accs : 0.84625 | Valid Accs : 0.85626 | Time: 0.37 seconds\n",
            "Epoch: 933 | Train Loss: 0.50427 | Valid Loss: 0.50434 | Train Accs : 0.85004 | Valid Accs : 0.85665 | Time: 0.38 seconds\n",
            "Epoch: 934 | Train Loss: 0.50456 | Valid Loss: 0.50458 | Train Accs : 0.84894 | Valid Accs : 0.85669 | Time: 0.37 seconds\n",
            "Epoch: 935 | Train Loss: 0.50424 | Valid Loss: 0.50318 | Train Accs : 0.84991 | Valid Accs : 0.85737 | Time: 0.35 seconds\n",
            "Epoch: 936 | Train Loss: 0.50416 | Valid Loss: 0.50409 | Train Accs : 0.85034 | Valid Accs : 0.85645 | Time: 0.43 seconds\n",
            "Epoch: 937 | Train Loss: 0.50386 | Valid Loss: 0.50507 | Train Accs : 0.85028 | Valid Accs : 0.85432 | Time: 0.36 seconds\n",
            "Epoch: 938 | Train Loss: 0.50511 | Valid Loss: 0.50608 | Train Accs : 0.84900 | Valid Accs : 0.85184 | Time: 0.38 seconds\n",
            "Epoch: 939 | Train Loss: 0.50375 | Valid Loss: 0.50379 | Train Accs : 0.85242 | Valid Accs : 0.85641 | Time: 0.36 seconds\n",
            "Epoch: 940 | Train Loss: 0.50540 | Valid Loss: 0.50451 | Train Accs : 0.85052 | Valid Accs : 0.85502 | Time: 0.35 seconds\n",
            "Epoch: 941 | Train Loss: 0.50449 | Valid Loss: 0.50577 | Train Accs : 0.84991 | Valid Accs : 0.85445 | Time: 0.43 seconds\n",
            "Epoch: 942 | Train Loss: 0.50358 | Valid Loss: 0.50404 | Train Accs : 0.85211 | Valid Accs : 0.85573 | Time: 0.36 seconds\n",
            "Epoch: 943 | Train Loss: 0.50600 | Valid Loss: 0.50453 | Train Accs : 0.84985 | Valid Accs : 0.85519 | Time: 0.36 seconds\n",
            "Epoch: 944 | Train Loss: 0.50471 | Valid Loss: 0.50355 | Train Accs : 0.84784 | Valid Accs : 0.85883 | Time: 0.36 seconds\n",
            "Epoch: 945 | Train Loss: 0.50555 | Valid Loss: 0.50509 | Train Accs : 0.85052 | Valid Accs : 0.85459 | Time: 0.36 seconds\n",
            "Epoch: 946 | Train Loss: 0.50408 | Valid Loss: 0.50322 | Train Accs : 0.85016 | Valid Accs : 0.85780 | Time: 0.43 seconds\n",
            "Epoch: 947 | Train Loss: 0.50366 | Valid Loss: 0.50532 | Train Accs : 0.85217 | Valid Accs : 0.85318 | Time: 0.36 seconds\n",
            "Epoch: 948 | Train Loss: 0.50528 | Valid Loss: 0.50377 | Train Accs : 0.84918 | Valid Accs : 0.85658 | Time: 0.35 seconds\n",
            "Epoch: 949 | Train Loss: 0.50385 | Valid Loss: 0.50480 | Train Accs : 0.85132 | Valid Accs : 0.85725 | Time: 0.38 seconds\n",
            "Epoch: 950 | Train Loss: 0.50459 | Valid Loss: 0.50485 | Train Accs : 0.85052 | Valid Accs : 0.85481 | Time: 0.38 seconds\n",
            "Epoch: 951 | Train Loss: 0.50605 | Valid Loss: 0.50468 | Train Accs : 0.84796 | Valid Accs : 0.85568 | Time: 0.43 seconds\n",
            "Epoch: 952 | Train Loss: 0.50521 | Valid Loss: 0.50402 | Train Accs : 0.85022 | Valid Accs : 0.85780 | Time: 0.36 seconds\n",
            "Epoch: 953 | Train Loss: 0.50628 | Valid Loss: 0.50631 | Train Accs : 0.84595 | Valid Accs : 0.85273 | Time: 0.35 seconds\n",
            "Epoch: 954 | Train Loss: 0.50605 | Valid Loss: 0.50450 | Train Accs : 0.84888 | Valid Accs : 0.85560 | Time: 0.37 seconds\n",
            "Epoch: 955 | Train Loss: 0.50612 | Valid Loss: 0.50346 | Train Accs : 0.84766 | Valid Accs : 0.85767 | Time: 0.36 seconds\n",
            "Epoch: 956 | Train Loss: 0.50650 | Valid Loss: 0.50356 | Train Accs : 0.85010 | Valid Accs : 0.85579 | Time: 0.42 seconds\n",
            "Epoch: 957 | Train Loss: 0.50489 | Valid Loss: 0.50405 | Train Accs : 0.84589 | Valid Accs : 0.85639 | Time: 0.37 seconds\n",
            "Epoch: 958 | Train Loss: 0.50626 | Valid Loss: 0.50402 | Train Accs : 0.85095 | Valid Accs : 0.85635 | Time: 0.36 seconds\n",
            "Epoch: 959 | Train Loss: 0.50703 | Valid Loss: 0.50423 | Train Accs : 0.85016 | Valid Accs : 0.85487 | Time: 0.36 seconds\n",
            "Epoch: 960 | Train Loss: 0.50432 | Valid Loss: 0.50314 | Train Accs : 0.84979 | Valid Accs : 0.85688 | Time: 0.36 seconds\n",
            "Epoch: 961 | Train Loss: 0.50530 | Valid Loss: 0.50326 | Train Accs : 0.84863 | Valid Accs : 0.85566 | Time: 0.42 seconds\n",
            "Epoch: 962 | Train Loss: 0.50487 | Valid Loss: 0.50339 | Train Accs : 0.85077 | Valid Accs : 0.85404 | Time: 0.36 seconds\n",
            "Epoch: 963 | Train Loss: 0.50546 | Valid Loss: 0.50413 | Train Accs : 0.85022 | Valid Accs : 0.85536 | Time: 0.35 seconds\n",
            "Epoch: 964 | Train Loss: 0.50569 | Valid Loss: 0.50378 | Train Accs : 0.84955 | Valid Accs : 0.85532 | Time: 0.35 seconds\n",
            "Epoch: 965 | Train Loss: 0.50649 | Valid Loss: 0.50356 | Train Accs : 0.84918 | Valid Accs : 0.85707 | Time: 0.37 seconds\n",
            "Epoch: 966 | Train Loss: 0.50390 | Valid Loss: 0.50407 | Train Accs : 0.85034 | Valid Accs : 0.85592 | Time: 0.41 seconds\n",
            "Epoch: 967 | Train Loss: 0.50341 | Valid Loss: 0.50358 | Train Accs : 0.85382 | Valid Accs : 0.85586 | Time: 0.36 seconds\n",
            "Epoch: 968 | Train Loss: 0.50396 | Valid Loss: 0.50448 | Train Accs : 0.85126 | Valid Accs : 0.85537 | Time: 0.36 seconds\n",
            "Epoch: 969 | Train Loss: 0.50391 | Valid Loss: 0.50346 | Train Accs : 0.85016 | Valid Accs : 0.85737 | Time: 0.36 seconds\n",
            "Epoch: 970 | Train Loss: 0.50283 | Valid Loss: 0.50502 | Train Accs : 0.85095 | Valid Accs : 0.85599 | Time: 0.36 seconds\n",
            "Epoch: 971 | Train Loss: 0.50670 | Valid Loss: 0.50355 | Train Accs : 0.84674 | Valid Accs : 0.85785 | Time: 0.42 seconds\n",
            "Epoch: 972 | Train Loss: 0.50540 | Valid Loss: 0.50384 | Train Accs : 0.85168 | Valid Accs : 0.85404 | Time: 0.35 seconds\n",
            "Epoch: 973 | Train Loss: 0.50465 | Valid Loss: 0.50435 | Train Accs : 0.85077 | Valid Accs : 0.85537 | Time: 0.36 seconds\n",
            "Epoch: 974 | Train Loss: 0.50347 | Valid Loss: 0.50495 | Train Accs : 0.85162 | Valid Accs : 0.85410 | Time: 0.36 seconds\n",
            "Epoch: 975 | Train Loss: 0.50433 | Valid Loss: 0.50423 | Train Accs : 0.84930 | Valid Accs : 0.85693 | Time: 0.35 seconds\n",
            "Epoch: 976 | Train Loss: 0.50386 | Valid Loss: 0.50425 | Train Accs : 0.84973 | Valid Accs : 0.85660 | Time: 0.43 seconds\n",
            "Epoch: 977 | Train Loss: 0.50492 | Valid Loss: 0.50557 | Train Accs : 0.84961 | Valid Accs : 0.85380 | Time: 0.35 seconds\n",
            "Epoch: 978 | Train Loss: 0.50607 | Valid Loss: 0.50349 | Train Accs : 0.84760 | Valid Accs : 0.85853 | Time: 0.36 seconds\n",
            "Epoch: 979 | Train Loss: 0.50404 | Valid Loss: 0.50521 | Train Accs : 0.85028 | Valid Accs : 0.85584 | Time: 0.37 seconds\n",
            "Epoch: 980 | Train Loss: 0.50512 | Valid Loss: 0.50524 | Train Accs : 0.85168 | Valid Accs : 0.85633 | Time: 0.36 seconds\n",
            "Epoch: 981 | Train Loss: 0.50425 | Valid Loss: 0.50669 | Train Accs : 0.85083 | Valid Accs : 0.85293 | Time: 0.42 seconds\n",
            "Epoch: 982 | Train Loss: 0.50578 | Valid Loss: 0.50340 | Train Accs : 0.84760 | Valid Accs : 0.85889 | Time: 0.36 seconds\n",
            "Epoch: 983 | Train Loss: 0.50509 | Valid Loss: 0.50481 | Train Accs : 0.84894 | Valid Accs : 0.85312 | Time: 0.36 seconds\n",
            "Epoch: 984 | Train Loss: 0.50634 | Valid Loss: 0.50500 | Train Accs : 0.85016 | Valid Accs : 0.85470 | Time: 0.36 seconds\n",
            "Epoch: 985 | Train Loss: 0.50592 | Valid Loss: 0.50533 | Train Accs : 0.84918 | Valid Accs : 0.85622 | Time: 0.35 seconds\n",
            "Epoch: 986 | Train Loss: 0.50456 | Valid Loss: 0.50398 | Train Accs : 0.84778 | Valid Accs : 0.85894 | Time: 0.45 seconds\n",
            "Epoch: 987 | Train Loss: 0.50478 | Valid Loss: 0.50556 | Train Accs : 0.85260 | Valid Accs : 0.85312 | Time: 0.38 seconds\n",
            "Epoch: 988 | Train Loss: 0.50452 | Valid Loss: 0.50418 | Train Accs : 0.84924 | Valid Accs : 0.85821 | Time: 0.36 seconds\n",
            "Epoch: 989 | Train Loss: 0.50541 | Valid Loss: 0.50433 | Train Accs : 0.84735 | Valid Accs : 0.85639 | Time: 0.36 seconds\n",
            "Epoch: 990 | Train Loss: 0.50451 | Valid Loss: 0.50434 | Train Accs : 0.85059 | Valid Accs : 0.85476 | Time: 0.36 seconds\n",
            "Epoch: 991 | Train Loss: 0.50460 | Valid Loss: 0.50399 | Train Accs : 0.84784 | Valid Accs : 0.85682 | Time: 0.42 seconds\n",
            "Epoch: 992 | Train Loss: 0.50856 | Valid Loss: 0.50482 | Train Accs : 0.84979 | Valid Accs : 0.85306 | Time: 0.37 seconds\n",
            "Epoch: 993 | Train Loss: 0.50548 | Valid Loss: 0.50386 | Train Accs : 0.85217 | Valid Accs : 0.85676 | Time: 0.36 seconds\n",
            "Epoch: 994 | Train Loss: 0.50411 | Valid Loss: 0.50472 | Train Accs : 0.85156 | Valid Accs : 0.85449 | Time: 0.36 seconds\n",
            "Epoch: 995 | Train Loss: 0.50311 | Valid Loss: 0.50504 | Train Accs : 0.85400 | Valid Accs : 0.85616 | Time: 0.36 seconds\n",
            "Epoch: 996 | Train Loss: 0.50466 | Valid Loss: 0.50476 | Train Accs : 0.84900 | Valid Accs : 0.85609 | Time: 0.42 seconds\n",
            "Epoch: 997 | Train Loss: 0.50572 | Valid Loss: 0.50512 | Train Accs : 0.84961 | Valid Accs : 0.85641 | Time: 0.36 seconds\n",
            "Epoch: 998 | Train Loss: 0.50579 | Valid Loss: 0.50365 | Train Accs : 0.84979 | Valid Accs : 0.85676 | Time: 0.36 seconds\n",
            "Epoch: 999 | Train Loss: 0.50477 | Valid Loss: 0.50391 | Train Accs : 0.85065 | Valid Accs : 0.85720 | Time: 0.36 seconds\n",
            "Epoch: 1000 | Train Loss: 0.50567 | Valid Loss: 0.50327 | Train Accs : 0.84930 | Valid Accs : 0.85701 | Time: 0.35 seconds\n",
            "\u001b[31m\n",
            "**************************************************\n",
            "\u001b[0m\n",
            "Best Validation Loss at Epoch ---> 638\n",
            "\u001b[31m\n",
            "**************************************************\n",
            "\u001b[0m\n",
            "Best Validation Accs at Epoch ---> 640\n",
            "\u001b[31m\n",
            "**************************************************\n",
            "\u001b[0m\n",
            "Time Taken [1000 Epochs] : 6.20 minutes\n",
            "\u001b[31m\n",
            "**************************************************\n",
            "\u001b[0m\n",
            "Training Completed\n",
            "\u001b[31m\n",
            "**************************************************\n",
            "\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWUHEOq8cYLZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}