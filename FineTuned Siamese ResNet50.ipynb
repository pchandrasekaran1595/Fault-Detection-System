{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FineTuned Siamese ResNet50",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMgiSNrJ8pWX4Nc5y5BHKuR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/123prashanth123/Fault-Detection-System/blob/Colabs/FineTuned%20Siamese%20ResNet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJSrzPNwYaho"
      },
      "source": [
        "# Notebook Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bExQQQGFXQto"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "\n",
        "!pip install --upgrade imgaug\n",
        "!pip install imagecorruptions\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRlcKrUbYcFY"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOgKGLRlYehv"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torchvision import models, transforms, ops\n",
        "from torch.utils.data import DataLoader as DL\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import imgaug\n",
        "from imgaug import augmenters\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "import os\n",
        "import re\n",
        "import cv2\n",
        "import random as r\n",
        "from time import time\n",
        "from termcolor import colored\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "seed = 0\n",
        "STANDARD_SIZE = 224\n",
        "DS_PATH = \"/content/gdrive/My Drive/Videos/\"\n",
        "\n",
        "\n",
        "def breaker(num=50, char=\"*\"):\n",
        "    print(colored(\"\\n\" + num*char + \"\\n\", color=\"yellow\"))\n",
        "\n",
        "\n",
        "def normalize(x=None):\n",
        "    for i in range(x.shape[0]):\n",
        "        x[i] = (x[i] - torch.min(x[i]))/(torch.max(x[i]) - torch.min(x[i]))\n",
        "    return x\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cIsXQhBY2za"
      },
      "source": [
        "# Build Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zx00d8cY0Z1"
      },
      "source": [
        "def build_roi_extractor():\n",
        "    breaker()\n",
        "    print(\"Building ROI Extractor ...\")\n",
        "\n",
        "    class RoIExtractor(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(RoIExtractor, self).__init__()\n",
        "            self.model = models.detection.fasterrcnn_mobilenet_v3_large_320_fpn(pretrained=True, progress=True)\n",
        "        \n",
        "        def forward(self, x):\n",
        "            return self.model(x)\n",
        "    \n",
        "    roi_extractor = RoIExtractor().to(device)\n",
        "    roi_extractor.eval()\n",
        "    roi_transform = transforms.Compose([transforms.ToTensor(),])\n",
        "    return roi_extractor, roi_transform\n",
        "\n",
        "\n",
        "def build_model():\n",
        "    breaker()\n",
        "    print(\"Building Model ...\")\n",
        "\n",
        "    class SiameseResNet(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(SiameseResNet, self).__init__()\n",
        "            model = models.resnet50(pretrained=True, progress=True)\n",
        "            in_f = model.fc.in_features\n",
        "\n",
        "            for params in model.parameters():\n",
        "                params.requires_grad = False\n",
        "\n",
        "            for names, params in model.named_parameters():\n",
        "                if re.match(r\"layer4.2\", names, re.IGNORECASE):\n",
        "                    params.requires_grad = True\n",
        "                \n",
        "            self.extractor = nn.Sequential(*[*model.children()][:-1])\n",
        "            self.classifier = nn.Sequential(nn.Linear(in_features=in_f, out_features=1))\n",
        "        \n",
        "        def getOptimizer(self, lr=1e-3, wd=0):\n",
        "            p = [p for p in self.parameters() if p.requires_grad]\n",
        "            return optim.Adam(self.parameters(), lr=lr, weight_decay=wd)\n",
        "    \n",
        "        def forward(self, x1, x2=None):\n",
        "            if x2 is not None:\n",
        "                x1 = self.extractor(x1)[:, :, 0, 0]\n",
        "                x2 = self.extractor(x2)[:, :, 0, 0]\n",
        "                x = torch.abs(x1 - x2)\n",
        "                x = self.classifier(x)\n",
        "            else:\n",
        "                x = self.classifier(self.extractor(x1)[:, :, 0, 0])\n",
        "            return x\n",
        "\n",
        "    siamese_net = SiameseResNet().to(device)\n",
        "    siamese_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),])\n",
        "    return siamese_net, siamese_transform"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmRfvVkXaggp"
      },
      "source": [
        "# Make Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5Q-LofQaWfA"
      },
      "source": [
        "def build_dataloaders(idx, batch_size, num_samples):\n",
        "    breaker()\n",
        "    print(\"Building Dataloaders ...\")\n",
        "    roi_extractor, roi_transform = build_roi_extractor()\n",
        "    _, siamese_transform = build_model()\n",
        "\n",
        "    def get_image(idx, size=224):\n",
        "        names = [name for name in os.listdir(DS_PATH) if (name[-4:] == \".jpg\")]\n",
        "        return cv2.cvtColor(cv2.imread(os.path.join(DS_PATH, names[idx]), cv2.IMREAD_COLOR), code=cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    def make_data(size=224, num_samples=1000, cls=\"Positive\",\n",
        "                  roi_extractor=None, roi_transform=None, \n",
        "                  device=\"cpu\", seed=0):\n",
        "        image = get_image(idx, size=size)\n",
        "        image = cv2.resize(src=image, dsize=(size, size), interpolation=cv2.INTER_AREA)\n",
        "        anchor = image.copy()\n",
        "\n",
        "        num_layers = 3\n",
        "        imgaug.seed(seed)\n",
        "        roi_augment = augmenters.Sequential([augmenters.imgcorruptlike.GlassBlur(severity=(3, 5), seed=seed)] * num_layers)\n",
        "        \n",
        "        imgaug.seed(seed)\n",
        "        dataset_augment = augmenters.Sequential([\n",
        "            augmenters.HorizontalFlip(p=0.25),\n",
        "            augmenters.VerticalFlip(p=0.25),\n",
        "            augmenters.SomeOf(5, [\n",
        "                    augmenters.blur.GaussianBlur(sigma=(0, 5), seed=seed),\n",
        "                    augmenters.blur.MedianBlur(k=(1, 7), seed=seed),\n",
        "                    augmenters.size.Crop(percent=(0, 0.1), seed=seed),\n",
        "                    augmenters.geometric.Affine(rotate=(-45, 45), scale=(0.5, 1.2),translate_percent=(-0.2, 0.2), seed=seed),\n",
        "                    augmenters.geometric.Rot90(k=(1, 3), seed=seed),\n",
        "                    augmenters.arithmetic.Dropout(p=(0, 0.05), seed=seed),\n",
        "                    augmenters.arithmetic.SaltAndPepper(p=(0, 0.05), seed=seed),\n",
        "                    augmenters.color.MultiplyBrightness(mul=(0.5, 1.5)),\n",
        "                    augmenters.color.MultiplySaturation(mul=(0, 5), seed=seed),\n",
        "                    augmenters.iaa_convolutional.Sharpen(alpha=(0.75, 1), lightness=(0.75, 1.25), seed=seed),\n",
        "                    augmenters.iaa_convolutional.Emboss(alpha=(0.75, 1), strength=(0.75, 1.25), seed=seed),\n",
        "                    augmenters.contrast.CLAHE(seed=seed),\n",
        "                    augmenters.contrast.GammaContrast(gamma=(0.2, 5), seed=seed), \n",
        "                    ])\n",
        "                ])\n",
        "\n",
        "        if re.match(r\"Negative\", cls, re.IGNORECASE):\n",
        "            with torch.no_grad():\n",
        "                output = roi_extractor(roi_transform(image).to(device).unsqueeze(dim=0))\n",
        "            cnts, scrs = output[0][\"boxes\"], output[0][\"scores\"]\n",
        "            if len(cnts) != 0:\n",
        "                cnts = ops.clip_boxes_to_image(cnts, (image.shape[0], image.shape[1]))\n",
        "                best_index = ops.nms(cnts, scrs, 0.1)[0]\n",
        "\n",
        "                x1, y1, x2, y2 = int(cnts[best_index][0]), int(cnts[best_index][1]), int(cnts[best_index][2]), int(cnts[best_index][3])\n",
        "                crp_img = image[y1:y2, x1:x2]\n",
        "                crp_img = roi_augment(images=np.expand_dims(crp_img, axis=0))\n",
        "                image[y1:y2, x1:x2] = crp_img.squeeze()\n",
        "\n",
        "        images = np.array(dataset_augment(images=[image for _ in range(num_samples)]))\n",
        "        return anchor, images\n",
        "    \n",
        "    _, p_images = make_data(size=STANDARD_SIZE, num_samples=num_samples, cls=\"Positive\", roi_extractor=roi_extractor, roi_transform=roi_transform, device=device, seed=seed)\n",
        "    anchor, n_images = make_data(size=STANDARD_SIZE, num_samples=num_samples, cls=\"Negative\", roi_extractor=roi_extractor, roi_transform=roi_transform, device=device, seed=seed)\n",
        "\n",
        "    class DS(Dataset):\n",
        "        def __init__(self, anchor, positive, negative, transform):\n",
        "            self.anchor = anchor\n",
        "            self.positive = positive\n",
        "            self.negative = negative\n",
        "            self.transform = transform\n",
        "\n",
        "            self.anchor = np.array([anchor for _ in range(self.positive.shape[0])])\n",
        "            self.pX = np.concatenate((np.expand_dims(self.anchor, axis=1), np.expand_dims(self.positive, axis=1)), axis=1)\n",
        "            self.nX = np.concatenate((np.expand_dims(self.anchor, axis=1), np.expand_dims(self.negative, axis=1)), axis=1)\n",
        "            self.py = np.ones((self.pX.shape[0], 1))\n",
        "            self.ny = np.zeros((self.nX.shape[0], 1))\n",
        "            self.X = np.concatenate((self.pX, self.nX), axis=0)\n",
        "            self.y = np.concatenate((self.py, self.ny), axis=0)\n",
        "        \n",
        "        def __len__(self):\n",
        "            return self.X.shape[0]\n",
        "\n",
        "        def __getitem__(self, idx): \n",
        "            return self.transform(self.X[idx, 0, :, :, :]), self.transform(self.X[idx, 1, :, :, :]), torch.FloatTensor(self.y[idx])\n",
        "    \n",
        "    for tr_idx, va_idx in KFold(n_splits=5, shuffle=True, random_state=seed).split(p_images):\n",
        "        train_indices, valid_indices = tr_idx, va_idx\n",
        "        break\n",
        "\n",
        "    p_train, p_valid = p_images[train_indices], p_images[valid_indices]\n",
        "    n_train, n_valid = n_images[train_indices], n_images[valid_indices]\n",
        "\n",
        "    tr_data_setup = DS(anchor=anchor, positive=p_train, negative=n_train, transform=siamese_transform)\n",
        "    va_data_setup = DS(anchor=anchor, positive=p_valid, negative=n_valid, transform=siamese_transform)\n",
        "\n",
        "    dataloaders = {\"train\" : DL(tr_data_setup, batch_size=batch_size, shuffle=True, generator=torch.manual_seed(seed)),\n",
        "                   \"valid\" : DL(va_data_setup, batch_size=batch_size, shuffle=False)\n",
        "                   }\n",
        "\n",
        "    return dataloaders"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVUOvVkYhoWZ"
      },
      "source": [
        "# Helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DViDB27VdgPK"
      },
      "source": [
        "def train(model, tr_data, va_data, epochs, lr, wd):\n",
        "\n",
        "    def fit_(model=None, optimizer=None, scheduler=None, epochs=None,\n",
        "             trainloader=None, validloader=None, criterion=None, device=None,\n",
        "             path=None, verbose=None):\n",
        "        breaker()\n",
        "        print(\"Training ...\")\n",
        "        breaker()\n",
        "\n",
        "        model.to(device)\n",
        "        Losses, Accuracies = [], []\n",
        "        bestLoss, bestAccs = {\"train\" : np.inf, \"valid\" : np.inf}, {\"train\" : 0.0, \"valid\" : 0.0}\n",
        "        DLS = {\"train\" : trainloader, \"valid\" : validloader}\n",
        "\n",
        "        start_time = time()\n",
        "        for e in range(epochs):\n",
        "            e_st = time()\n",
        "            epochLoss = {\"train\" : 0.0, \"valid\" : 0.0}\n",
        "            epochAccs = {\"train\" : 0.0, \"valid\" : 0.0}\n",
        "\n",
        "            for phase in [\"train\", \"valid\"]:\n",
        "                if phase == \"train\":\n",
        "                    model.train()\n",
        "                else:\n",
        "                    model.eval()\n",
        "                \n",
        "                lossPerPass, accsPerPass = [], []\n",
        "\n",
        "                for X1, X2, y in DLS[phase]:\n",
        "                    X1, X2, y = X1.to(device), X2.to(device), y.to(device)\n",
        "\n",
        "                    optimizer.zero_grad()\n",
        "                    with torch.set_grad_enabled(phase == \"train\"):\n",
        "                        output = model(X1, X2)\n",
        "                        loss = criterion(output, y)\n",
        "                        if phase == \"train\":\n",
        "                            loss.backward()\n",
        "                            optimizer.step()\n",
        "                    lossPerPass.append(loss.item())\n",
        "                    accsPerPass.append(getAccuracy(output, y))\n",
        "                epochLoss[phase] = np.mean(np.array(lossPerPass))\n",
        "                epochAccs[phase] = np.mean(np.array(accsPerPass))\n",
        "            Losses.append(epochLoss)\n",
        "            Accuracies.append(epochAccs)\n",
        "            \n",
        "            if epochLoss[\"valid\"] < bestLoss[\"valid\"]:\n",
        "                bestLoss = epochLoss\n",
        "                BLE = e+1\n",
        "                torch.save({\"model_state_dict\" : model.state_dict(),\n",
        "                            \"optim_state_dict\" : optimizer.state_dict()},\n",
        "                            os.path.join(path, \"state.pt\"))\n",
        "            \n",
        "            if epochAccs[\"valid\"] > bestAccs[\"valid\"]:\n",
        "                bestAccs = epochAccs\n",
        "                BAE = e+1\n",
        "            \n",
        "            if scheduler:\n",
        "                scheduler.step(epochLoss[\"valid\"])\n",
        "            \n",
        "            if verbose:\n",
        "                print(\"Epoch: {} | Train Loss: {:.5f} | Valid Loss: {:.5f} | Train Accs : {:.5f} | \\\n",
        "Valid Accs : {:.5f} | Time: {:.2f} seconds\".format(e + 1,\n",
        "                                                    epochLoss[\"train\"], epochLoss[\"valid\"],\n",
        "                                                    epochAccs[\"train\"], epochAccs[\"valid\"],\n",
        "                                                    time() - e_st))\n",
        "\n",
        "\n",
        "\n",
        "        breaker()\n",
        "        print(\"Best Validation Loss at Epoch ---> {}\".format(BLE))\n",
        "        breaker()\n",
        "        print(\"Best Validation Accs at Epoch ---> {}\".format(BAE))\n",
        "        breaker()\n",
        "        print(\"Time Taken [{} Epochs] : {:.2f} minutes\".format(epochs, (time() - start_time) / 60))\n",
        "        breaker()\n",
        "        print(\"Training Completed\")\n",
        "        breaker()\n",
        "\n",
        "        return Losses, Accuracies, BLE, BAE\n",
        "\n",
        "\n",
        "    def getAccuracy(y_pred=None, y_true=None):\n",
        "        y_pred, y_true = torch.sigmoid(y_pred).detach(), y_true.detach()\n",
        "\n",
        "        y_pred[y_pred > 0.5] = 1\n",
        "        y_pred[y_pred <= 0.5] = 0\n",
        "\n",
        "        return torch.count_nonzero(y_pred == y_true).item() / len(y_pred)\n",
        "    \n",
        "    optimizer = model.getOptimizer(lr=lr, wd=wd)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, patience=25, eps=1e-12, verbose=True)\n",
        "    checkpoint_path = os.path.join(\"/content/checkpoints\")\n",
        "    if not os.path.exists(checkpoint_path):\n",
        "        os.makedirs(checkpoint_path)\n",
        "\n",
        "    L, A, BLE, BAE = fit_(model=model, optimizer=optimizer, scheduler=scheduler, epochs=epochs,\n",
        "                          trainloader=tr_data, validloader=va_data, device=device,\n",
        "                          criterion=nn.BCEWithLogitsLoss(),\n",
        "                          path=checkpoint_path, verbose=True)\n",
        "\n",
        "    TL, VL, TA, VA = [], [], [], []\n",
        "\n",
        "    for i in range(len(L)):\n",
        "        TL.append(L[i][\"train\"])\n",
        "        VL.append(L[i][\"valid\"])\n",
        "        TA.append(A[i][\"train\"])\n",
        "        VA.append(A[i][\"valid\"])\n",
        "\n",
        "    x_Axis = np.arange(1, len(L)+1)\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(x_Axis, TL, \"r\", label=\"Training Loss\")\n",
        "    plt.plot(x_Axis, VL, \"b--\", label=\"Validation Loss\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(x_Axis, TA, \"r\", label=\"Training Accuracy\")\n",
        "    plt.plot(x_Axis, VA, \"b--\", label=\"Validation Accuracy\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "    return BLE, checkpoint_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUcE6fabh-U_"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbcBatMGh9xA"
      },
      "source": [
        "def main():\n",
        "    ###\n",
        "    num_samples = 1000\n",
        "    batch_size = 64\n",
        "    epochs = 100\n",
        "    lr, wd = 1e-6, 1e-6\n",
        "    ###\n",
        "\n",
        "    dataloaders = build_dataloaders(1, batch_size=batch_size, num_samples=num_samples)\n",
        "    model, _ = build_model()\n",
        "    # summary(model, (3, 224, 224), 64)\n",
        "    BLE, path = train(model, dataloaders[\"train\"], dataloaders[\"valid\"], epochs, lr, wd)\n",
        "\n",
        "    return model, BLE, path\n",
        "\n",
        "model, BLE, path = main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhG3SbKN31HV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}